/home/eshuranov/miniconda3/bin/conda run -n labram2 --no-capture-output python /media/public/eshuranov/eeg_epileptiform_detection/LaBraM-main/run_class_finetuning_multidata.py --output_dir ./checkpoints/finetune_SHU/ --log_dir ./log/finetune_SHU --model labram_base_patch200_200 --finetune ./checkpoints/labram-base.pth --weight_decay 0.05 --batch_size 128 --lr 5e-4 --update_freq 1 --warmup_epochs 3 --epochs 30 --layer_decay 0.65 --drop_path 0.1 --dist_eval --save_ckpt_freq 5 --disable_rel_pos_bias --abs_pos_emb --dataset SHU --disable_qkv_bias --seed 0 --datasets_dir /media/public/Datasets/cbramod_data/SHU/processed --num_workers 10 --no_pin_mem
Not using distributed mode
Namespace(batch_size=128, epochs=30, update_freq=1, save_ckpt_freq=5, robust_test=None, model='labram_base_patch200_200', qkv_bias=False, rel_pos_bias=False, abs_pos_emb=True, layer_scale_init_value=0.1, input_size=200, drop=0.0, attn_drop_rate=0.0, drop_path=0.1, disable_eval_during_finetuning=False, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.0005, layer_decay=0.65, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=3, warmup_steps=-1, smoothing=0.1, reprob=0.25, remode='pixel', recount=1, resplit=False, finetune='./checkpoints/labram-base.pth', model_key='model|module', model_prefix='', model_filter_name='gzp', init_scale=0.001, use_mean_pooling=True, disable_weight_decay_on_rel_pos_bias=False, patch_embed_freeze_epoch=5, check_dataset=False, nb_classes=0, output_dir='./checkpoints/finetune_SHU/', datasets_dir='/media/public/Datasets/cbramod_data/SHU/processed', fixed_chkpt='', log_dir='./log/finetune_SHU', device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=False, pos_weight=None, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', enable_deepspeed=False, dataset='SHU', distributed=False)
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f3fb76e8c50>
Patch size = 200
Load ckpt from ./checkpoints/labram-base.pth
Load state_dict by model_key = model
Weights of NeuralTransformer not initialized from pretrained model: ['fc_norm.weight', 'fc_norm.bias', 'head.weight', 'head.bias']
Weights from pretrained model not used in NeuralTransformer: ['mask_token', 'lm_head.weight', 'lm_head.bias', 'norm.weight', 'norm.bias']
Model = NeuralTransformer(
  (patch_embed): TemporalConv(
    (conv1): Conv2d(1, 8, kernel_size=(1, 15), stride=(1, 8), padding=(0, 7))
    (gelu1): GELU(approximate='none')
    (norm1): GroupNorm(4, 8, eps=1e-05, affine=True)
    (conv2): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    (gelu2): GELU(approximate='none')
    (norm2): GroupNorm(4, 8, eps=1e-05, affine=True)
    (conv3): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    (norm3): GroupNorm(4, 8, eps=1e-05, affine=True)
    (gelu3): GELU(approximate='none')
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.00909090880304575)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (2): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0181818176060915)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (3): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.027272727340459824)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (4): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.036363635212183)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (5): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.045454543083906174)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (6): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.054545458406209946)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (7): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.06363636255264282)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (8): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0727272778749466)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (9): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.08181818574666977)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (10): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.09090909361839294)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (11): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.10000000149011612)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): Identity()
  (fc_norm): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=200, out_features=1, bias=True)
)
number of params: 5820137
LR = 0.00050000
Batch size = 128
Update frequent = 1
Number of training examples = 7210
Number of training training per epoch = 56
Assigned values = [0.003697205891018715, 0.005688009063105715, 0.008750783174008792, 0.013462743344628911, 0.02071191283789063, 0.03186448128906251, 0.049022278906250015, 0.07541889062500001, 0.11602906250000002, 0.17850625000000003, 0.274625, 0.42250000000000004, 0.65, 1.0]
Skip weight decay name marked in model: {'time_embed', 'cls_token', 'pos_embed'}
Param groups = {
  "layer_0_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "cls_token",
      "pos_embed",
      "patch_embed.conv1.bias",
      "patch_embed.norm1.weight",
      "patch_embed.norm1.bias",
      "patch_embed.conv2.bias",
      "patch_embed.norm2.weight",
      "patch_embed.norm2.bias",
      "patch_embed.conv3.bias",
      "patch_embed.norm3.weight",
      "patch_embed.norm3.bias"
    ],
    "lr_scale": 0.003697205891018715
  },
  "layer_13_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "time_embed",
      "fc_norm.weight",
      "fc_norm.bias",
      "head.bias"
    ],
    "lr_scale": 1.0
  },
  "layer_0_decay": {
    "weight_decay": 0.05,
    "params": [
      "patch_embed.conv1.weight",
      "patch_embed.conv2.weight",
      "patch_embed.conv3.weight"
    ],
    "lr_scale": 0.003697205891018715
  },
  "layer_1_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.0.gamma_1",
      "blocks.0.gamma_2",
      "blocks.0.norm1.weight",
      "blocks.0.norm1.bias",
      "blocks.0.attn.q_norm.weight",
      "blocks.0.attn.q_norm.bias",
      "blocks.0.attn.k_norm.weight",
      "blocks.0.attn.k_norm.bias",
      "blocks.0.attn.proj.bias",
      "blocks.0.norm2.weight",
      "blocks.0.norm2.bias",
      "blocks.0.mlp.fc1.bias",
      "blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.005688009063105715
  },
  "layer_1_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.0.attn.qkv.weight",
      "blocks.0.attn.proj.weight",
      "blocks.0.mlp.fc1.weight",
      "blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.005688009063105715
  },
  "layer_2_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.1.gamma_1",
      "blocks.1.gamma_2",
      "blocks.1.norm1.weight",
      "blocks.1.norm1.bias",
      "blocks.1.attn.q_norm.weight",
      "blocks.1.attn.q_norm.bias",
      "blocks.1.attn.k_norm.weight",
      "blocks.1.attn.k_norm.bias",
      "blocks.1.attn.proj.bias",
      "blocks.1.norm2.weight",
      "blocks.1.norm2.bias",
      "blocks.1.mlp.fc1.bias",
      "blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.008750783174008792
  },
  "layer_2_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.1.attn.qkv.weight",
      "blocks.1.attn.proj.weight",
      "blocks.1.mlp.fc1.weight",
      "blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.008750783174008792
  },
  "layer_3_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.2.gamma_1",
      "blocks.2.gamma_2",
      "blocks.2.norm1.weight",
      "blocks.2.norm1.bias",
      "blocks.2.attn.q_norm.weight",
      "blocks.2.attn.q_norm.bias",
      "blocks.2.attn.k_norm.weight",
      "blocks.2.attn.k_norm.bias",
      "blocks.2.attn.proj.bias",
      "blocks.2.norm2.weight",
      "blocks.2.norm2.bias",
      "blocks.2.mlp.fc1.bias",
      "blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.013462743344628911
  },
  "layer_3_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.2.attn.qkv.weight",
      "blocks.2.attn.proj.weight",
      "blocks.2.mlp.fc1.weight",
      "blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.013462743344628911
  },
  "layer_4_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.3.gamma_1",
      "blocks.3.gamma_2",
      "blocks.3.norm1.weight",
      "blocks.3.norm1.bias",
      "blocks.3.attn.q_norm.weight",
      "blocks.3.attn.q_norm.bias",
      "blocks.3.attn.k_norm.weight",
      "blocks.3.attn.k_norm.bias",
      "blocks.3.attn.proj.bias",
      "blocks.3.norm2.weight",
      "blocks.3.norm2.bias",
      "blocks.3.mlp.fc1.bias",
      "blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.02071191283789063
  },
  "layer_4_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.3.attn.qkv.weight",
      "blocks.3.attn.proj.weight",
      "blocks.3.mlp.fc1.weight",
      "blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.02071191283789063
  },
  "layer_5_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.4.gamma_1",
      "blocks.4.gamma_2",
      "blocks.4.norm1.weight",
      "blocks.4.norm1.bias",
      "blocks.4.attn.q_norm.weight",
      "blocks.4.attn.q_norm.bias",
      "blocks.4.attn.k_norm.weight",
      "blocks.4.attn.k_norm.bias",
      "blocks.4.attn.proj.bias",
      "blocks.4.norm2.weight",
      "blocks.4.norm2.bias",
      "blocks.4.mlp.fc1.bias",
      "blocks.4.mlp.fc2.bias"
    ],
    "lr_scale": 0.03186448128906251
  },
  "layer_5_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.4.attn.qkv.weight",
      "blocks.4.attn.proj.weight",
      "blocks.4.mlp.fc1.weight",
      "blocks.4.mlp.fc2.weight"
    ],
    "lr_scale": 0.03186448128906251
  },
  "layer_6_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.5.gamma_1",
      "blocks.5.gamma_2",
      "blocks.5.norm1.weight",
      "blocks.5.norm1.bias",
      "blocks.5.attn.q_norm.weight",
      "blocks.5.attn.q_norm.bias",
      "blocks.5.attn.k_norm.weight",
      "blocks.5.attn.k_norm.bias",
      "blocks.5.attn.proj.bias",
      "blocks.5.norm2.weight",
      "blocks.5.norm2.bias",
      "blocks.5.mlp.fc1.bias",
      "blocks.5.mlp.fc2.bias"
    ],
    "lr_scale": 0.049022278906250015
  },
  "layer_6_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.5.attn.qkv.weight",
      "blocks.5.attn.proj.weight",
      "blocks.5.mlp.fc1.weight",
      "blocks.5.mlp.fc2.weight"
    ],
    "lr_scale": 0.049022278906250015
  },
  "layer_7_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.6.gamma_1",
      "blocks.6.gamma_2",
      "blocks.6.norm1.weight",
      "blocks.6.norm1.bias",
      "blocks.6.attn.q_norm.weight",
      "blocks.6.attn.q_norm.bias",
      "blocks.6.attn.k_norm.weight",
      "blocks.6.attn.k_norm.bias",
      "blocks.6.attn.proj.bias",
      "blocks.6.norm2.weight",
      "blocks.6.norm2.bias",
      "blocks.6.mlp.fc1.bias",
      "blocks.6.mlp.fc2.bias"
    ],
    "lr_scale": 0.07541889062500001
  },
  "layer_7_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.6.attn.qkv.weight",
      "blocks.6.attn.proj.weight",
      "blocks.6.mlp.fc1.weight",
      "blocks.6.mlp.fc2.weight"
    ],
    "lr_scale": 0.07541889062500001
  },
  "layer_8_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.7.gamma_1",
      "blocks.7.gamma_2",
      "blocks.7.norm1.weight",
      "blocks.7.norm1.bias",
      "blocks.7.attn.q_norm.weight",
      "blocks.7.attn.q_norm.bias",
      "blocks.7.attn.k_norm.weight",
      "blocks.7.attn.k_norm.bias",
      "blocks.7.attn.proj.bias",
      "blocks.7.norm2.weight",
      "blocks.7.norm2.bias",
      "blocks.7.mlp.fc1.bias",
      "blocks.7.mlp.fc2.bias"
    ],
    "lr_scale": 0.11602906250000002
  },
  "layer_8_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.7.attn.qkv.weight",
      "blocks.7.attn.proj.weight",
      "blocks.7.mlp.fc1.weight",
      "blocks.7.mlp.fc2.weight"
    ],
    "lr_scale": 0.11602906250000002
  },
  "layer_9_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.8.gamma_1",
      "blocks.8.gamma_2",
      "blocks.8.norm1.weight",
      "blocks.8.norm1.bias",
      "blocks.8.attn.q_norm.weight",
      "blocks.8.attn.q_norm.bias",
      "blocks.8.attn.k_norm.weight",
      "blocks.8.attn.k_norm.bias",
      "blocks.8.attn.proj.bias",
      "blocks.8.norm2.weight",
      "blocks.8.norm2.bias",
      "blocks.8.mlp.fc1.bias",
      "blocks.8.mlp.fc2.bias"
    ],
    "lr_scale": 0.17850625000000003
  },
  "layer_9_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.8.attn.qkv.weight",
      "blocks.8.attn.proj.weight",
      "blocks.8.mlp.fc1.weight",
      "blocks.8.mlp.fc2.weight"
    ],
    "lr_scale": 0.17850625000000003
  },
  "layer_10_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.9.gamma_1",
      "blocks.9.gamma_2",
      "blocks.9.norm1.weight",
      "blocks.9.norm1.bias",
      "blocks.9.attn.q_norm.weight",
      "blocks.9.attn.q_norm.bias",
      "blocks.9.attn.k_norm.weight",
      "blocks.9.attn.k_norm.bias",
      "blocks.9.attn.proj.bias",
      "blocks.9.norm2.weight",
      "blocks.9.norm2.bias",
      "blocks.9.mlp.fc1.bias",
      "blocks.9.mlp.fc2.bias"
    ],
    "lr_scale": 0.274625
  },
  "layer_10_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.9.attn.qkv.weight",
      "blocks.9.attn.proj.weight",
      "blocks.9.mlp.fc1.weight",
      "blocks.9.mlp.fc2.weight"
    ],
    "lr_scale": 0.274625
  },
  "layer_11_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.10.gamma_1",
      "blocks.10.gamma_2",
      "blocks.10.norm1.weight",
      "blocks.10.norm1.bias",
      "blocks.10.attn.q_norm.weight",
      "blocks.10.attn.q_norm.bias",
      "blocks.10.attn.k_norm.weight",
      "blocks.10.attn.k_norm.bias",
      "blocks.10.attn.proj.bias",
      "blocks.10.norm2.weight",
      "blocks.10.norm2.bias",
      "blocks.10.mlp.fc1.bias",
      "blocks.10.mlp.fc2.bias"
    ],
    "lr_scale": 0.42250000000000004
  },
  "layer_11_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.10.attn.qkv.weight",
      "blocks.10.attn.proj.weight",
      "blocks.10.mlp.fc1.weight",
      "blocks.10.mlp.fc2.weight"
    ],
    "lr_scale": 0.42250000000000004
  },
  "layer_12_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.11.gamma_1",
      "blocks.11.gamma_2",
      "blocks.11.norm1.weight",
      "blocks.11.norm1.bias",
      "blocks.11.attn.q_norm.weight",
      "blocks.11.attn.q_norm.bias",
      "blocks.11.attn.k_norm.weight",
      "blocks.11.attn.k_norm.bias",
      "blocks.11.attn.proj.bias",
      "blocks.11.norm2.weight",
      "blocks.11.norm2.bias",
      "blocks.11.mlp.fc1.bias",
      "blocks.11.mlp.fc2.bias"
    ],
    "lr_scale": 0.65
  },
  "layer_12_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.11.attn.qkv.weight",
      "blocks.11.attn.proj.weight",
      "blocks.11.mlp.fc1.weight",
      "blocks.11.mlp.fc2.weight"
    ],
    "lr_scale": 0.65
  },
  "layer_13_decay": {
    "weight_decay": 0.05,
    "params": [
      "head.weight"
    ],
    "lr_scale": 1.0
  }
}
Optimizer config: {'lr': 0.0005, 'weight_decay': 0.0, 'eps': 1e-08}
Use step level LR scheduler!
Set warmup steps = 168
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
Using BCEWithLogitsLoss without pos_weight; consider setting --pos_weight=N_neg/N_pos for imbalanced splits
criterion = BCEWithLogitsLoss()
Auto resume checkpoint:
Start training for 30 epochs
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
/home/eshuranov/miniconda3/envs/labram2/lib/python3.11/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
Epoch: [0]  [ 0/56]  eta: 0:01:20  lr: 0.000000  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.4844 (0.4844)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3615 (0.3615)  time: 1.4323  data: 0.6472  max mem: 0
Epoch: [0]  [10/56]  eta: 0:00:12  lr: 0.000030  min_lr: 0.000000  loss: 0.6932 (0.6931)  class_acc: 0.4844 (0.4950)  balanced_accuracy: 0.4990 (0.4968)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4396 (0.4945)  time: 0.2707  data: 0.0593  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [0]  [20/56]  eta: 0:00:07  lr: 0.000060  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4766 (0.4944)  balanced_accuracy: 0.5000 (0.4983)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5515 (0.5542)  time: 0.1545  data: 0.0003  max mem: 0
Epoch: [0]  [30/56]  eta: 0:00:05  lr: 0.000090  min_lr: 0.000000  loss: 0.6933 (0.6932)  class_acc: 0.4844 (0.4934)  balanced_accuracy: 0.5000 (0.4991)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3906 (0.4976)  time: 0.1551  data: 0.0006  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [0]  [40/56]  eta: 0:00:02  lr: 0.000120  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.5000 (0.4973)  balanced_accuracy: 0.4971 (0.4974)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3548 (0.4887)  time: 0.1555  data: 0.0010  max mem: 0
Epoch: [0]  [50/56]  eta: 0:00:01  lr: 0.000150  min_lr: 0.000001  loss: 0.6930 (0.6933)  class_acc: 0.5078 (0.4963)  balanced_accuracy: 0.5000 (0.4976)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4357 (0.5129)  time: 0.1552  data: 0.0010  max mem: 0
Epoch: [0]  [55/56]  eta: 0:00:00  lr: 0.000165  min_lr: 0.000001  loss: 0.6930 (0.6933)  class_acc: 0.5078 (0.4975)  balanced_accuracy: 0.5000 (0.4989)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4357 (0.5195)  time: 0.1551  data: 0.0010  max mem: 0
Epoch: [0] Total time: 0:00:10 (0.1795 s / it)
Averaged stats: lr: 0.000165  min_lr: 0.000001  loss: 0.6930 (0.6933)  class_acc: 0.5078 (0.4975)  balanced_accuracy: 0.5000 (0.4989)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4357 (0.5195)
Val:  [ 0/13]  eta: 0:00:09  loss: 0.6931 (0.6931)  pr_auc: 0.5130 (0.5130)  roc_auc: 0.5073 (0.5073)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5000 (0.5000)  time: 0.7128  data: 0.5259  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6933 (0.6932)  pr_auc: 0.4995 (0.5008)  roc_auc: 0.4991 (0.4904)  accuracy: 0.4948 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1321  data: 0.0484  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6933 (0.6932)  pr_auc: 0.4995 (0.4999)  roc_auc: 0.4991 (0.4895)  accuracy: 0.4961 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1231  data: 0.0409  max mem: 0
Val: Total time: 0:00:01 (0.1322 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4791 (0.4791)  roc_auc: 0.4440 (0.4440)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6088  data: 0.5358  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6931)  pr_auc: 0.5020 (0.5027)  roc_auc: 0.4868 (0.4882)  accuracy: 0.5000 (0.5033)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1224  data: 0.0492  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5020 (0.5022)  roc_auc: 0.4868 (0.4897)  accuracy: 0.5000 (0.5019)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1127  data: 0.0417  max mem: 0
Test: Total time: 0:00:01 (0.1216 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [1]  [ 0/56]  eta: 0:00:41  lr: 0.000168  min_lr: 0.000001  loss: 0.6938 (0.6938)  class_acc: 0.4531 (0.4531)  balanced_accuracy: 0.4677 (0.4677)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3280 (0.3280)  time: 0.7331  data: 0.5637  max mem: 0
Epoch: [1]  [10/56]  eta: 0:00:09  lr: 0.000198  min_lr: 0.000001  loss: 0.6928 (0.6927)  class_acc: 0.5234 (0.5128)  balanced_accuracy: 0.5034 (0.4957)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4852 (0.4683)  time: 0.2082  data: 0.0518  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [1]  [20/56]  eta: 0:00:06  lr: 0.000228  min_lr: 0.000001  loss: 0.6931 (0.6933)  class_acc: 0.5000 (0.5033)  balanced_accuracy: 0.5000 (0.4973)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5002 (0.5638)  time: 0.1559  data: 0.0006  max mem: 0
Epoch: [1]  [30/56]  eta: 0:00:04  lr: 0.000257  min_lr: 0.000001  loss: 0.6939 (0.6934)  class_acc: 0.4844 (0.5010)  balanced_accuracy: 0.5000 (0.4978)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4220 (0.5079)  time: 0.1560  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [1]  [40/56]  eta: 0:00:02  lr: 0.000287  min_lr: 0.000001  loss: 0.6934 (0.6933)  class_acc: 0.5000 (0.5050)  balanced_accuracy: 0.5000 (0.4971)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3679 (0.4869)  time: 0.1563  data: 0.0009  max mem: 0
Epoch: [1]  [50/56]  eta: 0:00:01  lr: 0.000317  min_lr: 0.000001  loss: 0.6928 (0.6934)  class_acc: 0.5156 (0.5026)  balanced_accuracy: 0.5000 (0.4975)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3193 (0.5123)  time: 0.1566  data: 0.0010  max mem: 0
Epoch: [1]  [55/56]  eta: 0:00:00  lr: 0.000332  min_lr: 0.000001  loss: 0.6931 (0.6934)  class_acc: 0.5078 (0.5027)  balanced_accuracy: 0.5000 (0.4982)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3130 (0.5152)  time: 0.1566  data: 0.0010  max mem: 0
Epoch: [1] Total time: 0:00:09 (0.1689 s / it)
Averaged stats: lr: 0.000332  min_lr: 0.000001  loss: 0.6931 (0.6934)  class_acc: 0.5078 (0.5027)  balanced_accuracy: 0.5000 (0.4982)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3130 (0.5152)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6931 (0.6931)  pr_auc: 0.5139 (0.5139)  roc_auc: 0.5130 (0.5130)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6271  data: 0.5537  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6934 (0.6932)  pr_auc: 0.5048 (0.5147)  roc_auc: 0.5034 (0.5173)  accuracy: 0.4948 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1241  data: 0.0505  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6934 (0.6932)  pr_auc: 0.5010 (0.5111)  roc_auc: 0.5015 (0.5110)  accuracy: 0.4961 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1146  data: 0.0427  max mem: 0
Val: Total time: 0:00:01 (0.1236 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6933 (0.6933)  pr_auc: 0.4980 (0.4980)  roc_auc: 0.4947 (0.4947)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6262  data: 0.5534  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6933 (0.6932)  pr_auc: 0.4975 (0.4998)  roc_auc: 0.4947 (0.4882)  accuracy: 0.5000 (0.5033)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1240  data: 0.0505  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6933 (0.6933)  pr_auc: 0.4975 (0.4999)  roc_auc: 0.4947 (0.4906)  accuracy: 0.5000 (0.5019)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1122  data: 0.0427  max mem: 0
Test: Total time: 0:00:01 (0.1213 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [2]  [ 0/56]  eta: 0:00:39  lr: 0.000335  min_lr: 0.000001  loss: 0.6941 (0.6941)  class_acc: 0.4844 (0.4844)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4432 (0.4432)  time: 0.6977  data: 0.5405  max mem: 0
Epoch: [2]  [10/56]  eta: 0:00:09  lr: 0.000365  min_lr: 0.000001  loss: 0.6919 (0.6923)  class_acc: 0.5312 (0.5199)  balanced_accuracy: 0.5000 (0.5007)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4432 (0.4322)  time: 0.2058  data: 0.0499  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [2]  [20/56]  eta: 0:00:06  lr: 0.000395  min_lr: 0.000001  loss: 0.6931 (0.6933)  class_acc: 0.5078 (0.5067)  balanced_accuracy: 0.5000 (0.4996)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5553 (0.6001)  time: 0.1563  data: 0.0006  max mem: 0
Epoch: [2]  [30/56]  eta: 0:00:04  lr: 0.000425  min_lr: 0.000002  loss: 0.6940 (0.6934)  class_acc: 0.4844 (0.5008)  balanced_accuracy: 0.5000 (0.4970)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4657 (0.5200)  time: 0.1565  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [2]  [40/56]  eta: 0:00:02  lr: 0.000455  min_lr: 0.000002  loss: 0.6932 (0.6933)  class_acc: 0.5000 (0.5061)  balanced_accuracy: 0.5000 (0.4976)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2911 (0.4870)  time: 0.1569  data: 0.0010  max mem: 0
Epoch: [2]  [50/56]  eta: 0:00:01  lr: 0.000485  min_lr: 0.000002  loss: 0.6927 (0.6935)  class_acc: 0.5078 (0.5037)  balanced_accuracy: 0.5000 (0.4981)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2875 (0.5098)  time: 0.1569  data: 0.0010  max mem: 0
Epoch: [2]  [55/56]  eta: 0:00:00  lr: 0.000500  min_lr: 0.000002  loss: 0.6932 (0.6935)  class_acc: 0.5000 (0.5029)  balanced_accuracy: 0.5000 (0.4981)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2875 (0.5131)  time: 0.1566  data: 0.0010  max mem: 0
Epoch: [2] Total time: 0:00:09 (0.1686 s / it)
Averaged stats: lr: 0.000500  min_lr: 0.000002  loss: 0.6932 (0.6935)  class_acc: 0.5000 (0.5029)  balanced_accuracy: 0.5000 (0.4981)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2875 (0.5131)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6931 (0.6931)  pr_auc: 0.5049 (0.5049)  roc_auc: 0.4958 (0.4958)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6078  data: 0.5344  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6935 (0.6933)  pr_auc: 0.4971 (0.4929)  roc_auc: 0.4753 (0.4802)  accuracy: 0.4948 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1227  data: 0.0487  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6935 (0.6933)  pr_auc: 0.4971 (0.4932)  roc_auc: 0.4865 (0.4811)  accuracy: 0.4961 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1135  data: 0.0412  max mem: 0
Val: Total time: 0:00:01 (0.1223 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6933 (0.6933)  pr_auc: 0.5118 (0.5118)  roc_auc: 0.5197 (0.5197)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6208  data: 0.5474  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6933 (0.6932)  pr_auc: 0.5050 (0.5050)  roc_auc: 0.5089 (0.5009)  accuracy: 0.5000 (0.5033)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1239  data: 0.0499  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6933 (0.6933)  pr_auc: 0.5024 (0.5042)  roc_auc: 0.5089 (0.5021)  accuracy: 0.5000 (0.5019)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1122  data: 0.0423  max mem: 0
Test: Total time: 0:00:01 (0.1213 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [3]  [ 0/56]  eta: 0:00:41  lr: 0.000500  min_lr: 0.000002  loss: 0.6939 (0.6939)  class_acc: 0.4844 (0.4844)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3329 (0.3329)  time: 0.7325  data: 0.5757  max mem: 0
Epoch: [3]  [10/56]  eta: 0:00:09  lr: 0.000500  min_lr: 0.000002  loss: 0.6921 (0.6924)  class_acc: 0.5234 (0.5192)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4109 (0.4066)  time: 0.2094  data: 0.0528  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [3]  [20/56]  eta: 0:00:06  lr: 0.000500  min_lr: 0.000002  loss: 0.6933 (0.6934)  class_acc: 0.5078 (0.5067)  balanced_accuracy: 0.5000 (0.4996)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5579 (0.5694)  time: 0.1569  data: 0.0004  max mem: 0
Epoch: [3]  [30/56]  eta: 0:00:04  lr: 0.000500  min_lr: 0.000002  loss: 0.6946 (0.6936)  class_acc: 0.4844 (0.5018)  balanced_accuracy: 0.5000 (0.4984)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4508 (0.5142)  time: 0.1571  data: 0.0006  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [3]  [40/56]  eta: 0:00:02  lr: 0.000499  min_lr: 0.000002  loss: 0.6933 (0.6933)  class_acc: 0.4922 (0.5069)  balanced_accuracy: 0.5000 (0.4986)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3823 (0.4806)  time: 0.1576  data: 0.0010  max mem: 0
Epoch: [3]  [50/56]  eta: 0:00:01  lr: 0.000499  min_lr: 0.000002  loss: 0.6927 (0.6936)  class_acc: 0.5156 (0.5046)  balanced_accuracy: 0.5000 (0.4993)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3579 (0.5120)  time: 0.1575  data: 0.0010  max mem: 0
Epoch: [3]  [55/56]  eta: 0:00:00  lr: 0.000498  min_lr: 0.000002  loss: 0.6934 (0.6935)  class_acc: 0.5078 (0.5046)  balanced_accuracy: 0.5000 (0.4997)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3579 (0.5151)  time: 0.1573  data: 0.0010  max mem: 0
Epoch: [3] Total time: 0:00:09 (0.1698 s / it)
Averaged stats: lr: 0.000498  min_lr: 0.000002  loss: 0.6934 (0.6935)  class_acc: 0.5078 (0.5046)  balanced_accuracy: 0.5000 (0.4997)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3579 (0.5151)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5205 (0.5205)  roc_auc: 0.5097 (0.5097)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5964  data: 0.5227  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6937 (0.6934)  pr_auc: 0.4982 (0.4978)  roc_auc: 0.4982 (0.4863)  accuracy: 0.4948 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1222  data: 0.0479  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6937 (0.6934)  pr_auc: 0.4948 (0.4936)  roc_auc: 0.4937 (0.4790)  accuracy: 0.4961 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1132  data: 0.0407  max mem: 0
Val: Total time: 0:00:01 (0.1220 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6934 (0.6934)  pr_auc: 0.5014 (0.5014)  roc_auc: 0.4989 (0.4989)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6581  data: 0.5846  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6934 (0.6933)  pr_auc: 0.5130 (0.5095)  roc_auc: 0.5082 (0.5048)  accuracy: 0.5000 (0.5033)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1274  data: 0.0533  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6934 (0.6934)  pr_auc: 0.5130 (0.5092)  roc_auc: 0.5082 (0.5067)  accuracy: 0.5000 (0.5019)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1152  data: 0.0451  max mem: 0
Test: Total time: 0:00:01 (0.1243 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [4]  [ 0/56]  eta: 0:00:29  lr: 0.000498  min_lr: 0.000002  loss: 0.6951 (0.6951)  class_acc: 0.4844 (0.4844)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3835 (0.3835)  time: 0.5345  data: 0.3755  max mem: 0
Epoch: [4]  [10/56]  eta: 0:00:09  lr: 0.000498  min_lr: 0.000002  loss: 0.6930 (0.6928)  class_acc: 0.5234 (0.5185)  balanced_accuracy: 0.5000 (0.4993)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4559 (0.4356)  time: 0.1959  data: 0.0393  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [4]  [20/56]  eta: 0:00:06  lr: 0.000497  min_lr: 0.000002  loss: 0.6934 (0.6937)  class_acc: 0.5000 (0.5067)  balanced_accuracy: 0.5000 (0.4996)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5440 (0.5623)  time: 0.1593  data: 0.0030  max mem: 0
Epoch: [4]  [30/56]  eta: 0:00:04  lr: 0.000496  min_lr: 0.000002  loss: 0.6938 (0.6937)  class_acc: 0.4844 (0.5045)  balanced_accuracy: 0.5000 (0.5010)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4408 (0.4934)  time: 0.1568  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [4]  [40/56]  eta: 0:00:02  lr: 0.000495  min_lr: 0.000002  loss: 0.6930 (0.6933)  class_acc: 0.5078 (0.5091)  balanced_accuracy: 0.5000 (0.5008)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2751 (0.4541)  time: 0.1572  data: 0.0011  max mem: 0
Epoch: [4]  [50/56]  eta: 0:00:00  lr: 0.000494  min_lr: 0.000002  loss: 0.6924 (0.6935)  class_acc: 0.5156 (0.5061)  balanced_accuracy: 0.5000 (0.5006)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2204 (0.4800)  time: 0.1570  data: 0.0010  max mem: 0
Epoch: [4]  [55/56]  eta: 0:00:00  lr: 0.000493  min_lr: 0.000002  loss: 0.6928 (0.6935)  class_acc: 0.5078 (0.5042)  balanced_accuracy: 0.5000 (0.5006)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2204 (0.4850)  time: 0.1569  data: 0.0010  max mem: 0
Epoch: [4] Total time: 0:00:09 (0.1669 s / it)
Averaged stats: lr: 0.000493  min_lr: 0.000002  loss: 0.6928 (0.6935)  class_acc: 0.5078 (0.5042)  balanced_accuracy: 0.5000 (0.5006)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2204 (0.4850)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5301 (0.5301)  roc_auc: 0.5421 (0.5421)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6095  data: 0.5358  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5022 (0.5027)  roc_auc: 0.5033 (0.4987)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1235  data: 0.0493  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4966 (0.5011)  roc_auc: 0.4944 (0.4950)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1142  data: 0.0418  max mem: 0
Val: Total time: 0:00:01 (0.1230 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6931 (0.6931)  pr_auc: 0.5231 (0.5231)  roc_auc: 0.5407 (0.5407)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6058  data: 0.5321  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5002 (0.5063)  roc_auc: 0.4990 (0.5033)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1229  data: 0.0487  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.4968 (0.5045)  roc_auc: 0.4955 (0.5018)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1115  data: 0.0412  max mem: 0
Test: Total time: 0:00:01 (0.1206 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [5]  [ 0/56]  eta: 0:00:41  lr: 0.000493  min_lr: 0.000002  loss: 0.6932 (0.6932)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5015 (0.5015)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1975 (0.1975)  time: 0.7478  data: 0.5895  max mem: 0
Epoch: [5]  [10/56]  eta: 0:00:09  lr: 0.000492  min_lr: 0.000002  loss: 0.6927 (0.6926)  class_acc: 0.5391 (0.5298)  balanced_accuracy: 0.5000 (0.5051)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4363 (0.4153)  time: 0.2113  data: 0.0540  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [5]  [20/56]  eta: 0:00:06  lr: 0.000491  min_lr: 0.000002  loss: 0.6931 (0.6935)  class_acc: 0.5078 (0.5126)  balanced_accuracy: 0.5000 (0.5027)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5533 (0.5590)  time: 0.1577  data: 0.0004  max mem: 0
Epoch: [5]  [30/56]  eta: 0:00:04  lr: 0.000489  min_lr: 0.000002  loss: 0.6938 (0.6935)  class_acc: 0.4844 (0.5058)  balanced_accuracy: 0.5000 (0.5015)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4450 (0.4894)  time: 0.1580  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [5]  [40/56]  eta: 0:00:02  lr: 0.000488  min_lr: 0.000002  loss: 0.6931 (0.6933)  class_acc: 0.5000 (0.5101)  balanced_accuracy: 0.5000 (0.5011)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2776 (0.4536)  time: 0.1584  data: 0.0012  max mem: 0
Epoch: [5]  [50/56]  eta: 0:00:01  lr: 0.000486  min_lr: 0.000002  loss: 0.6926 (0.6934)  class_acc: 0.5156 (0.5069)  balanced_accuracy: 0.5000 (0.5009)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2439 (0.4793)  time: 0.1583  data: 0.0013  max mem: 0
Epoch: [5]  [55/56]  eta: 0:00:00  lr: 0.000485  min_lr: 0.000002  loss: 0.6927 (0.6934)  class_acc: 0.5156 (0.5070)  balanced_accuracy: 0.5000 (0.5011)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2439 (0.4827)  time: 0.1583  data: 0.0013  max mem: 0
Epoch: [5] Total time: 0:00:09 (0.1710 s / it)
Averaged stats: lr: 0.000485  min_lr: 0.000002  loss: 0.6927 (0.6934)  class_acc: 0.5156 (0.5070)  balanced_accuracy: 0.5000 (0.5011)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2439 (0.4827)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6931 (0.6931)  pr_auc: 0.4881 (0.4881)  roc_auc: 0.4633 (0.4633)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6724  data: 0.5986  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6931)  pr_auc: 0.5084 (0.5078)  roc_auc: 0.5135 (0.5116)  accuracy: 0.4948 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1295  data: 0.0550  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6931)  pr_auc: 0.5084 (0.5092)  roc_auc: 0.5135 (0.5143)  accuracy: 0.4961 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1194  data: 0.0465  max mem: 0
Val: Total time: 0:00:01 (0.1290 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4949 (0.4949)  roc_auc: 0.4896 (0.4896)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5902  data: 0.5162  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5071 (0.5059)  roc_auc: 0.4976 (0.5036)  accuracy: 0.5000 (0.5033)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1222  data: 0.0475  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5040 (0.5028)  roc_auc: 0.4957 (0.5001)  accuracy: 0.5000 (0.5019)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1109  data: 0.0403  max mem: 0
Test: Total time: 0:00:01 (0.1199 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.51%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [6]  [ 0/56]  eta: 0:00:50  lr: 0.000485  min_lr: 0.000002  loss: 0.6941 (0.6941)  class_acc: 0.4844 (0.4844)  balanced_accuracy: 0.4961 (0.4961)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2372 (0.2372)  time: 0.9072  data: 0.5934  max mem: 0
Epoch: [6]  [10/56]  eta: 0:00:10  lr: 0.000483  min_lr: 0.000002  loss: 0.6938 (0.6930)  class_acc: 0.4844 (0.5092)  balanced_accuracy: 0.4941 (0.4941)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4325 (0.4261)  time: 0.2313  data: 0.0546  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [6]  [20/56]  eta: 0:00:07  lr: 0.000481  min_lr: 0.000002  loss: 0.6941 (0.6937)  class_acc: 0.4844 (0.5011)  balanced_accuracy: 0.4989 (0.4958)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4917 (0.5469)  time: 0.1625  data: 0.0006  max mem: 0
Epoch: [6]  [30/56]  eta: 0:00:04  lr: 0.000479  min_lr: 0.000002  loss: 0.6940 (0.6937)  class_acc: 0.4766 (0.4965)  balanced_accuracy: 0.5000 (0.4938)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4368 (0.4811)  time: 0.1616  data: 0.0008  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [6]  [40/56]  eta: 0:00:02  lr: 0.000477  min_lr: 0.000002  loss: 0.6932 (0.6934)  class_acc: 0.5000 (0.5021)  balanced_accuracy: 0.4995 (0.4945)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2648 (0.4440)  time: 0.1615  data: 0.0010  max mem: 0
Epoch: [6]  [50/56]  eta: 0:00:01  lr: 0.000475  min_lr: 0.000002  loss: 0.6923 (0.6936)  class_acc: 0.5078 (0.5005)  balanced_accuracy: 0.5000 (0.4956)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2659 (0.4713)  time: 0.1612  data: 0.0010  max mem: 0
Epoch: [6]  [55/56]  eta: 0:00:00  lr: 0.000474  min_lr: 0.000002  loss: 0.6928 (0.6936)  class_acc: 0.5078 (0.5011)  balanced_accuracy: 0.5000 (0.4961)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2659 (0.4748)  time: 0.1610  data: 0.0010  max mem: 0
Epoch: [6] Total time: 0:00:09 (0.1776 s / it)
Averaged stats: lr: 0.000474  min_lr: 0.000002  loss: 0.6928 (0.6936)  class_acc: 0.5078 (0.5011)  balanced_accuracy: 0.5000 (0.4961)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2659 (0.4748)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6931 (0.6931)  pr_auc: 0.4951 (0.4951)  roc_auc: 0.4794 (0.4794)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6319  data: 0.5580  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6931)  pr_auc: 0.4958 (0.4991)  roc_auc: 0.4998 (0.4950)  accuracy: 0.4948 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1255  data: 0.0509  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6931)  pr_auc: 0.4961 (0.4995)  roc_auc: 0.5000 (0.4956)  accuracy: 0.4961 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1160  data: 0.0431  max mem: 0
Val: Total time: 0:00:01 (0.1252 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.4923 (0.4923)  roc_auc: 0.4844 (0.4844)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6326  data: 0.5585  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6931)  pr_auc: 0.5000 (0.4963)  roc_auc: 0.4901 (0.4853)  accuracy: 0.5000 (0.5033)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1260  data: 0.0514  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.4976 (0.4961)  roc_auc: 0.4948 (0.4878)  accuracy: 0.5000 (0.5019)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1141  data: 0.0435  max mem: 0
Test: Total time: 0:00:01 (0.1235 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [7]  [ 0/56]  eta: 0:00:39  lr: 0.000473  min_lr: 0.000002  loss: 0.6932 (0.6932)  class_acc: 0.5000 (0.5000)  balanced_accuracy: 0.5122 (0.5122)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2290 (0.2290)  time: 0.7127  data: 0.5509  max mem: 0
Epoch: [7]  [10/56]  eta: 0:00:09  lr: 0.000471  min_lr: 0.000002  loss: 0.6925 (0.6926)  class_acc: 0.5234 (0.5199)  balanced_accuracy: 0.5022 (0.5023)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4594 (0.4075)  time: 0.2113  data: 0.0506  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [7]  [20/56]  eta: 0:00:06  lr: 0.000469  min_lr: 0.000002  loss: 0.6934 (0.6934)  class_acc: 0.4922 (0.5074)  balanced_accuracy: 0.5000 (0.5012)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5404 (0.5456)  time: 0.1611  data: 0.0005  max mem: 0
Epoch: [7]  [30/56]  eta: 0:00:04  lr: 0.000466  min_lr: 0.000002  loss: 0.6937 (0.6935)  class_acc: 0.4766 (0.5023)  balanced_accuracy: 0.5000 (0.5004)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4270 (0.4888)  time: 0.1612  data: 0.0004  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [7]  [40/56]  eta: 0:00:02  lr: 0.000463  min_lr: 0.000002  loss: 0.6933 (0.6932)  class_acc: 0.5000 (0.5072)  balanced_accuracy: 0.5000 (0.5001)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3028 (0.4563)  time: 0.1616  data: 0.0006  max mem: 0
Epoch: [7]  [50/56]  eta: 0:00:01  lr: 0.000461  min_lr: 0.000002  loss: 0.6925 (0.6935)  class_acc: 0.5156 (0.5046)  balanced_accuracy: 0.5000 (0.5001)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2757 (0.4830)  time: 0.1619  data: 0.0011  max mem: 0
Epoch: [7]  [55/56]  eta: 0:00:00  lr: 0.000459  min_lr: 0.000002  loss: 0.6930 (0.6934)  class_acc: 0.5078 (0.5045)  balanced_accuracy: 0.5000 (0.5004)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2757 (0.4858)  time: 0.1619  data: 0.0011  max mem: 0
Epoch: [7] Total time: 0:00:09 (0.1737 s / it)
Averaged stats: lr: 0.000459  min_lr: 0.000002  loss: 0.6930 (0.6934)  class_acc: 0.5078 (0.5045)  balanced_accuracy: 0.5000 (0.5004)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2757 (0.4858)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6931 (0.6931)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.5000 (0.5000)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6048  data: 0.5305  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.4948 (0.5014)  roc_auc: 0.5000 (0.5000)  accuracy: 0.4948 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1234  data: 0.0485  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.4961 (0.5014)  roc_auc: 0.5000 (0.5000)  accuracy: 0.4961 (0.5014)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1142  data: 0.0411  max mem: 0
Val: Total time: 0:00:01 (0.1239 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5000)  roc_auc: 0.5000 (0.5000)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6784  data: 0.6042  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6931)  pr_auc: 0.5026 (0.5036)  roc_auc: 0.5000 (0.5005)  accuracy: 0.5000 (0.5033)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1301  data: 0.0552  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5021)  roc_auc: 0.5000 (0.5004)  accuracy: 0.5000 (0.5019)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1176  data: 0.0467  max mem: 0
Test: Total time: 0:00:01 (0.1271 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [8]  [ 0/56]  eta: 0:00:41  lr: 0.000459  min_lr: 0.000002  loss: 0.6935 (0.6935)  class_acc: 0.4844 (0.4844)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2480 (0.2480)  time: 0.7324  data: 0.5708  max mem: 0
Epoch: [8]  [10/56]  eta: 0:00:09  lr: 0.000456  min_lr: 0.000002  loss: 0.6923 (0.6926)  class_acc: 0.5234 (0.5185)  balanced_accuracy: 0.5000 (0.4993)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4267 (0.4029)  time: 0.2131  data: 0.0521  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [8]  [20/56]  eta: 0:00:06  lr: 0.000453  min_lr: 0.000002  loss: 0.6933 (0.6933)  class_acc: 0.5000 (0.5067)  balanced_accuracy: 0.5000 (0.4996)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4790 (0.5218)  time: 0.1612  data: 0.0003  max mem: 0
Epoch: [8]  [30/56]  eta: 0:00:04  lr: 0.000450  min_lr: 0.000002  loss: 0.6938 (0.6935)  class_acc: 0.4844 (0.5033)  balanced_accuracy: 0.5000 (0.5010)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4403 (0.4597)  time: 0.1615  data: 0.0008  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [8]  [40/56]  eta: 0:00:02  lr: 0.000447  min_lr: 0.000002  loss: 0.6931 (0.6933)  class_acc: 0.5078 (0.5063)  balanced_accuracy: 0.5000 (0.4991)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2275 (0.4301)  time: 0.1618  data: 0.0011  max mem: 0
Epoch: [8]  [50/56]  eta: 0:00:01  lr: 0.000444  min_lr: 0.000002  loss: 0.6926 (0.6935)  class_acc: 0.5156 (0.5038)  balanced_accuracy: 0.5000 (0.4992)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2275 (0.4569)  time: 0.1615  data: 0.0010  max mem: 0
Epoch: [8]  [55/56]  eta: 0:00:00  lr: 0.000442  min_lr: 0.000002  loss: 0.6930 (0.6935)  class_acc: 0.5078 (0.5021)  balanced_accuracy: 0.5000 (0.4993)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2269 (0.4618)  time: 0.1616  data: 0.0011  max mem: 0
Epoch: [8] Total time: 0:00:09 (0.1741 s / it)
Averaged stats: lr: 0.000442  min_lr: 0.000002  loss: 0.6930 (0.6935)  class_acc: 0.5078 (0.5021)  balanced_accuracy: 0.5000 (0.4993)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2269 (0.4618)
Val:  [ 0/13]  eta: 0:00:06  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.5000 (0.5000)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5007  data: 0.4255  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4999 (0.5021)  roc_auc: 0.5000 (0.5014)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1156  data: 0.0407  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4999 (0.5021)  roc_auc: 0.5000 (0.5013)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1077  data: 0.0344  max mem: 0
Val: Total time: 0:00:01 (0.1168 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4974 (0.4974)  roc_auc: 0.4948 (0.4948)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6103  data: 0.5359  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5037)  roc_auc: 0.5000 (0.5007)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1242  data: 0.0494  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5022)  roc_auc: 0.5000 (0.5006)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1127  data: 0.0418  max mem: 0
Test: Total time: 0:00:01 (0.1220 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [9]  [ 0/56]  eta: 0:00:39  lr: 0.000442  min_lr: 0.000002  loss: 0.6930 (0.6930)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1809 (0.1809)  time: 0.7003  data: 0.5394  max mem: 0
Epoch: [9]  [10/56]  eta: 0:00:09  lr: 0.000438  min_lr: 0.000002  loss: 0.6930 (0.6930)  class_acc: 0.5234 (0.5170)  balanced_accuracy: 0.5000 (0.4931)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4562 (0.4264)  time: 0.2106  data: 0.0497  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [9]  [20/56]  eta: 0:00:06  lr: 0.000435  min_lr: 0.000002  loss: 0.6931 (0.6933)  class_acc: 0.4922 (0.5060)  balanced_accuracy: 0.5000 (0.4964)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4893 (0.5189)  time: 0.1615  data: 0.0005  max mem: 0
Epoch: [9]  [30/56]  eta: 0:00:04  lr: 0.000431  min_lr: 0.000002  loss: 0.6940 (0.6934)  class_acc: 0.4766 (0.5033)  balanced_accuracy: 0.5000 (0.5008)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4107 (0.4541)  time: 0.1618  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [9]  [40/56]  eta: 0:00:02  lr: 0.000428  min_lr: 0.000002  loss: 0.6927 (0.6931)  class_acc: 0.5156 (0.5118)  balanced_accuracy: 0.5051 (0.5053)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2106 (0.4263)  time: 0.1623  data: 0.0010  max mem: 0
Epoch: [9]  [50/56]  eta: 0:00:01  lr: 0.000424  min_lr: 0.000002  loss: 0.6925 (0.6936)  class_acc: 0.5156 (0.5052)  balanced_accuracy: 0.5051 (0.5009)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2502 (0.4572)  time: 0.1621  data: 0.0010  max mem: 0
Epoch: [9]  [55/56]  eta: 0:00:00  lr: 0.000422  min_lr: 0.000002  loss: 0.6936 (0.6936)  class_acc: 0.5000 (0.5018)  balanced_accuracy: 0.4879 (0.4990)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2693 (0.4619)  time: 0.1620  data: 0.0011  max mem: 0
Epoch: [9] Total time: 0:00:09 (0.1739 s / it)
Averaged stats: lr: 0.000422  min_lr: 0.000002  loss: 0.6936 (0.6936)  class_acc: 0.5000 (0.5018)  balanced_accuracy: 0.4879 (0.4990)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2693 (0.4619)
Val:  [ 0/13]  eta: 0:00:06  loss: 0.6932 (0.6932)  pr_auc: 0.5216 (0.5216)  roc_auc: 0.5290 (0.5290)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5181  data: 0.4435  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5048 (0.5022)  roc_auc: 0.5008 (0.4993)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1164  data: 0.0414  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6931)  pr_auc: 0.5019 (0.5016)  roc_auc: 0.4930 (0.4980)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1084  data: 0.0351  max mem: 0
Val: Total time: 0:00:01 (0.1177 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6931 (0.6931)  pr_auc: 0.4974 (0.4974)  roc_auc: 0.4948 (0.4948)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6335  data: 0.5593  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5027 (0.5035)  roc_auc: 0.5000 (0.4989)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1263  data: 0.0512  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5000 (0.5008)  roc_auc: 0.5000 (0.4963)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1143  data: 0.0434  max mem: 0
Test: Total time: 0:00:01 (0.1239 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [10]  [ 0/56]  eta: 0:00:38  lr: 0.000422  min_lr: 0.000002  loss: 0.6929 (0.6929)  class_acc: 0.5703 (0.5703)  balanced_accuracy: 0.5613 (0.5613)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2142 (0.2142)  time: 0.6941  data: 0.5327  max mem: 0
Epoch: [10]  [10/56]  eta: 0:00:09  lr: 0.000418  min_lr: 0.000002  loss: 0.6928 (0.6928)  class_acc: 0.5391 (0.5277)  balanced_accuracy: 0.5000 (0.5061)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4355 (0.4081)  time: 0.2115  data: 0.0497  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [10]  [20/56]  eta: 0:00:06  lr: 0.000414  min_lr: 0.000002  loss: 0.6931 (0.6932)  class_acc: 0.5078 (0.5115)  balanced_accuracy: 0.5000 (0.5032)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4661 (0.5022)  time: 0.1625  data: 0.0009  max mem: 0
Epoch: [10]  [30/56]  eta: 0:00:04  lr: 0.000410  min_lr: 0.000002  loss: 0.6940 (0.6934)  class_acc: 0.4844 (0.5060)  balanced_accuracy: 0.5000 (0.5022)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4156 (0.4396)  time: 0.1619  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [10]  [40/56]  eta: 0:00:02  lr: 0.000406  min_lr: 0.000002  loss: 0.6932 (0.6933)  class_acc: 0.5000 (0.5036)  balanced_accuracy: 0.5000 (0.5021)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2502 (0.4202)  time: 0.1623  data: 0.0010  max mem: 0
Epoch: [10]  [50/56]  eta: 0:00:01  lr: 0.000402  min_lr: 0.000001  loss: 0.6931 (0.6934)  class_acc: 0.5000 (0.5017)  balanced_accuracy: 0.5000 (0.5017)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3247 (0.4470)  time: 0.1624  data: 0.0010  max mem: 0
Epoch: [10]  [55/56]  eta: 0:00:00  lr: 0.000400  min_lr: 0.000001  loss: 0.6930 (0.6934)  class_acc: 0.5078 (0.5001)  balanced_accuracy: 0.5000 (0.5015)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3325 (0.4503)  time: 0.1623  data: 0.0010  max mem: 0
Epoch: [10] Total time: 0:00:09 (0.1742 s / it)
Averaged stats: lr: 0.000400  min_lr: 0.000001  loss: 0.6930 (0.6934)  class_acc: 0.5078 (0.5001)  balanced_accuracy: 0.5000 (0.5015)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3325 (0.4503)
Val:  [ 0/13]  eta: 0:00:06  loss: 0.6933 (0.6933)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.5000 (0.5000)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.4784  data: 0.4037  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4949 (0.5011)  roc_auc: 0.4999 (0.4993)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1156  data: 0.0406  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4961 (0.5010)  roc_auc: 0.4999 (0.4990)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1076  data: 0.0344  max mem: 0
Val: Total time: 0:00:01 (0.1171 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5000)  roc_auc: 0.5000 (0.5000)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6324  data: 0.5583  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5012 (0.5043)  roc_auc: 0.5000 (0.5017)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1259  data: 0.0509  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5021)  roc_auc: 0.5000 (0.5002)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1141  data: 0.0431  max mem: 0
Test: Total time: 0:00:01 (0.1235 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [11]  [ 0/56]  eta: 0:00:40  lr: 0.000399  min_lr: 0.000001  loss: 0.6930 (0.6930)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1493 (0.1493)  time: 0.7259  data: 0.5642  max mem: 0
Epoch: [11]  [10/56]  eta: 0:00:09  lr: 0.000395  min_lr: 0.000001  loss: 0.6931 (0.6930)  class_acc: 0.5312 (0.5206)  balanced_accuracy: 0.5042 (0.5144)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3741 (0.4299)  time: 0.2131  data: 0.0520  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [11]  [20/56]  eta: 0:00:06  lr: 0.000391  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4922 (0.5078)  balanced_accuracy: 0.5000 (0.5075)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5017 (0.5032)  time: 0.1619  data: 0.0005  max mem: 0
Epoch: [11]  [30/56]  eta: 0:00:04  lr: 0.000387  min_lr: 0.000001  loss: 0.6934 (0.6934)  class_acc: 0.4844 (0.5035)  balanced_accuracy: 0.5000 (0.5051)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4102 (0.4385)  time: 0.1621  data: 0.0006  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [11]  [40/56]  eta: 0:00:02  lr: 0.000382  min_lr: 0.000001  loss: 0.6932 (0.6934)  class_acc: 0.4844 (0.5004)  balanced_accuracy: 0.5000 (0.5028)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2589 (0.4193)  time: 0.1623  data: 0.0010  max mem: 0
Epoch: [11]  [50/56]  eta: 0:00:01  lr: 0.000378  min_lr: 0.000001  loss: 0.6931 (0.6934)  class_acc: 0.5000 (0.4991)  balanced_accuracy: 0.5000 (0.5023)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3213 (0.4448)  time: 0.1622  data: 0.0010  max mem: 0
Epoch: [11]  [55/56]  eta: 0:00:00  lr: 0.000376  min_lr: 0.000001  loss: 0.6931 (0.6934)  class_acc: 0.5078 (0.4976)  balanced_accuracy: 0.5000 (0.5019)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3370 (0.4488)  time: 0.1622  data: 0.0010  max mem: 0
Epoch: [11] Total time: 0:00:09 (0.1746 s / it)
Averaged stats: lr: 0.000376  min_lr: 0.000001  loss: 0.6931 (0.6934)  class_acc: 0.5078 (0.4976)  balanced_accuracy: 0.5000 (0.5019)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3370 (0.4488)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6933 (0.6933)  pr_auc: 0.5140 (0.5140)  roc_auc: 0.5173 (0.5173)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6312  data: 0.5567  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5129 (0.5083)  roc_auc: 0.5117 (0.5133)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1265  data: 0.0513  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5128 (0.5079)  roc_auc: 0.5111 (0.5124)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1169  data: 0.0434  max mem: 0
Val: Total time: 0:00:01 (0.1262 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5218 (0.5218)  roc_auc: 0.5417 (0.5417)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5806  data: 0.5062  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6933)  pr_auc: 0.5059 (0.5057)  roc_auc: 0.5013 (0.5042)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1217  data: 0.0466  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5058 (0.5042)  roc_auc: 0.5013 (0.5042)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1105  data: 0.0395  max mem: 0
Test: Total time: 0:00:01 (0.1195 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [12]  [ 0/56]  eta: 0:00:40  lr: 0.000375  min_lr: 0.000001  loss: 0.6928 (0.6928)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1462 (0.1462)  time: 0.7232  data: 0.5611  max mem: 0
Epoch: [12]  [10/56]  eta: 0:00:09  lr: 0.000371  min_lr: 0.000001  loss: 0.6931 (0.6931)  class_acc: 0.4922 (0.5007)  balanced_accuracy: 0.5011 (0.5079)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3647 (0.4354)  time: 0.2140  data: 0.0522  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [12]  [20/56]  eta: 0:00:06  lr: 0.000366  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4844 (0.4974)  balanced_accuracy: 0.5000 (0.5041)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4659 (0.4946)  time: 0.1627  data: 0.0008  max mem: 0
Epoch: [12]  [30/56]  eta: 0:00:04  lr: 0.000362  min_lr: 0.000001  loss: 0.6934 (0.6933)  class_acc: 0.4844 (0.4965)  balanced_accuracy: 0.5000 (0.5027)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3892 (0.4294)  time: 0.1624  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [12]  [40/56]  eta: 0:00:02  lr: 0.000357  min_lr: 0.000001  loss: 0.6931 (0.6932)  class_acc: 0.4922 (0.4956)  balanced_accuracy: 0.5000 (0.5019)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2677 (0.4120)  time: 0.1626  data: 0.0010  max mem: 0
Epoch: [12]  [50/56]  eta: 0:00:01  lr: 0.000352  min_lr: 0.000001  loss: 0.6930 (0.6933)  class_acc: 0.5000 (0.4951)  balanced_accuracy: 0.4995 (0.5013)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3387 (0.4384)  time: 0.1625  data: 0.0010  max mem: 0
Epoch: [12]  [55/56]  eta: 0:00:00  lr: 0.000350  min_lr: 0.000001  loss: 0.6930 (0.6934)  class_acc: 0.5000 (0.4927)  balanced_accuracy: 0.4928 (0.4996)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3431 (0.4420)  time: 0.1625  data: 0.0010  max mem: 0
Epoch: [12] Total time: 0:00:09 (0.1750 s / it)
Averaged stats: lr: 0.000350  min_lr: 0.000001  loss: 0.6930 (0.6934)  class_acc: 0.5000 (0.4927)  balanced_accuracy: 0.4928 (0.4996)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3431 (0.4420)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6933 (0.6933)  pr_auc: 0.4989 (0.4989)  roc_auc: 0.4781 (0.4781)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6311  data: 0.5563  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5020 (0.5019)  roc_auc: 0.4855 (0.4964)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1264  data: 0.0511  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4989 (0.4996)  roc_auc: 0.4853 (0.4908)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1168  data: 0.0432  max mem: 0
Val: Total time: 0:00:01 (0.1261 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5078 (0.5078)  roc_auc: 0.5150 (0.5150)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6012  data: 0.5263  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5078 (0.5069)  roc_auc: 0.5079 (0.5047)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1235  data: 0.0481  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5078 (0.5070)  roc_auc: 0.5081 (0.5077)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1121  data: 0.0408  max mem: 0
Test: Total time: 0:00:01 (0.1214 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [13]  [ 0/56]  eta: 0:00:36  lr: 0.000349  min_lr: 0.000001  loss: 0.6931 (0.6931)  class_acc: 0.4844 (0.4844)  balanced_accuracy: 0.4712 (0.4712)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1517 (0.1517)  time: 0.6590  data: 0.4962  max mem: 0
Epoch: [13]  [10/56]  eta: 0:00:09  lr: 0.000345  min_lr: 0.000001  loss: 0.6934 (0.6933)  class_acc: 0.4766 (0.4886)  balanced_accuracy: 0.4869 (0.4940)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3593 (0.4327)  time: 0.2087  data: 0.0463  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [13]  [20/56]  eta: 0:00:06  lr: 0.000340  min_lr: 0.000001  loss: 0.6934 (0.6933)  class_acc: 0.4766 (0.4911)  balanced_accuracy: 0.5000 (0.4969)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4542 (0.4900)  time: 0.1631  data: 0.0009  max mem: 0
Epoch: [13]  [30/56]  eta: 0:00:04  lr: 0.000335  min_lr: 0.000001  loss: 0.6935 (0.6933)  class_acc: 0.4844 (0.4922)  balanced_accuracy: 0.5000 (0.4979)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3619 (0.4247)  time: 0.1628  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [13]  [40/56]  eta: 0:00:02  lr: 0.000330  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4922 (0.4893)  balanced_accuracy: 0.5000 (0.4986)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2611 (0.4106)  time: 0.1629  data: 0.0010  max mem: 0
Epoch: [13]  [50/56]  eta: 0:00:01  lr: 0.000325  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4922 (0.4902)  balanced_accuracy: 0.5000 (0.4989)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3287 (0.4362)  time: 0.1628  data: 0.0011  max mem: 0
Epoch: [13]  [55/56]  eta: 0:00:00  lr: 0.000323  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.5000 (0.4897)  balanced_accuracy: 0.5000 (0.4990)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3738 (0.4399)  time: 0.1626  data: 0.0010  max mem: 0
Epoch: [13] Total time: 0:00:09 (0.1741 s / it)
Averaged stats: lr: 0.000323  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.5000 (0.4897)  balanced_accuracy: 0.5000 (0.4990)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3738 (0.4399)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.4895 (0.4895)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6124  data: 0.5378  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5029 (0.5014)  roc_auc: 0.4951 (0.4970)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1245  data: 0.0490  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5025 (0.4999)  roc_auc: 0.4942 (0.4929)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1152  data: 0.0415  max mem: 0
Val: Total time: 0:00:01 (0.1242 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.5052 (0.5052)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6206  data: 0.5459  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5045 (0.5101)  roc_auc: 0.5052 (0.5109)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1253  data: 0.0498  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5039 (0.5080)  roc_auc: 0.5052 (0.5098)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1135  data: 0.0421  max mem: 0
Test: Total time: 0:00:01 (0.1226 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [14]  [ 0/56]  eta: 0:00:33  lr: 0.000322  min_lr: 0.000001  loss: 0.6930 (0.6930)  class_acc: 0.4922 (0.4922)  balanced_accuracy: 0.4778 (0.4778)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1699 (0.1699)  time: 0.6016  data: 0.4384  max mem: 0
Epoch: [14]  [10/56]  eta: 0:00:09  lr: 0.000317  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4837)  balanced_accuracy: 0.4926 (0.4972)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3696 (0.4324)  time: 0.2036  data: 0.0415  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [14]  [20/56]  eta: 0:00:06  lr: 0.000312  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4903)  balanced_accuracy: 0.5000 (0.5002)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4475 (0.4847)  time: 0.1631  data: 0.0011  max mem: 0
Epoch: [14]  [30/56]  eta: 0:00:04  lr: 0.000307  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4844 (0.4914)  balanced_accuracy: 0.5000 (0.4999)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3605 (0.4189)  time: 0.1628  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [14]  [40/56]  eta: 0:00:02  lr: 0.000302  min_lr: 0.000001  loss: 0.6933 (0.6933)  class_acc: 0.4844 (0.4909)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2597 (0.4032)  time: 0.1633  data: 0.0010  max mem: 0
Epoch: [14]  [50/56]  eta: 0:00:01  lr: 0.000297  min_lr: 0.000001  loss: 0.6933 (0.6933)  class_acc: 0.4844 (0.4913)  balanced_accuracy: 0.5000 (0.5001)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3188 (0.4301)  time: 0.1631  data: 0.0010  max mem: 0
Epoch: [14]  [55/56]  eta: 0:00:00  lr: 0.000294  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.5000 (0.4902)  balanced_accuracy: 0.5000 (0.4996)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3641 (0.4352)  time: 0.1629  data: 0.0011  max mem: 0
Epoch: [14] Total time: 0:00:09 (0.1733 s / it)
Averaged stats: lr: 0.000294  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.5000 (0.4902)  balanced_accuracy: 0.5000 (0.4996)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3641 (0.4352)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6933 (0.6933)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.5000 (0.5000)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6205  data: 0.5457  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5076 (0.5072)  roc_auc: 0.5041 (0.5087)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1253  data: 0.0498  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5052 (0.5063)  roc_auc: 0.5000 (0.5039)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1158  data: 0.0422  max mem: 0
Val: Total time: 0:00:01 (0.1252 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5078 (0.5078)  roc_auc: 0.5104 (0.5104)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6259  data: 0.5513  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5072 (0.5072)  roc_auc: 0.5040 (0.5039)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1259  data: 0.0505  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5021 (0.5043)  roc_auc: 0.5002 (0.5009)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1141  data: 0.0428  max mem: 0
Test: Total time: 0:00:01 (0.1235 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [15]  [ 0/56]  eta: 0:00:37  lr: 0.000294  min_lr: 0.000001  loss: 0.6933 (0.6933)  class_acc: 0.5078 (0.5078)  balanced_accuracy: 0.4924 (0.4924)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1671 (0.1671)  time: 0.6761  data: 0.5132  max mem: 0
Epoch: [15]  [10/56]  eta: 0:00:09  lr: 0.000289  min_lr: 0.000001  loss: 0.6933 (0.6933)  class_acc: 0.4766 (0.4808)  balanced_accuracy: 0.4963 (0.4957)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3587 (0.4345)  time: 0.2094  data: 0.0473  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [15]  [20/56]  eta: 0:00:06  lr: 0.000284  min_lr: 0.000001  loss: 0.6934 (0.6933)  class_acc: 0.4766 (0.4870)  balanced_accuracy: 0.5000 (0.4965)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4352 (0.4819)  time: 0.1623  data: 0.0005  max mem: 0
Epoch: [15]  [30/56]  eta: 0:00:04  lr: 0.000278  min_lr: 0.000001  loss: 0.6934 (0.6933)  class_acc: 0.4844 (0.4894)  balanced_accuracy: 0.5000 (0.4976)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3491 (0.4201)  time: 0.1624  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [15]  [40/56]  eta: 0:00:02  lr: 0.000273  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4844 (0.4861)  balanced_accuracy: 0.5000 (0.4969)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2558 (0.4047)  time: 0.1627  data: 0.0010  max mem: 0
Epoch: [15]  [50/56]  eta: 0:00:01  lr: 0.000268  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4844 (0.4876)  balanced_accuracy: 0.5000 (0.4975)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3173 (0.4312)  time: 0.1625  data: 0.0010  max mem: 0
Epoch: [15]  [55/56]  eta: 0:00:00  lr: 0.000266  min_lr: 0.000001  loss: 0.6931 (0.6933)  class_acc: 0.4922 (0.4873)  balanced_accuracy: 0.5000 (0.4977)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3644 (0.4351)  time: 0.1624  data: 0.0010  max mem: 0
Epoch: [15] Total time: 0:00:09 (0.1740 s / it)
Averaged stats: lr: 0.000266  min_lr: 0.000001  loss: 0.6931 (0.6933)  class_acc: 0.4922 (0.4873)  balanced_accuracy: 0.5000 (0.4977)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3644 (0.4351)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.5000 (0.5000)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6222  data: 0.5475  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4948 (0.5014)  roc_auc: 0.5000 (0.5000)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1252  data: 0.0499  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4961 (0.5014)  roc_auc: 0.5000 (0.5000)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1158  data: 0.0423  max mem: 0
Val: Total time: 0:00:01 (0.1253 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5000)  roc_auc: 0.5000 (0.5000)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6052  data: 0.5305  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5033)  roc_auc: 0.5000 (0.5000)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1237  data: 0.0484  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5019)  roc_auc: 0.5000 (0.5000)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1123  data: 0.0410  max mem: 0
Test: Total time: 0:00:01 (0.1217 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [16]  [ 0/56]  eta: 0:00:39  lr: 0.000265  min_lr: 0.000001  loss: 0.6930 (0.6930)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1674 (0.1674)  time: 0.6994  data: 0.5316  max mem: 0
Epoch: [16]  [10/56]  eta: 0:00:09  lr: 0.000260  min_lr: 0.000001  loss: 0.6933 (0.6932)  class_acc: 0.4766 (0.4801)  balanced_accuracy: 0.5000 (0.4969)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3747 (0.4298)  time: 0.2117  data: 0.0487  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [16]  [20/56]  eta: 0:00:06  lr: 0.000255  min_lr: 0.000001  loss: 0.6933 (0.6932)  class_acc: 0.4766 (0.4874)  balanced_accuracy: 0.5000 (0.4988)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4284 (0.4787)  time: 0.1629  data: 0.0004  max mem: 0
Epoch: [16]  [30/56]  eta: 0:00:04  lr: 0.000249  min_lr: 0.000001  loss: 0.6933 (0.6932)  class_acc: 0.4844 (0.4897)  balanced_accuracy: 0.5000 (0.4992)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3405 (0.4137)  time: 0.1632  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [16]  [40/56]  eta: 0:00:02  lr: 0.000244  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4884)  balanced_accuracy: 0.5000 (0.4992)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2546 (0.3982)  time: 0.1635  data: 0.0011  max mem: 0
Epoch: [16]  [50/56]  eta: 0:00:01  lr: 0.000239  min_lr: 0.000001  loss: 0.6931 (0.6933)  class_acc: 0.5000 (0.4890)  balanced_accuracy: 0.5000 (0.4987)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3128 (0.4252)  time: 0.1636  data: 0.0010  max mem: 0
Epoch: [16]  [55/56]  eta: 0:00:00  lr: 0.000237  min_lr: 0.000001  loss: 0.6931 (0.6933)  class_acc: 0.5078 (0.4890)  balanced_accuracy: 0.5019 (0.4992)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3751 (0.4300)  time: 0.1636  data: 0.0010  max mem: 0
Epoch: [16] Total time: 0:00:09 (0.1753 s / it)
Averaged stats: lr: 0.000237  min_lr: 0.000001  loss: 0.6931 (0.6933)  class_acc: 0.5078 (0.4890)  balanced_accuracy: 0.5019 (0.4992)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3751 (0.4300)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5075 (0.5075)  roc_auc: 0.5043 (0.5043)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6561  data: 0.5814  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5047 (0.5038)  roc_auc: 0.5043 (0.5036)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1286  data: 0.0532  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5047 (0.5032)  roc_auc: 0.5043 (0.4999)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1187  data: 0.0450  max mem: 0
Val: Total time: 0:00:01 (0.1279 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5029 (0.5029)  roc_auc: 0.5052 (0.5052)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5794  data: 0.5046  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5059 (0.5063)  roc_auc: 0.5014 (0.5045)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1218  data: 0.0464  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5059 (0.5056)  roc_auc: 0.5014 (0.5058)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1106  data: 0.0393  max mem: 0
Test: Total time: 0:00:01 (0.1199 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [17]  [ 0/56]  eta: 0:00:37  lr: 0.000236  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.5000 (0.5000)  balanced_accuracy: 0.4873 (0.4873)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1742 (0.1742)  time: 0.6649  data: 0.5021  max mem: 0
Epoch: [17]  [10/56]  eta: 0:00:09  lr: 0.000231  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.5000 (0.4929)  balanced_accuracy: 0.5031 (0.5070)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3732 (0.4294)  time: 0.2094  data: 0.0465  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [17]  [20/56]  eta: 0:00:06  lr: 0.000226  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4844 (0.5000)  balanced_accuracy: 0.5000 (0.5087)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4215 (0.4752)  time: 0.1632  data: 0.0008  max mem: 0
Epoch: [17]  [30/56]  eta: 0:00:04  lr: 0.000221  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4844 (0.4982)  balanced_accuracy: 0.5000 (0.5059)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3322 (0.4113)  time: 0.1628  data: 0.0009  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [17]  [40/56]  eta: 0:00:02  lr: 0.000215  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4766 (0.4914)  balanced_accuracy: 0.5000 (0.5020)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2538 (0.3984)  time: 0.1629  data: 0.0011  max mem: 0
Epoch: [17]  [50/56]  eta: 0:00:01  lr: 0.000210  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4766 (0.4919)  balanced_accuracy: 0.5000 (0.5016)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3081 (0.4247)  time: 0.1627  data: 0.0010  max mem: 0
Epoch: [17]  [55/56]  eta: 0:00:00  lr: 0.000208  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4844 (0.4912)  balanced_accuracy: 0.5000 (0.5015)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3793 (0.4291)  time: 0.1627  data: 0.0010  max mem: 0
Epoch: [17] Total time: 0:00:09 (0.1743 s / it)
Averaged stats: lr: 0.000208  min_lr: 0.000001  loss: 0.6932 (0.6933)  class_acc: 0.4844 (0.4912)  balanced_accuracy: 0.5000 (0.5015)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3793 (0.4291)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4999 (0.4999)  roc_auc: 0.4891 (0.4891)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5758  data: 0.5007  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4946 (0.5029)  roc_auc: 0.4995 (0.5018)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1217  data: 0.0462  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4999 (0.5042)  roc_auc: 0.4996 (0.5044)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1129  data: 0.0391  max mem: 0
Val: Total time: 0:00:01 (0.1222 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4877 (0.4877)  roc_auc: 0.4740 (0.4740)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6150  data: 0.5403  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.4974 (0.4947)  roc_auc: 0.4814 (0.4779)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1251  data: 0.0497  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.4940 (0.4928)  roc_auc: 0.4814 (0.4770)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1135  data: 0.0420  max mem: 0
Test: Total time: 0:00:01 (0.1225 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [18]  [ 0/56]  eta: 0:00:38  lr: 0.000207  min_lr: 0.000001  loss: 0.6931 (0.6931)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1828 (0.1828)  time: 0.6820  data: 0.5191  max mem: 0
Epoch: [18]  [10/56]  eta: 0:00:09  lr: 0.000202  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4879)  balanced_accuracy: 0.5000 (0.5012)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3727 (0.4278)  time: 0.2098  data: 0.0476  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [18]  [20/56]  eta: 0:00:06  lr: 0.000197  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4892)  balanced_accuracy: 0.5000 (0.4995)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4112 (0.4768)  time: 0.1627  data: 0.0004  max mem: 0
Epoch: [18]  [30/56]  eta: 0:00:04  lr: 0.000192  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4904)  balanced_accuracy: 0.4978 (0.4991)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3222 (0.4105)  time: 0.1627  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [18]  [40/56]  eta: 0:00:02  lr: 0.000187  min_lr: 0.000001  loss: 0.6933 (0.6933)  class_acc: 0.4766 (0.4836)  balanced_accuracy: 0.4873 (0.4947)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2666 (0.3971)  time: 0.1628  data: 0.0011  max mem: 0
Epoch: [18]  [50/56]  eta: 0:00:01  lr: 0.000182  min_lr: 0.000001  loss: 0.6933 (0.6933)  class_acc: 0.4609 (0.4847)  balanced_accuracy: 0.5000 (0.4949)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3100 (0.4246)  time: 0.1626  data: 0.0011  max mem: 0
Epoch: [18]  [55/56]  eta: 0:00:00  lr: 0.000179  min_lr: 0.000001  loss: 0.6933 (0.6933)  class_acc: 0.4531 (0.4847)  balanced_accuracy: 0.5000 (0.4953)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3875 (0.4284)  time: 0.1625  data: 0.0011  max mem: 0
Epoch: [18] Total time: 0:00:09 (0.1743 s / it)
Averaged stats: lr: 0.000179  min_lr: 0.000001  loss: 0.6933 (0.6933)  class_acc: 0.4531 (0.4847)  balanced_accuracy: 0.5000 (0.4953)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3875 (0.4284)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5013 (0.5013)  roc_auc: 0.4921 (0.4921)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6099  data: 0.5351  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5035 (0.5082)  roc_auc: 0.5020 (0.5117)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1253  data: 0.0499  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5035 (0.5086)  roc_auc: 0.5020 (0.5125)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1159  data: 0.0422  max mem: 0
Val: Total time: 0:00:01 (0.1254 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4949 (0.4949)  roc_auc: 0.4896 (0.4896)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6121  data: 0.5374  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.4949 (0.4985)  roc_auc: 0.4864 (0.4889)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1251  data: 0.0495  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.4949 (0.4982)  roc_auc: 0.4864 (0.4911)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1134  data: 0.0420  max mem: 0
Test: Total time: 0:00:01 (0.1225 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.48%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [19]  [ 0/56]  eta: 0:00:39  lr: 0.000179  min_lr: 0.000001  loss: 0.6929 (0.6929)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1916 (0.1916)  time: 0.7030  data: 0.5406  max mem: 0
Epoch: [19]  [10/56]  eta: 0:00:09  lr: 0.000174  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4886)  balanced_accuracy: 0.5042 (0.5029)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3760 (0.4254)  time: 0.2116  data: 0.0493  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [19]  [20/56]  eta: 0:00:06  lr: 0.000169  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4922)  balanced_accuracy: 0.5000 (0.5018)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4089 (0.4706)  time: 0.1624  data: 0.0004  max mem: 0
Epoch: [19]  [30/56]  eta: 0:00:04  lr: 0.000164  min_lr: 0.000001  loss: 0.6933 (0.6932)  class_acc: 0.4844 (0.4929)  balanced_accuracy: 0.5000 (0.5012)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3225 (0.4067)  time: 0.1628  data: 0.0008  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [19]  [40/56]  eta: 0:00:02  lr: 0.000159  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4884)  balanced_accuracy: 0.5000 (0.4992)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2654 (0.3930)  time: 0.1632  data: 0.0011  max mem: 0
Epoch: [19]  [50/56]  eta: 0:00:01  lr: 0.000155  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4900)  balanced_accuracy: 0.5000 (0.5001)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3034 (0.4206)  time: 0.1630  data: 0.0011  max mem: 0
Epoch: [19]  [55/56]  eta: 0:00:00  lr: 0.000152  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4895)  balanced_accuracy: 0.5000 (0.5001)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3808 (0.4248)  time: 0.1628  data: 0.0011  max mem: 0
Epoch: [19] Total time: 0:00:09 (0.1749 s / it)
Averaged stats: lr: 0.000152  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4895)  balanced_accuracy: 0.5000 (0.5001)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3808 (0.4248)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.5000 (0.5000)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6092  data: 0.5342  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4973 (0.5017)  roc_auc: 0.5000 (0.5005)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1245  data: 0.0491  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4973 (0.5017)  roc_auc: 0.5000 (0.5004)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1153  data: 0.0416  max mem: 0
Val: Total time: 0:00:01 (0.1243 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4974 (0.4974)  roc_auc: 0.4948 (0.4948)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6064  data: 0.5318  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5026 (0.5032)  roc_auc: 0.5000 (0.4996)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1243  data: 0.0488  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5017)  roc_auc: 0.5000 (0.4996)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1128  data: 0.0413  max mem: 0
Test: Total time: 0:00:01 (0.1219 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [20]  [ 0/56]  eta: 0:00:40  lr: 0.000152  min_lr: 0.000001  loss: 0.6930 (0.6930)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1904 (0.1904)  time: 0.7216  data: 0.5592  max mem: 0
Epoch: [20]  [10/56]  eta: 0:00:09  lr: 0.000147  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4872)  balanced_accuracy: 0.5000 (0.5045)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3787 (0.4267)  time: 0.2152  data: 0.0522  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [20]  [20/56]  eta: 0:00:06  lr: 0.000142  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4926)  balanced_accuracy: 0.5000 (0.5019)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4075 (0.4687)  time: 0.1635  data: 0.0009  max mem: 0
Epoch: [20]  [30/56]  eta: 0:00:04  lr: 0.000138  min_lr: 0.000001  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4927)  balanced_accuracy: 0.5000 (0.5010)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3117 (0.4051)  time: 0.1629  data: 0.0008  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [20]  [40/56]  eta: 0:00:02  lr: 0.000133  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4899)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2733 (0.3913)  time: 0.1633  data: 0.0011  max mem: 0
Epoch: [20]  [50/56]  eta: 0:00:01  lr: 0.000128  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4897)  balanced_accuracy: 0.5000 (0.4992)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3039 (0.4197)  time: 0.1630  data: 0.0011  max mem: 0
Epoch: [20]  [55/56]  eta: 0:00:00  lr: 0.000126  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.5000 (0.4891)  balanced_accuracy: 0.5000 (0.4991)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3825 (0.4248)  time: 0.1628  data: 0.0010  max mem: 0
Epoch: [20] Total time: 0:00:09 (0.1756 s / it)
Averaged stats: lr: 0.000126  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.5000 (0.4891)  balanced_accuracy: 0.5000 (0.4991)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3825 (0.4248)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5052)  roc_auc: 0.4947 (0.4947)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6475  data: 0.5724  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4985 (0.5073)  roc_auc: 0.5055 (0.5081)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1281  data: 0.0526  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.4985 (0.5066)  roc_auc: 0.5054 (0.5070)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1182  data: 0.0445  max mem: 0
Val: Total time: 0:00:01 (0.1274 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5000)  roc_auc: 0.4844 (0.4844)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6118  data: 0.5369  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5041)  roc_auc: 0.5000 (0.4986)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1245  data: 0.0490  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5000 (0.5026)  roc_auc: 0.5000 (0.4987)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1130  data: 0.0415  max mem: 0
Test: Total time: 0:00:01 (0.1221 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [21]  [ 0/56]  eta: 0:00:40  lr: 0.000126  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5078 (0.5078)  balanced_accuracy: 0.4924 (0.4924)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1763 (0.1763)  time: 0.7207  data: 0.5589  max mem: 0
Epoch: [21]  [10/56]  eta: 0:00:09  lr: 0.000121  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4844 (0.4851)  balanced_accuracy: 0.4926 (0.4994)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3740 (0.4281)  time: 0.2138  data: 0.0514  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [21]  [20/56]  eta: 0:00:06  lr: 0.000117  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4877)  balanced_accuracy: 0.4926 (0.4954)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4001 (0.4694)  time: 0.1630  data: 0.0006  max mem: 0
Epoch: [21]  [30/56]  eta: 0:00:04  lr: 0.000113  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4904)  balanced_accuracy: 0.4955 (0.4971)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3084 (0.4047)  time: 0.1631  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [21]  [40/56]  eta: 0:00:02  lr: 0.000108  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4766 (0.4872)  balanced_accuracy: 0.5017 (0.4968)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2809 (0.3918)  time: 0.1632  data: 0.0009  max mem: 0
Epoch: [21]  [50/56]  eta: 0:00:01  lr: 0.000104  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4766 (0.4907)  balanced_accuracy: 0.5054 (0.4999)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3035 (0.4197)  time: 0.1631  data: 0.0011  max mem: 0
Epoch: [21]  [55/56]  eta: 0:00:00  lr: 0.000102  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4766 (0.4902)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3816 (0.4243)  time: 0.1630  data: 0.0011  max mem: 0
Epoch: [21] Total time: 0:00:09 (0.1754 s / it)
Averaged stats: lr: 0.000102  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4766 (0.4902)  balanced_accuracy: 0.5000 (0.5000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3816 (0.4243)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5026 (0.5026)  roc_auc: 0.4948 (0.4948)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6393  data: 0.5645  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5026 (0.5027)  roc_auc: 0.5000 (0.5019)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1272  data: 0.0517  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5026 (0.5028)  roc_auc: 0.5000 (0.5020)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1175  data: 0.0438  max mem: 0
Val: Total time: 0:00:01 (0.1267 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.4948 (0.4948)  roc_auc: 0.4845 (0.4845)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6866  data: 0.6120  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5052 (0.5064)  roc_auc: 0.5001 (0.5054)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1312  data: 0.0558  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5052 (0.5044)  roc_auc: 0.5000 (0.5044)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1186  data: 0.0472  max mem: 0
Test: Total time: 0:00:01 (0.1276 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [22]  [ 0/56]  eta: 0:00:42  lr: 0.000102  min_lr: 0.000000  loss: 0.6930 (0.6930)  class_acc: 0.5312 (0.5312)  balanced_accuracy: 0.5161 (0.5161)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1853 (0.1853)  time: 0.7598  data: 0.5970  max mem: 0
Epoch: [22]  [10/56]  eta: 0:00:09  lr: 0.000097  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4972)  balanced_accuracy: 0.5161 (0.5104)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3907 (0.4240)  time: 0.2169  data: 0.0546  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [22]  [20/56]  eta: 0:00:06  lr: 0.000093  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.5019)  balanced_accuracy: 0.5071 (0.5105)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4057 (0.4672)  time: 0.1624  data: 0.0004  max mem: 0
Epoch: [22]  [30/56]  eta: 0:00:04  lr: 0.000089  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4844 (0.4990)  balanced_accuracy: 0.5000 (0.5066)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3080 (0.4043)  time: 0.1628  data: 0.0008  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [22]  [40/56]  eta: 0:00:02  lr: 0.000085  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4844 (0.4950)  balanced_accuracy: 0.5000 (0.5049)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2838 (0.3916)  time: 0.1631  data: 0.0011  max mem: 0
Epoch: [22]  [50/56]  eta: 0:00:01  lr: 0.000082  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4688 (0.4920)  balanced_accuracy: 0.4990 (0.5014)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3002 (0.4201)  time: 0.1630  data: 0.0010  max mem: 0
Epoch: [22]  [55/56]  eta: 0:00:00  lr: 0.000080  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4844 (0.4918)  balanced_accuracy: 0.4973 (0.5017)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3865 (0.4247)  time: 0.1629  data: 0.0011  max mem: 0
Epoch: [22] Total time: 0:00:09 (0.1759 s / it)
Averaged stats: lr: 0.000080  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4844 (0.4918)  balanced_accuracy: 0.4973 (0.5017)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3865 (0.4247)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4907 (0.4907)  roc_auc: 0.4691 (0.4691)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5952  data: 0.5204  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5095 (0.5092)  roc_auc: 0.4981 (0.5107)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1234  data: 0.0479  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5095 (0.5095)  roc_auc: 0.4981 (0.5118)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1143  data: 0.0406  max mem: 0
Val: Total time: 0:00:01 (0.1238 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.4958 (0.4958)  roc_auc: 0.4913 (0.4913)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6187  data: 0.5440  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5042 (0.5055)  roc_auc: 0.5008 (0.5027)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1251  data: 0.0497  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5014 (0.5037)  roc_auc: 0.5008 (0.5015)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1135  data: 0.0421  max mem: 0
Test: Total time: 0:00:01 (0.1227 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [23]  [ 0/56]  eta: 0:00:37  lr: 0.000079  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5034 (0.5034)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1905 (0.1905)  time: 0.6731  data: 0.5112  max mem: 0
Epoch: [23]  [10/56]  eta: 0:00:09  lr: 0.000076  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5000 (0.4901)  balanced_accuracy: 0.4902 (0.4988)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3818 (0.4249)  time: 0.2093  data: 0.0471  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [23]  [20/56]  eta: 0:00:06  lr: 0.000072  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4937)  balanced_accuracy: 0.4953 (0.5010)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4028 (0.4668)  time: 0.1629  data: 0.0007  max mem: 0
Epoch: [23]  [30/56]  eta: 0:00:04  lr: 0.000068  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4945)  balanced_accuracy: 0.5000 (0.5013)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3015 (0.4037)  time: 0.1628  data: 0.0008  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [23]  [40/56]  eta: 0:00:02  lr: 0.000065  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4766 (0.4901)  balanced_accuracy: 0.4940 (0.4995)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2860 (0.3921)  time: 0.1629  data: 0.0010  max mem: 0
Epoch: [23]  [50/56]  eta: 0:00:01  lr: 0.000061  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4766 (0.4896)  balanced_accuracy: 0.4844 (0.4985)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3144 (0.4202)  time: 0.1627  data: 0.0011  max mem: 0
Epoch: [23]  [55/56]  eta: 0:00:00  lr: 0.000060  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4891)  balanced_accuracy: 0.4862 (0.4982)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3824 (0.4246)  time: 0.1626  data: 0.0010  max mem: 0
Epoch: [23] Total time: 0:00:09 (0.1743 s / it)
Averaged stats: lr: 0.000060  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4891)  balanced_accuracy: 0.4862 (0.4982)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3824 (0.4246)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5049 (0.5049)  roc_auc: 0.4992 (0.4992)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6202  data: 0.5453  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5074 (0.5085)  roc_auc: 0.5038 (0.5118)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1254  data: 0.0500  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5074 (0.5094)  roc_auc: 0.5038 (0.5136)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1159  data: 0.0423  max mem: 0
Val: Total time: 0:00:01 (0.1252 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.4953 (0.4953)  roc_auc: 0.4907 (0.4907)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6435  data: 0.5687  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5128 (0.5132)  roc_auc: 0.5117 (0.5144)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1274  data: 0.0518  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5112 (0.5111)  roc_auc: 0.5117 (0.5132)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1153  data: 0.0439  max mem: 0
Test: Total time: 0:00:01 (0.1249 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.49%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [24]  [ 0/56]  eta: 0:00:39  lr: 0.000059  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4531 (0.4531)  balanced_accuracy: 0.4413 (0.4413)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1898 (0.1898)  time: 0.7071  data: 0.5451  max mem: 0
Epoch: [24]  [10/56]  eta: 0:00:09  lr: 0.000056  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4922 (0.4851)  balanced_accuracy: 0.4968 (0.4943)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3923 (0.4242)  time: 0.2129  data: 0.0506  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [24]  [20/56]  eta: 0:00:06  lr: 0.000053  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4922 (0.4911)  balanced_accuracy: 0.4993 (0.4976)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4047 (0.4671)  time: 0.1633  data: 0.0010  max mem: 0
Epoch: [24]  [30/56]  eta: 0:00:04  lr: 0.000050  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4922 (0.4955)  balanced_accuracy: 0.5048 (0.5015)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3074 (0.4039)  time: 0.1633  data: 0.0009  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [24]  [40/56]  eta: 0:00:02  lr: 0.000047  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4922 (0.4956)  balanced_accuracy: 0.5048 (0.5044)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2888 (0.3908)  time: 0.1634  data: 0.0010  max mem: 0
Epoch: [24]  [50/56]  eta: 0:00:01  lr: 0.000044  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4951)  balanced_accuracy: 0.5069 (0.5037)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3005 (0.4189)  time: 0.1630  data: 0.0010  max mem: 0
Epoch: [24]  [55/56]  eta: 0:00:00  lr: 0.000042  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5156 (0.4964)  balanced_accuracy: 0.5127 (0.5051)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3906 (0.4240)  time: 0.1629  data: 0.0010  max mem: 0
Epoch: [24] Total time: 0:00:09 (0.1752 s / it)
Averaged stats: lr: 0.000042  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5156 (0.4964)  balanced_accuracy: 0.5127 (0.5051)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3906 (0.4240)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6931 (0.6931)  pr_auc: 0.5095 (0.5095)  roc_auc: 0.5076 (0.5076)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6559  data: 0.5762  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5100 (0.5132)  roc_auc: 0.5122 (0.5182)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1310  data: 0.0525  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5104 (0.5136)  roc_auc: 0.5122 (0.5196)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1208  data: 0.0445  max mem: 0
Val: Total time: 0:00:01 (0.1302 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4960 (0.4960)  roc_auc: 0.4902 (0.4902)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.5927  data: 0.5181  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6932 (0.6932)  pr_auc: 0.5085 (0.5111)  roc_auc: 0.5010 (0.5118)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1228  data: 0.0473  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5074 (0.5088)  roc_auc: 0.5010 (0.5102)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1115  data: 0.0401  max mem: 0
Test: Total time: 0:00:01 (0.1208 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.51%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [25]  [ 0/56]  eta: 0:00:39  lr: 0.000042  min_lr: 0.000000  loss: 0.6930 (0.6930)  class_acc: 0.5234 (0.5234)  balanced_accuracy: 0.5144 (0.5144)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2067 (0.2067)  time: 0.7065  data: 0.5435  max mem: 0
Epoch: [25]  [10/56]  eta: 0:00:09  lr: 0.000039  min_lr: 0.000000  loss: 0.6930 (0.6931)  class_acc: 0.5234 (0.5085)  balanced_accuracy: 0.5144 (0.5160)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3870 (0.4267)  time: 0.2129  data: 0.0503  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [25]  [20/56]  eta: 0:00:06  lr: 0.000037  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5156 (0.5093)  balanced_accuracy: 0.5251 (0.5164)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3938 (0.4679)  time: 0.1630  data: 0.0007  max mem: 0
Epoch: [25]  [30/56]  eta: 0:00:04  lr: 0.000034  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5000 (0.5076)  balanced_accuracy: 0.5088 (0.5138)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3015 (0.4051)  time: 0.1630  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [25]  [40/56]  eta: 0:00:02  lr: 0.000031  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.4922 (0.5029)  balanced_accuracy: 0.4963 (0.5113)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2868 (0.3907)  time: 0.1635  data: 0.0011  max mem: 0
Epoch: [25]  [50/56]  eta: 0:00:01  lr: 0.000029  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.4922 (0.4992)  balanced_accuracy: 0.4954 (0.5070)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2956 (0.4201)  time: 0.1632  data: 0.0010  max mem: 0
Epoch: [25]  [55/56]  eta: 0:00:00  lr: 0.000028  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.4922 (0.5022)  balanced_accuracy: 0.4966 (0.5102)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3821 (0.4250)  time: 0.1631  data: 0.0011  max mem: 0
Epoch: [25] Total time: 0:00:09 (0.1753 s / it)
Averaged stats: lr: 0.000028  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.4922 (0.5022)  balanced_accuracy: 0.4966 (0.5102)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3821 (0.4250)
Val:  [ 0/13]  eta: 0:00:06  loss: 0.6931 (0.6931)  pr_auc: 0.5384 (0.5384)  roc_auc: 0.5354 (0.5354)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.5000 (0.5000)  time: 0.4656  data: 0.3899  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5212 (0.5181)  roc_auc: 0.5134 (0.5211)  accuracy: 0.5052 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1198  data: 0.0443  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5212 (0.5188)  roc_auc: 0.5227 (0.5237)  accuracy: 0.5039 (0.4986)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1113  data: 0.0376  max mem: 0
Val: Total time: 0:00:01 (0.1204 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4883 (0.4883)  roc_auc: 0.4742 (0.4742)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5000 (0.5000)  time: 0.6149  data: 0.5400  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6932)  pr_auc: 0.5111 (0.5122)  roc_auc: 0.5136 (0.5144)  accuracy: 0.5000 (0.4967)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1248  data: 0.0492  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5078 (0.5108)  roc_auc: 0.5136 (0.5137)  accuracy: 0.5000 (0.4981)  balanced_accuracy: 0.5000 (0.5000)  time: 0.1132  data: 0.0417  max mem: 0
Test: Total time: 0:00:01 (0.1225 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.51%
Max balanced_accuracy val:0.50%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [26]  [ 0/56]  eta: 0:00:39  lr: 0.000028  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5234 (0.5234)  balanced_accuracy: 0.5159 (0.5159)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2017 (0.2017)  time: 0.7090  data: 0.5453  max mem: 0
Epoch: [26]  [10/56]  eta: 0:00:09  lr: 0.000025  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.5000 (0.5036)  balanced_accuracy: 0.5064 (0.5073)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3897 (0.4248)  time: 0.2138  data: 0.0510  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [26]  [20/56]  eta: 0:00:06  lr: 0.000023  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4922 (0.5041)  balanced_accuracy: 0.5038 (0.5089)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3897 (0.4664)  time: 0.1638  data: 0.0010  max mem: 0
Epoch: [26]  [30/56]  eta: 0:00:04  lr: 0.000021  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.4922 (0.4992)  balanced_accuracy: 0.4990 (0.5041)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2969 (0.4033)  time: 0.1635  data: 0.0007  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [26]  [40/56]  eta: 0:00:02  lr: 0.000019  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5000 (0.4996)  balanced_accuracy: 0.5037 (0.5062)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2944 (0.3905)  time: 0.1638  data: 0.0011  max mem: 0
Epoch: [26]  [50/56]  eta: 0:00:01  lr: 0.000017  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5000 (0.4982)  balanced_accuracy: 0.5078 (0.5044)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3044 (0.4185)  time: 0.1636  data: 0.0011  max mem: 0
Epoch: [26]  [55/56]  eta: 0:00:00  lr: 0.000016  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4987)  balanced_accuracy: 0.4917 (0.5049)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3916 (0.4239)  time: 0.1636  data: 0.0012  max mem: 0
Epoch: [26] Total time: 0:00:09 (0.1759 s / it)
Averaged stats: lr: 0.000016  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4987)  balanced_accuracy: 0.4917 (0.5049)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3916 (0.4239)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6931 (0.6931)  pr_auc: 0.5112 (0.5112)  roc_auc: 0.5036 (0.5036)  accuracy: 0.5000 (0.5000)  balanced_accuracy: 0.5052 (0.5052)  time: 0.6065  data: 0.5314  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5296 (0.5252)  roc_auc: 0.5201 (0.5307)  accuracy: 0.5104 (0.5142)  balanced_accuracy: 0.5063 (0.5159)  time: 0.1243  data: 0.0486  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5296 (0.5254)  roc_auc: 0.5251 (0.5321)  accuracy: 0.5104 (0.5101)  balanced_accuracy: 0.5054 (0.5118)  time: 0.1150  data: 0.0412  max mem: 0
Val: Total time: 0:00:01 (0.1243 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.51%, balanced_accuracy:0.51%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5064 (0.5064)  roc_auc: 0.5111 (0.5111)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.4948 (0.4948)  time: 0.5953  data: 0.5204  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5071 (0.5139)  roc_auc: 0.5103 (0.5163)  accuracy: 0.4948 (0.4962)  balanced_accuracy: 0.5000 (0.4995)  time: 0.1231  data: 0.0476  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5070 (0.5120)  roc_auc: 0.5103 (0.5156)  accuracy: 0.5000 (0.4977)  balanced_accuracy: 0.5000 (0.4996)  time: 0.1117  data: 0.0403  max mem: 0
Test: Total time: 0:00:01 (0.1209 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.51%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [27]  [ 0/56]  eta: 0:00:37  lr: 0.000016  min_lr: 0.000000  loss: 0.6930 (0.6930)  class_acc: 0.5625 (0.5625)  balanced_accuracy: 0.5611 (0.5611)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1944 (0.1944)  time: 0.6766  data: 0.5145  max mem: 0
Epoch: [27]  [10/56]  eta: 0:00:09  lr: 0.000014  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5391 (0.5128)  balanced_accuracy: 0.5412 (0.5138)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3963 (0.4263)  time: 0.2096  data: 0.0474  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [27]  [20/56]  eta: 0:00:06  lr: 0.000013  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5078 (0.5026)  balanced_accuracy: 0.5088 (0.5067)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3963 (0.4676)  time: 0.1627  data: 0.0005  max mem: 0
Epoch: [27]  [30/56]  eta: 0:00:04  lr: 0.000011  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4844 (0.4980)  balanced_accuracy: 0.4897 (0.5020)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2988 (0.4042)  time: 0.1629  data: 0.0008  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [27]  [40/56]  eta: 0:00:02  lr: 0.000010  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5000 (0.4994)  balanced_accuracy: 0.5049 (0.5050)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2915 (0.3900)  time: 0.1633  data: 0.0011  max mem: 0
Epoch: [27]  [50/56]  eta: 0:00:01  lr: 0.000008  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.4922 (0.4934)  balanced_accuracy: 0.5015 (0.4981)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2970 (0.4178)  time: 0.1631  data: 0.0012  max mem: 0
Epoch: [27]  [55/56]  eta: 0:00:00  lr: 0.000008  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5000 (0.4961)  balanced_accuracy: 0.5015 (0.5003)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3908 (0.4229)  time: 0.1629  data: 0.0011  max mem: 0
Epoch: [27] Total time: 0:00:09 (0.1745 s / it)
Averaged stats: lr: 0.000008  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5000 (0.4961)  balanced_accuracy: 0.5015 (0.5003)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3908 (0.4229)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6931 (0.6931)  pr_auc: 0.5073 (0.5073)  roc_auc: 0.5051 (0.5051)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.4982 (0.4982)  time: 0.6155  data: 0.5404  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5161 (0.5122)  roc_auc: 0.5070 (0.5180)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5001 (0.5057)  time: 0.1254  data: 0.0499  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5161 (0.5127)  roc_auc: 0.5130 (0.5194)  accuracy: 0.5052 (0.5039)  balanced_accuracy: 0.5001 (0.5047)  time: 0.1160  data: 0.0422  max mem: 0
Val: Total time: 0:00:01 (0.1254 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.50%, balanced_accuracy:0.50%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.4885 (0.4885)  roc_auc: 0.4783 (0.4783)  accuracy: 0.4740 (0.4740)  balanced_accuracy: 0.4740 (0.4740)  time: 0.5619  data: 0.4861  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5100 (0.5088)  roc_auc: 0.5101 (0.5082)  accuracy: 0.4896 (0.4986)  balanced_accuracy: 0.5000 (0.5013)  time: 0.1203  data: 0.0449  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5074 (0.5076)  roc_auc: 0.5116 (0.5090)  accuracy: 0.5052 (0.4998)  balanced_accuracy: 0.5052 (0.5021)  time: 0.1093  data: 0.0380  max mem: 0
Test: Total time: 0:00:01 (0.1187 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.50%, balanced_accuracy:0.50%
Max balanced_accuracy val:0.51%,  balanced_accuracy train: 0.50% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [28]  [ 0/56]  eta: 0:00:39  lr: 0.000008  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5078 (0.5078)  balanced_accuracy: 0.5071 (0.5071)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2016 (0.2016)  time: 0.7129  data: 0.5508  max mem: 0
Epoch: [28]  [10/56]  eta: 0:00:09  lr: 0.000007  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5078 (0.5241)  balanced_accuracy: 0.5071 (0.5204)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3942 (0.4238)  time: 0.2131  data: 0.0508  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [28]  [20/56]  eta: 0:00:06  lr: 0.000006  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5156 (0.5164)  balanced_accuracy: 0.5071 (0.5150)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3942 (0.4661)  time: 0.1630  data: 0.0006  max mem: 0
Epoch: [28]  [30/56]  eta: 0:00:04  lr: 0.000005  min_lr: 0.000000  loss: 0.6932 (0.6932)  class_acc: 0.5078 (0.5076)  balanced_accuracy: 0.4946 (0.5072)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2995 (0.4031)  time: 0.1632  data: 0.0008  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [28]  [40/56]  eta: 0:00:02  lr: 0.000004  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5156 (0.5112)  balanced_accuracy: 0.5188 (0.5131)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2967 (0.3900)  time: 0.1634  data: 0.0012  max mem: 0
Epoch: [28]  [50/56]  eta: 0:00:01  lr: 0.000003  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5156 (0.5113)  balanced_accuracy: 0.5197 (0.5124)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2973 (0.4182)  time: 0.1632  data: 0.0011  max mem: 0
Epoch: [28]  [55/56]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5156 (0.5113)  balanced_accuracy: 0.5092 (0.5119)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3875 (0.4238)  time: 0.1631  data: 0.0011  max mem: 0
Epoch: [28] Total time: 0:00:09 (0.1753 s / it)
Averaged stats: lr: 0.000003  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5156 (0.5113)  balanced_accuracy: 0.5092 (0.5119)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3875 (0.4238)
Val:  [ 0/13]  eta: 0:00:07  loss: 0.6931 (0.6931)  pr_auc: 0.5055 (0.5055)  roc_auc: 0.5013 (0.5013)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.4964 (0.4964)  time: 0.5906  data: 0.5151  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5121 (0.5163)  roc_auc: 0.5063 (0.5215)  accuracy: 0.5052 (0.5166)  balanced_accuracy: 0.5047 (0.5164)  time: 0.1231  data: 0.0475  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5141 (0.5178)  roc_auc: 0.5109 (0.5252)  accuracy: 0.5104 (0.5187)  balanced_accuracy: 0.5114 (0.5188)  time: 0.1141  data: 0.0403  max mem: 0
Val: Total time: 0:00:01 (0.1233 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.52%, balanced_accuracy:0.52%
Test:  [ 0/13]  eta: 0:00:08  loss: 0.6932 (0.6932)  pr_auc: 0.5033 (0.5033)  roc_auc: 0.5068 (0.5068)  accuracy: 0.4948 (0.4948)  balanced_accuracy: 0.4948 (0.4948)  time: 0.6558  data: 0.5808  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5132 (0.5124)  roc_auc: 0.5068 (0.5143)  accuracy: 0.4948 (0.5014)  balanced_accuracy: 0.4996 (0.5039)  time: 0.1289  data: 0.0533  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5080 (0.5104)  roc_auc: 0.5068 (0.5131)  accuracy: 0.4948 (0.5011)  balanced_accuracy: 0.4996 (0.5034)  time: 0.1166  data: 0.0451  max mem: 0
Test: Total time: 0:00:01 (0.1256 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.50%, balanced_accuracy:0.50%
Accuracy of the network on the 7210 train EEG: 0.51%, balanced_accuracy:0.51%
Max balanced_accuracy val:0.52%,  balanced_accuracy train: 0.51% balanced_accuracy test: 0.50%
[SANITY] step=0 min=-43.88 max=13.7 mean=-6.985e-12 std=0.2264
Epoch: [29]  [ 0/56]  eta: 0:00:35  lr: 0.000003  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5391 (0.5391)  balanced_accuracy: 0.5428 (0.5428)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1990 (0.1990)  time: 0.6320  data: 0.4690  max mem: 0
Epoch: [29]  [10/56]  eta: 0:00:09  lr: 0.000002  min_lr: 0.000000  loss: 0.6931 (0.6932)  class_acc: 0.5078 (0.5149)  balanced_accuracy: 0.4991 (0.5106)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3964 (0.4244)  time: 0.2056  data: 0.0438  max mem: 0
[SANITY] step=20 min=-31.55 max=9.957 mean=3.725e-11 std=0.1878
Epoch: [29]  [20/56]  eta: 0:00:06  lr: 0.000002  min_lr: 0.000000  loss: 0.6932 (0.6931)  class_acc: 0.5078 (0.5219)  balanced_accuracy: 0.5088 (0.5211)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3973 (0.4678)  time: 0.1628  data: 0.0009  max mem: 0
Epoch: [29]  [30/56]  eta: 0:00:04  lr: 0.000001  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5234 (0.5202)  balanced_accuracy: 0.5347 (0.5202)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2976 (0.4036)  time: 0.1628  data: 0.0006  max mem: 0
[SANITY] step=40 min=-70.11 max=13.58 mean=-2.328e-11 std=0.2754
Epoch: [29]  [40/56]  eta: 0:00:02  lr: 0.000001  min_lr: 0.000000  loss: 0.6930 (0.6931)  class_acc: 0.5156 (0.5170)  balanced_accuracy: 0.5147 (0.5190)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2884 (0.3910)  time: 0.1628  data: 0.0009  max mem: 0
Epoch: [29]  [50/56]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.5000 (0.5152)  balanced_accuracy: 0.5093 (0.5167)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3027 (0.4191)  time: 0.1628  data: 0.0011  max mem: 0
Epoch: [29]  [55/56]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.4922 (0.5142)  balanced_accuracy: 0.4947 (0.5150)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3942 (0.4240)  time: 0.1628  data: 0.0011  max mem: 0
Epoch: [29] Total time: 0:00:09 (0.1736 s / it)
Averaged stats: lr: 0.000001  min_lr: 0.000000  loss: 0.6931 (0.6931)  class_acc: 0.4922 (0.5142)  balanced_accuracy: 0.4947 (0.5150)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3942 (0.4240)
Val:  [ 0/13]  eta: 0:00:08  loss: 0.6931 (0.6931)  pr_auc: 0.5088 (0.5088)  roc_auc: 0.5065 (0.5065)  accuracy: 0.5052 (0.5052)  balanced_accuracy: 0.5065 (0.5065)  time: 0.6610  data: 0.5859  max mem: 0
Val:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5114 (0.5123)  roc_auc: 0.5119 (0.5147)  accuracy: 0.5052 (0.5095)  balanced_accuracy: 0.5065 (0.5092)  time: 0.1293  data: 0.0537  max mem: 0
Val:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5184 (0.5147)  roc_auc: 0.5198 (0.5201)  accuracy: 0.5156 (0.5125)  balanced_accuracy: 0.5165 (0.5126)  time: 0.1193  data: 0.0455  max mem: 0
Val: Total time: 0:00:01 (0.1287 s / it)
* loss 0.693
Accuracy of the network on the 2431 val EEG: 0.51%, balanced_accuracy:0.51%
Test:  [ 0/13]  eta: 0:00:07  loss: 0.6932 (0.6932)  pr_auc: 0.5156 (0.5156)  roc_auc: 0.5273 (0.5273)  accuracy: 0.5156 (0.5156)  balanced_accuracy: 0.5156 (0.5156)  time: 0.6131  data: 0.5382  max mem: 0
Test:  [10/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5159 (0.5147)  roc_auc: 0.5205 (0.5183)  accuracy: 0.5104 (0.5090)  balanced_accuracy: 0.5104 (0.5114)  time: 0.1251  data: 0.0496  max mem: 0
Test:  [12/13]  eta: 0:00:00  loss: 0.6931 (0.6931)  pr_auc: 0.5156 (0.5128)  roc_auc: 0.5174 (0.5175)  accuracy: 0.5104 (0.5087)  balanced_accuracy: 0.5104 (0.5110)  time: 0.1134  data: 0.0420  max mem: 0
Test: Total time: 0:00:01 (0.1228 s / it)
* loss 0.693
Accuracy of the network on the 2347 test EEG: 0.51%, balanced_accuracy:0.51%
Accuracy of the network on the 7210 train EEG: 0.51%, balanced_accuracy:0.52%
Max balanced_accuracy val:0.52%,  balanced_accuracy train: 0.51% balanced_accuracy test: 0.50%
Training time 0:06:53

Process finished with exit code 0
