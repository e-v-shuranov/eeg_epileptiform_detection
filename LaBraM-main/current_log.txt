/home/eshuranov/miniconda3/bin/conda run -n labram2 --no-capture-output python /media/public/eshuranov/eeg_epileptiform_detection/LaBraM-main/run_class_finetuning_multidata.py --output_dir ./checkpoints/finetune_SPEECH/ --log_dir ./log/finetune_SPEECH --model labram_base_patch200_200 --finetune ./checkpoints/labram-base.pth --weight_decay 0.05 --batch_size 128 --lr 5e-4 --update_freq 1 --warmup_epochs 3 --epochs 30 --layer_decay 0.65 --drop_path 0.1 --dist_eval --save_ckpt_freq 5 --disable_rel_pos_bias --abs_pos_emb --dataset SPEECH --disable_qkv_bias --seed 0 --datasets_dir /media/public/Datasets/cbramod_data/Imagined_speech/processed --num_workers 10 --no_pin_mem --check_dataset
Not using distributed mode
Namespace(batch_size=128, epochs=30, update_freq=1, save_ckpt_freq=5, robust_test=None, model='labram_base_patch200_200', qkv_bias=False, rel_pos_bias=False, abs_pos_emb=True, layer_scale_init_value=0.1, input_size=200, drop=0.0, attn_drop_rate=0.0, drop_path=0.1, disable_eval_during_finetuning=False, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.0005, layer_decay=0.65, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=3, warmup_steps=-1, smoothing=0.1, reprob=0.25, remode='pixel', recount=1, resplit=False, finetune='./checkpoints/labram-base.pth', model_key='model|module', model_prefix='', model_filter_name='gzp', init_scale=0.001, use_mean_pooling=True, disable_weight_decay_on_rel_pos_bias=False, patch_embed_freeze_epoch=5, check_dataset=True, nb_classes=0, output_dir='./checkpoints/finetune_SPEECH/', datasets_dir='/media/public/Datasets/cbramod_data/Imagined_speech/processed', fixed_chkpt='', log_dir='./log/finetune_SPEECH', device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, start_epoch=0, eval=False, dist_eval=True, num_workers=10, pin_mem=False, pos_weight=None, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', enable_deepspeed=False, dataset='SPEECH', distributed=False)

==== Dataset sanity check ====

[train] size=4500 (checked 4500)
  NaN total: 0, Inf total: 0
  Class balance (count / share):
    class 0: 900 (20.00%)
    class 1: 900 (20.00%)
    class 2: 900 (20.00%)
    class 3: 900 (20.00%)
    class 4: 900 (20.00%)
  Bad samples: 0

[val] size=750 (checked 750)
  NaN total: 0, Inf total: 0
  Class balance (count / share):
    class 0: 150 (20.00%)
    class 1: 150 (20.00%)
    class 2: 150 (20.00%)
    class 3: 150 (20.00%)
    class 4: 150 (20.00%)
  Bad samples: 0

[test] size=750 (checked 750)
  NaN total: 0, Inf total: 0
  Class balance (count / share):
    class 0: 150 (20.00%)
    class 1: 150 (20.00%)
    class 2: 150 (20.00%)
    class 3: 150 (20.00%)
    class 4: 150 (20.00%)
  Bad samples: 0
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7efd9542a710>
Patch size = 200
Load ckpt from ./checkpoints/labram-base.pth
Load state_dict by model_key = model
Weights of NeuralTransformer not initialized from pretrained model: ['fc_norm.weight', 'fc_norm.bias', 'head.weight', 'head.bias']
Weights from pretrained model not used in NeuralTransformer: ['mask_token', 'lm_head.weight', 'lm_head.bias', 'norm.weight', 'norm.bias']
Model = NeuralTransformer(
  (patch_embed): TemporalConv(
    (conv1): Conv2d(1, 8, kernel_size=(1, 15), stride=(1, 8), padding=(0, 7))
    (gelu1): GELU(approximate='none')
    (norm1): GroupNorm(4, 8, eps=1e-05, affine=True)
    (conv2): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    (gelu2): GELU(approximate='none')
    (norm2): GroupNorm(4, 8, eps=1e-05, affine=True)
    (conv3): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    (norm3): GroupNorm(4, 8, eps=1e-05, affine=True)
    (gelu3): GELU(approximate='none')
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.00909090880304575)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (2): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0181818176060915)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (3): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.027272727340459824)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (4): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.036363635212183)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (5): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.045454543083906174)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (6): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.054545458406209946)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (7): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.06363636255264282)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (8): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0727272778749466)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (9): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.08181818574666977)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (10): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.09090909361839294)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (11): Block(
      (norm1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=200, out_features=600, bias=False)
        (q_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (k_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=200, out_features=200, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.10000000149011612)
      (norm2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=200, out_features=800, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=800, out_features=200, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): Identity()
  (fc_norm): LayerNorm((200,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=200, out_features=5, bias=True)
)
number of params: 5820941
LR = 0.00050000
Batch size = 128
Update frequent = 1
Number of training examples = 4500
Number of training training per epoch = 35
Assigned values = [0.003697205891018715, 0.005688009063105715, 0.008750783174008792, 0.013462743344628911, 0.02071191283789063, 0.03186448128906251, 0.049022278906250015, 0.07541889062500001, 0.11602906250000002, 0.17850625000000003, 0.274625, 0.42250000000000004, 0.65, 1.0]
Skip weight decay name marked in model: {'time_embed', 'pos_embed', 'cls_token'}
Param groups = {
  "layer_0_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "cls_token",
      "pos_embed",
      "patch_embed.conv1.bias",
      "patch_embed.norm1.weight",
      "patch_embed.norm1.bias",
      "patch_embed.conv2.bias",
      "patch_embed.norm2.weight",
      "patch_embed.norm2.bias",
      "patch_embed.conv3.bias",
      "patch_embed.norm3.weight",
      "patch_embed.norm3.bias"
    ],
    "lr_scale": 0.003697205891018715
  },
  "layer_13_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "time_embed",
      "fc_norm.weight",
      "fc_norm.bias",
      "head.bias"
    ],
    "lr_scale": 1.0
  },
  "layer_0_decay": {
    "weight_decay": 0.05,
    "params": [
      "patch_embed.conv1.weight",
      "patch_embed.conv2.weight",
      "patch_embed.conv3.weight"
    ],
    "lr_scale": 0.003697205891018715
  },
  "layer_1_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.0.gamma_1",
      "blocks.0.gamma_2",
      "blocks.0.norm1.weight",
      "blocks.0.norm1.bias",
      "blocks.0.attn.q_norm.weight",
      "blocks.0.attn.q_norm.bias",
      "blocks.0.attn.k_norm.weight",
      "blocks.0.attn.k_norm.bias",
      "blocks.0.attn.proj.bias",
      "blocks.0.norm2.weight",
      "blocks.0.norm2.bias",
      "blocks.0.mlp.fc1.bias",
      "blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.005688009063105715
  },
  "layer_1_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.0.attn.qkv.weight",
      "blocks.0.attn.proj.weight",
      "blocks.0.mlp.fc1.weight",
      "blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.005688009063105715
  },
  "layer_2_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.1.gamma_1",
      "blocks.1.gamma_2",
      "blocks.1.norm1.weight",
      "blocks.1.norm1.bias",
      "blocks.1.attn.q_norm.weight",
      "blocks.1.attn.q_norm.bias",
      "blocks.1.attn.k_norm.weight",
      "blocks.1.attn.k_norm.bias",
      "blocks.1.attn.proj.bias",
      "blocks.1.norm2.weight",
      "blocks.1.norm2.bias",
      "blocks.1.mlp.fc1.bias",
      "blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.008750783174008792
  },
  "layer_2_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.1.attn.qkv.weight",
      "blocks.1.attn.proj.weight",
      "blocks.1.mlp.fc1.weight",
      "blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.008750783174008792
  },
  "layer_3_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.2.gamma_1",
      "blocks.2.gamma_2",
      "blocks.2.norm1.weight",
      "blocks.2.norm1.bias",
      "blocks.2.attn.q_norm.weight",
      "blocks.2.attn.q_norm.bias",
      "blocks.2.attn.k_norm.weight",
      "blocks.2.attn.k_norm.bias",
      "blocks.2.attn.proj.bias",
      "blocks.2.norm2.weight",
      "blocks.2.norm2.bias",
      "blocks.2.mlp.fc1.bias",
      "blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.013462743344628911
  },
  "layer_3_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.2.attn.qkv.weight",
      "blocks.2.attn.proj.weight",
      "blocks.2.mlp.fc1.weight",
      "blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.013462743344628911
  },
  "layer_4_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.3.gamma_1",
      "blocks.3.gamma_2",
      "blocks.3.norm1.weight",
      "blocks.3.norm1.bias",
      "blocks.3.attn.q_norm.weight",
      "blocks.3.attn.q_norm.bias",
      "blocks.3.attn.k_norm.weight",
      "blocks.3.attn.k_norm.bias",
      "blocks.3.attn.proj.bias",
      "blocks.3.norm2.weight",
      "blocks.3.norm2.bias",
      "blocks.3.mlp.fc1.bias",
      "blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.02071191283789063
  },
  "layer_4_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.3.attn.qkv.weight",
      "blocks.3.attn.proj.weight",
      "blocks.3.mlp.fc1.weight",
      "blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.02071191283789063
  },
  "layer_5_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.4.gamma_1",
      "blocks.4.gamma_2",
      "blocks.4.norm1.weight",
      "blocks.4.norm1.bias",
      "blocks.4.attn.q_norm.weight",
      "blocks.4.attn.q_norm.bias",
      "blocks.4.attn.k_norm.weight",
      "blocks.4.attn.k_norm.bias",
      "blocks.4.attn.proj.bias",
      "blocks.4.norm2.weight",
      "blocks.4.norm2.bias",
      "blocks.4.mlp.fc1.bias",
      "blocks.4.mlp.fc2.bias"
    ],
    "lr_scale": 0.03186448128906251
  },
  "layer_5_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.4.attn.qkv.weight",
      "blocks.4.attn.proj.weight",
      "blocks.4.mlp.fc1.weight",
      "blocks.4.mlp.fc2.weight"
    ],
    "lr_scale": 0.03186448128906251
  },
  "layer_6_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.5.gamma_1",
      "blocks.5.gamma_2",
      "blocks.5.norm1.weight",
      "blocks.5.norm1.bias",
      "blocks.5.attn.q_norm.weight",
      "blocks.5.attn.q_norm.bias",
      "blocks.5.attn.k_norm.weight",
      "blocks.5.attn.k_norm.bias",
      "blocks.5.attn.proj.bias",
      "blocks.5.norm2.weight",
      "blocks.5.norm2.bias",
      "blocks.5.mlp.fc1.bias",
      "blocks.5.mlp.fc2.bias"
    ],
    "lr_scale": 0.049022278906250015
  },
  "layer_6_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.5.attn.qkv.weight",
      "blocks.5.attn.proj.weight",
      "blocks.5.mlp.fc1.weight",
      "blocks.5.mlp.fc2.weight"
    ],
    "lr_scale": 0.049022278906250015
  },
  "layer_7_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.6.gamma_1",
      "blocks.6.gamma_2",
      "blocks.6.norm1.weight",
      "blocks.6.norm1.bias",
      "blocks.6.attn.q_norm.weight",
      "blocks.6.attn.q_norm.bias",
      "blocks.6.attn.k_norm.weight",
      "blocks.6.attn.k_norm.bias",
      "blocks.6.attn.proj.bias",
      "blocks.6.norm2.weight",
      "blocks.6.norm2.bias",
      "blocks.6.mlp.fc1.bias",
      "blocks.6.mlp.fc2.bias"
    ],
    "lr_scale": 0.07541889062500001
  },
  "layer_7_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.6.attn.qkv.weight",
      "blocks.6.attn.proj.weight",
      "blocks.6.mlp.fc1.weight",
      "blocks.6.mlp.fc2.weight"
    ],
    "lr_scale": 0.07541889062500001
  },
  "layer_8_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.7.gamma_1",
      "blocks.7.gamma_2",
      "blocks.7.norm1.weight",
      "blocks.7.norm1.bias",
      "blocks.7.attn.q_norm.weight",
      "blocks.7.attn.q_norm.bias",
      "blocks.7.attn.k_norm.weight",
      "blocks.7.attn.k_norm.bias",
      "blocks.7.attn.proj.bias",
      "blocks.7.norm2.weight",
      "blocks.7.norm2.bias",
      "blocks.7.mlp.fc1.bias",
      "blocks.7.mlp.fc2.bias"
    ],
    "lr_scale": 0.11602906250000002
  },
  "layer_8_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.7.attn.qkv.weight",
      "blocks.7.attn.proj.weight",
      "blocks.7.mlp.fc1.weight",
      "blocks.7.mlp.fc2.weight"
    ],
    "lr_scale": 0.11602906250000002
  },
  "layer_9_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.8.gamma_1",
      "blocks.8.gamma_2",
      "blocks.8.norm1.weight",
      "blocks.8.norm1.bias",
      "blocks.8.attn.q_norm.weight",
      "blocks.8.attn.q_norm.bias",
      "blocks.8.attn.k_norm.weight",
      "blocks.8.attn.k_norm.bias",
      "blocks.8.attn.proj.bias",
      "blocks.8.norm2.weight",
      "blocks.8.norm2.bias",
      "blocks.8.mlp.fc1.bias",
      "blocks.8.mlp.fc2.bias"
    ],
    "lr_scale": 0.17850625000000003
  },
  "layer_9_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.8.attn.qkv.weight",
      "blocks.8.attn.proj.weight",
      "blocks.8.mlp.fc1.weight",
      "blocks.8.mlp.fc2.weight"
    ],
    "lr_scale": 0.17850625000000003
  },
  "layer_10_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.9.gamma_1",
      "blocks.9.gamma_2",
      "blocks.9.norm1.weight",
      "blocks.9.norm1.bias",
      "blocks.9.attn.q_norm.weight",
      "blocks.9.attn.q_norm.bias",
      "blocks.9.attn.k_norm.weight",
      "blocks.9.attn.k_norm.bias",
      "blocks.9.attn.proj.bias",
      "blocks.9.norm2.weight",
      "blocks.9.norm2.bias",
      "blocks.9.mlp.fc1.bias",
      "blocks.9.mlp.fc2.bias"
    ],
    "lr_scale": 0.274625
  },
  "layer_10_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.9.attn.qkv.weight",
      "blocks.9.attn.proj.weight",
      "blocks.9.mlp.fc1.weight",
      "blocks.9.mlp.fc2.weight"
    ],
    "lr_scale": 0.274625
  },
  "layer_11_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.10.gamma_1",
      "blocks.10.gamma_2",
      "blocks.10.norm1.weight",
      "blocks.10.norm1.bias",
      "blocks.10.attn.q_norm.weight",
      "blocks.10.attn.q_norm.bias",
      "blocks.10.attn.k_norm.weight",
      "blocks.10.attn.k_norm.bias",
      "blocks.10.attn.proj.bias",
      "blocks.10.norm2.weight",
      "blocks.10.norm2.bias",
      "blocks.10.mlp.fc1.bias",
      "blocks.10.mlp.fc2.bias"
    ],
    "lr_scale": 0.42250000000000004
  },
  "layer_11_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.10.attn.qkv.weight",
      "blocks.10.attn.proj.weight",
      "blocks.10.mlp.fc1.weight",
      "blocks.10.mlp.fc2.weight"
    ],
    "lr_scale": 0.42250000000000004
  },
  "layer_12_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.11.gamma_1",
      "blocks.11.gamma_2",
      "blocks.11.norm1.weight",
      "blocks.11.norm1.bias",
      "blocks.11.attn.q_norm.weight",
      "blocks.11.attn.q_norm.bias",
      "blocks.11.attn.k_norm.weight",
      "blocks.11.attn.k_norm.bias",
      "blocks.11.attn.proj.bias",
      "blocks.11.norm2.weight",
      "blocks.11.norm2.bias",
      "blocks.11.mlp.fc1.bias",
      "blocks.11.mlp.fc2.bias"
    ],
    "lr_scale": 0.65
  },
  "layer_12_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.11.attn.qkv.weight",
      "blocks.11.attn.proj.weight",
      "blocks.11.mlp.fc1.weight",
      "blocks.11.mlp.fc2.weight"
    ],
    "lr_scale": 0.65
  },
  "layer_13_decay": {
    "weight_decay": 0.05,
    "params": [
      "head.weight"
    ],
    "lr_scale": 1.0
  }
}
Optimizer config: {'lr': 0.0005, 'weight_decay': 0.0, 'eps': 1e-08}
Use step level LR scheduler!
Set warmup steps = 105
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = LabelSmoothingCrossEntropy()
Auto resume checkpoint:
Start training for 30 epochs
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
/home/eshuranov/miniconda3/envs/labram2/lib/python3.11/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
Epoch: [0]  [ 0/35]  eta: 0:01:00  lr: 0.000000  min_lr: 0.000000  loss: 1.6094 (1.6094)  class_acc: 0.2734 (0.2734)  balanced_accuracy: 0.2000 (0.2000)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7586 (0.7586)  time: 1.7219  data: 0.7723  max mem: 0
Exception ignored in: <function _ConnectionBase.__del__ at 0x7efd9f9228e0>
Traceback (most recent call last):
  File "/home/eshuranov/miniconda3/envs/labram2/lib/python3.11/multiprocessing/connection.py", line 133, in __del__
    self._close()
  File "/home/eshuranov/miniconda3/envs/labram2/lib/python3.11/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
TypeError:         def _close(self, _close=_multiprocessing.closesocket):

Epoch: [0]  [10/35]  eta: 0:00:09  lr: 0.000048  min_lr: 0.000000  loss: 1.6094 (1.6094)  class_acc: 0.2188 (0.2195)  balanced_accuracy: 0.2000 (0.1934)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8681 (0.9391)  time: 0.3785  data: 0.0708  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [0]  [20/35]  eta: 0:00:04  lr: 0.000096  min_lr: 0.000000  loss: 1.6095 (1.6096)  class_acc: 0.1875 (0.1972)  balanced_accuracy: 0.2000 (0.1923)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8681 (0.9563)  time: 0.2442  data: 0.0004  max mem: 0
Epoch: [0]  [30/35]  eta: 0:00:01  lr: 0.000144  min_lr: 0.000001  loss: 1.6094 (1.6094)  class_acc: 0.1875 (0.2014)  balanced_accuracy: 0.2000 (0.1976)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9353 (0.9558)  time: 0.2438  data: 0.0006  max mem: 0
Epoch: [0]  [34/35]  eta: 0:00:00  lr: 0.000163  min_lr: 0.000001  loss: 1.6094 (1.6093)  class_acc: 0.1953 (0.2016)  balanced_accuracy: 0.2000 (0.1981)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8215 (0.9397)  time: 0.2437  data: 0.0008  max mem: 0
Epoch: [0] Total time: 0:00:10 (0.2895 s / it)
Averaged stats: lr: 0.000163  min_lr: 0.000001  loss: 1.6094 (1.6093)  class_acc: 0.1953 (0.2016)  balanced_accuracy: 0.2000 (0.1981)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8215 (0.9397)
Val:  [0/4]  eta: 0:00:03  loss: 1.6130 (1.6130)  accuracy: 0.1979 (0.1979)  balanced_accuracy: 0.2000 (0.2000)  cohen_kappa: 0.0000 (0.0000)  f1_weighted: 0.0654 (0.0654)  time: 0.8274  data: 0.5335  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6099 (1.6104)  accuracy: 0.1979 (0.2000)  balanced_accuracy: 0.2000 (0.2000)  cohen_kappa: 0.0000 (0.0000)  f1_weighted: 0.0654 (0.0667)  time: 0.3063  data: 0.1337  max mem: 0
Val: Total time: 0:00:01 (0.3331 s / it)
* loss 1.610
Accuracy of the network on the 750 val EEG: 0.20%, balanced_accuracy:0.20%
Test:  [0/4]  eta: 0:00:02  loss: 1.6112 (1.6112)  accuracy: 0.1979 (0.1979)  balanced_accuracy: 0.2000 (0.2000)  cohen_kappa: 0.0000 (0.0000)  f1_weighted: 0.0654 (0.0654)  time: 0.6613  data: 0.5359  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6090 (1.6102)  accuracy: 0.1979 (0.2000)  balanced_accuracy: 0.2000 (0.2000)  cohen_kappa: 0.0000 (0.0000)  f1_weighted: 0.0654 (0.0667)  time: 0.2560  data: 0.1340  max mem: 0
Test: Total time: 0:00:01 (0.2848 s / it)
* loss 1.610
Accuracy of the network on the 750 test EEG: 0.20%, balanced_accuracy:0.20%
Accuracy of the network on the 4500 train EEG: 0.20%, balanced_accuracy:0.20%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [1]  [ 0/35]  eta: 0:00:33  lr: 0.000168  min_lr: 0.000001  loss: 1.6086 (1.6086)  class_acc: 0.2109 (0.2109)  balanced_accuracy: 0.2183 (0.2183)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8491 (0.8491)  time: 0.9643  data: 0.7240  max mem: 0
Epoch: [1]  [10/35]  eta: 0:00:07  lr: 0.000216  min_lr: 0.000001  loss: 1.6092 (1.6116)  class_acc: 0.2031 (0.1882)  balanced_accuracy: 0.2069 (0.2064)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0621 (1.0513)  time: 0.3119  data: 0.0666  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [1]  [20/35]  eta: 0:00:04  lr: 0.000264  min_lr: 0.000001  loss: 1.6098 (1.6115)  class_acc: 0.1953 (0.1908)  balanced_accuracy: 0.2000 (0.2030)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9225 (1.0401)  time: 0.2450  data: 0.0006  max mem: 0
Epoch: [1]  [30/35]  eta: 0:00:01  lr: 0.000313  min_lr: 0.000001  loss: 1.6096 (1.6109)  class_acc: 0.2031 (0.1953)  balanced_accuracy: 0.2000 (0.2018)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9225 (1.0163)  time: 0.2435  data: 0.0006  max mem: 0
Epoch: [1]  [34/35]  eta: 0:00:00  lr: 0.000332  min_lr: 0.000001  loss: 1.6095 (1.6107)  class_acc: 0.2109 (0.1978)  balanced_accuracy: 0.2013 (0.2037)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8806 (0.9853)  time: 0.2430  data: 0.0007  max mem: 0
Epoch: [1] Total time: 0:00:09 (0.2687 s / it)
Averaged stats: lr: 0.000332  min_lr: 0.000001  loss: 1.6095 (1.6107)  class_acc: 0.2109 (0.1978)  balanced_accuracy: 0.2013 (0.2037)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8806 (0.9853)
Val:  [0/4]  eta: 0:00:02  loss: 1.6117 (1.6117)  accuracy: 0.1771 (0.1771)  balanced_accuracy: 0.1789 (0.1789)  cohen_kappa: -0.0263 (-0.0263)  f1_weighted: 0.0650 (0.0650)  time: 0.5964  data: 0.4695  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6090 (1.6101)  accuracy: 0.1927 (0.1987)  balanced_accuracy: 0.1903 (0.1983)  cohen_kappa: -0.0127 (-0.0017)  f1_weighted: 0.1121 (0.1074)  time: 0.2409  data: 0.1180  max mem: 0
Val: Total time: 0:00:01 (0.2689 s / it)
* loss 1.610
Accuracy of the network on the 750 val EEG: 0.20%, balanced_accuracy:0.20%
Test:  [0/4]  eta: 0:00:02  loss: 1.6119 (1.6119)  accuracy: 0.2031 (0.2031)  balanced_accuracy: 0.2050 (0.2050)  cohen_kappa: 0.0062 (0.0062)  f1_weighted: 0.0991 (0.0991)  time: 0.6407  data: 0.5143  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6099 (1.6101)  accuracy: 0.2031 (0.2080)  balanced_accuracy: 0.2004 (0.2088)  cohen_kappa: 0.0008 (0.0103)  f1_weighted: 0.1107 (0.1169)  time: 0.2519  data: 0.1290  max mem: 0
Test: Total time: 0:00:01 (0.2800 s / it)
* loss 1.610
Accuracy of the network on the 750 test EEG: 0.21%, balanced_accuracy:0.21%
Accuracy of the network on the 4500 train EEG: 0.20%, balanced_accuracy:0.20%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [2]  [ 0/35]  eta: 0:00:34  lr: 0.000337  min_lr: 0.000001  loss: 1.6079 (1.6079)  class_acc: 0.2266 (0.2266)  balanced_accuracy: 0.2317 (0.2317)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6603 (0.6603)  time: 0.9998  data: 0.7564  max mem: 0
Epoch: [2]  [10/35]  eta: 0:00:07  lr: 0.000385  min_lr: 0.000001  loss: 1.6085 (1.6104)  class_acc: 0.2266 (0.2152)  balanced_accuracy: 0.2295 (0.2229)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8509 (0.9575)  time: 0.3145  data: 0.0698  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [2]  [20/35]  eta: 0:00:04  lr: 0.000433  min_lr: 0.000002  loss: 1.6089 (1.6106)  class_acc: 0.2031 (0.2068)  balanced_accuracy: 0.2143 (0.2145)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8509 (0.9663)  time: 0.2460  data: 0.0008  max mem: 0
Epoch: [2]  [30/35]  eta: 0:00:01  lr: 0.000481  min_lr: 0.000002  loss: 1.6089 (1.6101)  class_acc: 0.1953 (0.2039)  balanced_accuracy: 0.2000 (0.2089)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8990 (0.9643)  time: 0.2452  data: 0.0007  max mem: 0
Epoch: [2]  [34/35]  eta: 0:00:00  lr: 0.000500  min_lr: 0.000002  loss: 1.6089 (1.6103)  class_acc: 0.1953 (0.2047)  balanced_accuracy: 0.2000 (0.2098)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8433 (0.9441)  time: 0.2447  data: 0.0008  max mem: 0
Epoch: [2] Total time: 0:00:09 (0.2710 s / it)
Averaged stats: lr: 0.000500  min_lr: 0.000002  loss: 1.6089 (1.6103)  class_acc: 0.1953 (0.2047)  balanced_accuracy: 0.2000 (0.2098)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8433 (0.9441)
Val:  [0/4]  eta: 0:00:02  loss: 1.6139 (1.6139)  accuracy: 0.1719 (0.1719)  balanced_accuracy: 0.1735 (0.1735)  cohen_kappa: -0.0332 (-0.0332)  f1_weighted: 0.0694 (0.0694)  time: 0.6319  data: 0.5029  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6105 (1.6113)  accuracy: 0.1875 (0.1933)  balanced_accuracy: 0.1852 (0.1929)  cohen_kappa: -0.0189 (-0.0086)  f1_weighted: 0.0946 (0.0997)  time: 0.2518  data: 0.1262  max mem: 0
Val: Total time: 0:00:01 (0.2801 s / it)
* loss 1.611
Accuracy of the network on the 750 val EEG: 0.19%, balanced_accuracy:0.19%
Test:  [0/4]  eta: 0:00:02  loss: 1.6118 (1.6118)  accuracy: 0.1771 (0.1771)  balanced_accuracy: 0.1789 (0.1789)  cohen_kappa: -0.0260 (-0.0260)  f1_weighted: 0.0797 (0.0797)  time: 0.6585  data: 0.5310  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6087 (1.6099)  accuracy: 0.1782 (0.1987)  balanced_accuracy: 0.1823 (0.1993)  cohen_kappa: -0.0226 (-0.0015)  f1_weighted: 0.1196 (0.1145)  time: 0.2582  data: 0.1330  max mem: 0
Test: Total time: 0:00:01 (0.2865 s / it)
* loss 1.610
Accuracy of the network on the 750 test EEG: 0.20%, balanced_accuracy:0.20%
Accuracy of the network on the 4500 train EEG: 0.20%, balanced_accuracy:0.21%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [3]  [ 0/35]  eta: 0:00:35  lr: 0.000500  min_lr: 0.000002  loss: 1.6075 (1.6075)  class_acc: 0.1875 (0.1875)  balanced_accuracy: 0.2100 (0.2100)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8174 (0.8174)  time: 1.0083  data: 0.7509  max mem: 0
Epoch: [3]  [10/35]  eta: 0:00:07  lr: 0.000500  min_lr: 0.000002  loss: 1.6088 (1.6102)  class_acc: 0.2031 (0.2166)  balanced_accuracy: 0.2100 (0.2157)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8941 (0.9742)  time: 0.3174  data: 0.0695  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [3]  [20/35]  eta: 0:00:04  lr: 0.000499  min_lr: 0.000002  loss: 1.6104 (1.6118)  class_acc: 0.2031 (0.1990)  balanced_accuracy: 0.2000 (0.2048)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8941 (0.9935)  time: 0.2468  data: 0.0010  max mem: 0
Epoch: [3]  [30/35]  eta: 0:00:01  lr: 0.000499  min_lr: 0.000002  loss: 1.6104 (1.6112)  class_acc: 0.1875 (0.1991)  balanced_accuracy: 0.2000 (0.2049)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8949 (0.9677)  time: 0.2450  data: 0.0007  max mem: 0
Epoch: [3]  [34/35]  eta: 0:00:00  lr: 0.000498  min_lr: 0.000002  loss: 1.6110 (1.6111)  class_acc: 0.1875 (0.1984)  balanced_accuracy: 0.2000 (0.2049)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8698 (0.9422)  time: 0.2445  data: 0.0008  max mem: 0
Epoch: [3] Total time: 0:00:09 (0.2713 s / it)
Averaged stats: lr: 0.000498  min_lr: 0.000002  loss: 1.6110 (1.6111)  class_acc: 0.1875 (0.1984)  balanced_accuracy: 0.2000 (0.2049)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8698 (0.9422)
Val:  [0/4]  eta: 0:00:02  loss: 1.6108 (1.6108)  accuracy: 0.1927 (0.1927)  balanced_accuracy: 0.1947 (0.1947)  cohen_kappa: -0.0065 (-0.0065)  f1_weighted: 0.0645 (0.0645)  time: 0.6102  data: 0.4824  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6102 (1.6105)  accuracy: 0.1927 (0.2000)  balanced_accuracy: 0.2000 (0.2001)  cohen_kappa: 0.0000 (0.0002)  f1_weighted: 0.0645 (0.0733)  time: 0.2465  data: 0.1209  max mem: 0
Val: Total time: 0:00:01 (0.2748 s / it)
* loss 1.610
Accuracy of the network on the 750 val EEG: 0.20%, balanced_accuracy:0.20%
Test:  [0/4]  eta: 0:00:02  loss: 1.6107 (1.6107)  accuracy: 0.2083 (0.2083)  balanced_accuracy: 0.2053 (0.2053)  cohen_kappa: 0.0067 (0.0067)  f1_weighted: 0.0792 (0.0792)  time: 0.6224  data: 0.4937  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6107 (1.6104)  accuracy: 0.1897 (0.2000)  balanced_accuracy: 0.2000 (0.1998)  cohen_kappa: 0.0000 (0.0000)  f1_weighted: 0.0681 (0.0737)  time: 0.2479  data: 0.1241  max mem: 0
Test: Total time: 0:00:01 (0.2789 s / it)
* loss 1.610
Accuracy of the network on the 750 test EEG: 0.20%, balanced_accuracy:0.20%
Accuracy of the network on the 4500 train EEG: 0.20%, balanced_accuracy:0.20%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [4]  [ 0/35]  eta: 0:00:33  lr: 0.000498  min_lr: 0.000002  loss: 1.6100 (1.6100)  class_acc: 0.2578 (0.2578)  balanced_accuracy: 0.2417 (0.2417)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7119 (0.7119)  time: 0.9690  data: 0.7264  max mem: 0
Epoch: [4]  [10/35]  eta: 0:00:07  lr: 0.000497  min_lr: 0.000002  loss: 1.6095 (1.6109)  class_acc: 0.2031 (0.2010)  balanced_accuracy: 0.2000 (0.2013)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7882 (0.9313)  time: 0.3133  data: 0.0673  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [4]  [20/35]  eta: 0:00:04  lr: 0.000496  min_lr: 0.000002  loss: 1.6115 (1.6117)  class_acc: 0.1875 (0.1942)  balanced_accuracy: 0.2000 (0.2005)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8424 (0.9467)  time: 0.2462  data: 0.0011  max mem: 0
Epoch: [4]  [30/35]  eta: 0:00:01  lr: 0.000494  min_lr: 0.000002  loss: 1.6107 (1.6112)  class_acc: 0.1875 (0.1948)  balanced_accuracy: 0.2000 (0.2002)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8744 (0.9396)  time: 0.2452  data: 0.0009  max mem: 0
Epoch: [4]  [34/35]  eta: 0:00:00  lr: 0.000493  min_lr: 0.000002  loss: 1.6107 (1.6110)  class_acc: 0.1875 (0.1962)  balanced_accuracy: 0.2000 (0.2010)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8441 (0.9120)  time: 0.2450  data: 0.0009  max mem: 0
Epoch: [4] Total time: 0:00:09 (0.2703 s / it)
Averaged stats: lr: 0.000493  min_lr: 0.000002  loss: 1.6107 (1.6110)  class_acc: 0.1875 (0.1962)  balanced_accuracy: 0.2000 (0.2010)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8441 (0.9120)
Val:  [0/4]  eta: 0:00:02  loss: 1.6104 (1.6104)  accuracy: 0.1979 (0.1979)  balanced_accuracy: 0.2000 (0.2000)  cohen_kappa: -0.0000 (-0.0000)  f1_weighted: 0.0666 (0.0666)  time: 0.6080  data: 0.4788  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6098 (1.6100)  accuracy: 0.1979 (0.2013)  balanced_accuracy: 0.2000 (0.2012)  cohen_kappa: -0.0000 (0.0017)  f1_weighted: 0.0868 (0.0862)  time: 0.2445  data: 0.1197  max mem: 0
Val: Total time: 0:00:01 (0.2723 s / it)
* loss 1.610
Accuracy of the network on the 750 val EEG: 0.20%, balanced_accuracy:0.20%
Test:  [0/4]  eta: 0:00:02  loss: 1.6103 (1.6103)  accuracy: 0.1979 (0.1979)  balanced_accuracy: 0.2000 (0.2000)  cohen_kappa: -0.0001 (-0.0001)  f1_weighted: 0.0821 (0.0821)  time: 0.6248  data: 0.4975  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6098 (1.6098)  accuracy: 0.1979 (0.2093)  balanced_accuracy: 0.2000 (0.2100)  cohen_kappa: -0.0001 (0.0117)  f1_weighted: 0.0821 (0.1010)  time: 0.2488  data: 0.1251  max mem: 0
Test: Total time: 0:00:01 (0.2766 s / it)
* loss 1.610
Accuracy of the network on the 750 test EEG: 0.21%, balanced_accuracy:0.21%
Accuracy of the network on the 4500 train EEG: 0.20%, balanced_accuracy:0.20%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.21%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [5]  [ 0/35]  eta: 0:00:37  lr: 0.000493  min_lr: 0.000002  loss: 1.6107 (1.6107)  class_acc: 0.1719 (0.1719)  balanced_accuracy: 0.1800 (0.1800)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.6817 (0.6817)  time: 1.0793  data: 0.8139  max mem: 0
Epoch: [5]  [10/35]  eta: 0:00:08  lr: 0.000491  min_lr: 0.000002  loss: 1.6107 (1.6112)  class_acc: 0.1875 (0.1832)  balanced_accuracy: 0.1961 (0.1930)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8464 (0.9047)  time: 0.3221  data: 0.0745  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [5]  [20/35]  eta: 0:00:04  lr: 0.000489  min_lr: 0.000002  loss: 1.6111 (1.6114)  class_acc: 0.1875 (0.1838)  balanced_accuracy: 0.2000 (0.1964)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9142 (0.9253)  time: 0.2458  data: 0.0004  max mem: 0
Epoch: [5]  [30/35]  eta: 0:00:01  lr: 0.000486  min_lr: 0.000002  loss: 1.6097 (1.6106)  class_acc: 0.1875 (0.1898)  balanced_accuracy: 0.2000 (0.2021)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9142 (0.9175)  time: 0.2455  data: 0.0007  max mem: 0
Epoch: [5]  [34/35]  eta: 0:00:00  lr: 0.000485  min_lr: 0.000002  loss: 1.6095 (1.6104)  class_acc: 0.2031 (0.1926)  balanced_accuracy: 0.2095 (0.2049)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8764 (0.8886)  time: 0.2453  data: 0.0009  max mem: 0
Epoch: [5] Total time: 0:00:09 (0.2733 s / it)
Averaged stats: lr: 0.000485  min_lr: 0.000002  loss: 1.6095 (1.6104)  class_acc: 0.2031 (0.1926)  balanced_accuracy: 0.2095 (0.2049)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8764 (0.8886)
Val:  [0/4]  eta: 0:00:02  loss: 1.6135 (1.6135)  accuracy: 0.1719 (0.1719)  balanced_accuracy: 0.1699 (0.1699)  cohen_kappa: -0.0377 (-0.0377)  f1_weighted: 0.0908 (0.0908)  time: 0.6939  data: 0.5669  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6102 (1.6111)  accuracy: 0.1782 (0.1960)  balanced_accuracy: 0.1747 (0.1952)  cohen_kappa: -0.0298 (-0.0055)  f1_weighted: 0.1095 (0.1274)  time: 0.2662  data: 0.1422  max mem: 0
Val: Total time: 0:00:01 (0.2941 s / it)
* loss 1.611
Accuracy of the network on the 750 val EEG: 0.20%, balanced_accuracy:0.20%
Test:  [0/4]  eta: 0:00:02  loss: 1.6120 (1.6120)  accuracy: 0.2083 (0.2083)  balanced_accuracy: 0.2101 (0.2101)  cohen_kappa: 0.0125 (0.0125)  f1_weighted: 0.1267 (0.1267)  time: 0.5610  data: 0.4322  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6078 (1.6088)  accuracy: 0.2083 (0.2227)  balanced_accuracy: 0.2101 (0.2235)  cohen_kappa: 0.0125 (0.0285)  f1_weighted: 0.1380 (0.1505)  time: 0.2331  data: 0.1087  max mem: 0
Test: Total time: 0:00:01 (0.2672 s / it)
* loss 1.609
Accuracy of the network on the 750 test EEG: 0.22%, balanced_accuracy:0.22%
Accuracy of the network on the 4500 train EEG: 0.19%, balanced_accuracy:0.20%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.21%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [6]  [ 0/35]  eta: 0:00:43  lr: 0.000485  min_lr: 0.000002  loss: 1.6064 (1.6064)  class_acc: 0.2656 (0.2656)  balanced_accuracy: 0.2433 (0.2433)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.8014 (0.8014)  time: 1.2393  data: 0.7676  max mem: 0
Epoch: [6]  [10/35]  eta: 0:00:08  lr: 0.000482  min_lr: 0.000002  loss: 1.6122 (1.6103)  class_acc: 0.1875 (0.1960)  balanced_accuracy: 0.2091 (0.2080)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2351 (1.2472)  time: 0.3425  data: 0.0704  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [6]  [20/35]  eta: 0:00:04  lr: 0.000479  min_lr: 0.000002  loss: 1.6105 (1.6102)  class_acc: 0.1875 (0.1949)  balanced_accuracy: 0.2026 (0.2051)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2125 (1.2254)  time: 0.2518  data: 0.0005  max mem: 0
Epoch: [6]  [30/35]  eta: 0:00:01  lr: 0.000475  min_lr: 0.000002  loss: 1.6086 (1.6096)  class_acc: 0.2031 (0.2011)  balanced_accuracy: 0.2026 (0.2087)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1010 (1.2051)  time: 0.2508  data: 0.0007  max mem: 0
Epoch: [6]  [34/35]  eta: 0:00:00  lr: 0.000474  min_lr: 0.000002  loss: 1.6085 (1.6094)  class_acc: 0.2031 (0.2022)  balanced_accuracy: 0.2026 (0.2094)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0743 (1.1805)  time: 0.2506  data: 0.0008  max mem: 0
Epoch: [6] Total time: 0:00:09 (0.2833 s / it)
Averaged stats: lr: 0.000474  min_lr: 0.000002  loss: 1.6085 (1.6094)  class_acc: 0.2031 (0.2022)  balanced_accuracy: 0.2026 (0.2094)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0743 (1.1805)
Val:  [0/4]  eta: 0:00:02  loss: 1.6144 (1.6144)  accuracy: 0.1562 (0.1562)  balanced_accuracy: 0.1561 (0.1561)  cohen_kappa: -0.0546 (-0.0546)  f1_weighted: 0.1110 (0.1110)  time: 0.6257  data: 0.4976  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6102 (1.6110)  accuracy: 0.1823 (0.1973)  balanced_accuracy: 0.1820 (0.1966)  cohen_kappa: -0.0225 (-0.0034)  f1_weighted: 0.1338 (0.1471)  time: 0.2491  data: 0.1247  max mem: 0
Val: Total time: 0:00:01 (0.2779 s / it)
* loss 1.611
Accuracy of the network on the 750 val EEG: 0.20%, balanced_accuracy:0.20%
Test:  [0/4]  eta: 0:00:02  loss: 1.6144 (1.6144)  accuracy: 0.1875 (0.1875)  balanced_accuracy: 0.1887 (0.1887)  cohen_kappa: -0.0141 (-0.0141)  f1_weighted: 0.1341 (0.1341)  time: 0.6825  data: 0.5540  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6081 (1.6095)  accuracy: 0.1927 (0.2053)  balanced_accuracy: 0.1889 (0.2064)  cohen_kappa: -0.0141 (0.0071)  f1_weighted: 0.1476 (0.1511)  time: 0.2638  data: 0.1386  max mem: 0
Test: Total time: 0:00:01 (0.2959 s / it)
* loss 1.610
Accuracy of the network on the 750 test EEG: 0.21%, balanced_accuracy:0.21%
Accuracy of the network on the 4500 train EEG: 0.20%, balanced_accuracy:0.21%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.21%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [7]  [ 0/35]  eta: 0:00:37  lr: 0.000473  min_lr: 0.000002  loss: 1.6094 (1.6094)  class_acc: 0.2578 (0.2578)  balanced_accuracy: 0.2517 (0.2517)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0915 (1.0915)  time: 1.0760  data: 0.8280  max mem: 0
Epoch: [7]  [10/35]  eta: 0:00:08  lr: 0.000470  min_lr: 0.000002  loss: 1.6084 (1.6086)  class_acc: 0.1875 (0.1989)  balanced_accuracy: 0.2231 (0.2110)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2964 (1.2711)  time: 0.3261  data: 0.0757  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [7]  [20/35]  eta: 0:00:04  lr: 0.000466  min_lr: 0.000002  loss: 1.6097 (1.6101)  class_acc: 0.1875 (0.1968)  balanced_accuracy: 0.2000 (0.2125)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2964 (1.3140)  time: 0.2508  data: 0.0004  max mem: 0
Epoch: [7]  [30/35]  eta: 0:00:01  lr: 0.000461  min_lr: 0.000002  loss: 1.6094 (1.6092)  class_acc: 0.1953 (0.2001)  balanced_accuracy: 0.2112 (0.2128)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3065 (1.3203)  time: 0.2512  data: 0.0007  max mem: 0
Epoch: [7]  [34/35]  eta: 0:00:00  lr: 0.000459  min_lr: 0.000002  loss: 1.6074 (1.6091)  class_acc: 0.1953 (0.2011)  balanced_accuracy: 0.2094 (0.2128)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3323 (1.3493)  time: 0.2515  data: 0.0009  max mem: 0
Epoch: [7] Total time: 0:00:09 (0.2788 s / it)
Averaged stats: lr: 0.000459  min_lr: 0.000002  loss: 1.6074 (1.6091)  class_acc: 0.1953 (0.2011)  balanced_accuracy: 0.2094 (0.2128)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3323 (1.3493)
Val:  [0/4]  eta: 0:00:02  loss: 1.6136 (1.6136)  accuracy: 0.1250 (0.1250)  balanced_accuracy: 0.1259 (0.1259)  cohen_kappa: -0.0924 (-0.0924)  f1_weighted: 0.0969 (0.0969)  time: 0.6228  data: 0.4937  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6097 (1.6110)  accuracy: 0.1979 (0.1920)  balanced_accuracy: 0.1963 (0.1913)  cohen_kappa: -0.0046 (-0.0100)  f1_weighted: 0.1445 (0.1439)  time: 0.2489  data: 0.1239  max mem: 0
Val: Total time: 0:00:01 (0.2780 s / it)
* loss 1.611
Accuracy of the network on the 750 val EEG: 0.19%, balanced_accuracy:0.19%
Test:  [0/4]  eta: 0:00:02  loss: 1.6136 (1.6136)  accuracy: 0.1771 (0.1771)  balanced_accuracy: 0.1775 (0.1775)  cohen_kappa: -0.0285 (-0.0285)  f1_weighted: 0.1339 (0.1339)  time: 0.6494  data: 0.5202  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6081 (1.6092)  accuracy: 0.1954 (0.1947)  balanced_accuracy: 0.1972 (0.1953)  cohen_kappa: -0.0049 (-0.0066)  f1_weighted: 0.1414 (0.1457)  time: 0.2552  data: 0.1301  max mem: 0
Test: Total time: 0:00:01 (0.2840 s / it)
* loss 1.609
Accuracy of the network on the 750 test EEG: 0.19%, balanced_accuracy:0.19%
Accuracy of the network on the 4500 train EEG: 0.20%, balanced_accuracy:0.21%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.21%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [8]  [ 0/35]  eta: 0:00:32  lr: 0.000459  min_lr: 0.000002  loss: 1.6074 (1.6074)  class_acc: 0.2031 (0.2031)  balanced_accuracy: 0.1991 (0.1991)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2063 (1.2063)  time: 0.9416  data: 0.6923  max mem: 0
Epoch: [8]  [10/35]  eta: 0:00:07  lr: 0.000454  min_lr: 0.000002  loss: 1.6096 (1.6090)  class_acc: 0.2031 (0.1953)  balanced_accuracy: 0.2101 (0.2067)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3866 (1.3209)  time: 0.3156  data: 0.0638  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [8]  [20/35]  eta: 0:00:04  lr: 0.000449  min_lr: 0.000002  loss: 1.6094 (1.6094)  class_acc: 0.2031 (0.2009)  balanced_accuracy: 0.2122 (0.2125)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3866 (1.3702)  time: 0.2522  data: 0.0009  max mem: 0
Epoch: [8]  [30/35]  eta: 0:00:01  lr: 0.000444  min_lr: 0.000002  loss: 1.6078 (1.6085)  class_acc: 0.1953 (0.2004)  balanced_accuracy: 0.2135 (0.2146)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6124 (1.6428)  time: 0.2519  data: 0.0009  max mem: 0
Epoch: [8]  [34/35]  eta: 0:00:00  lr: 0.000442  min_lr: 0.000002  loss: 1.6078 (1.6084)  class_acc: 0.1953 (0.2013)  balanced_accuracy: 0.2135 (0.2151)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0515 (1.8619)  time: 0.2521  data: 0.0009  max mem: 0
Epoch: [8] Total time: 0:00:09 (0.2761 s / it)
Averaged stats: lr: 0.000442  min_lr: 0.000002  loss: 1.6078 (1.6084)  class_acc: 0.1953 (0.2013)  balanced_accuracy: 0.2135 (0.2151)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0515 (1.8619)
Val:  [0/4]  eta: 0:00:02  loss: 1.6304 (1.6304)  accuracy: 0.1615 (0.1615)  balanced_accuracy: 0.1605 (0.1605)  cohen_kappa: -0.0489 (-0.0489)  f1_weighted: 0.1178 (0.1178)  time: 0.6497  data: 0.5200  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6158 (1.6198)  accuracy: 0.1897 (0.1933)  balanced_accuracy: 0.1876 (0.1929)  cohen_kappa: -0.0135 (-0.0081)  f1_weighted: 0.1472 (0.1528)  time: 0.2573  data: 0.1301  max mem: 0
Val: Total time: 0:00:01 (0.2861 s / it)
* loss 1.620
Accuracy of the network on the 750 val EEG: 0.19%, balanced_accuracy:0.19%
Test:  [0/4]  eta: 0:00:02  loss: 1.6288 (1.6288)  accuracy: 0.2135 (0.2135)  balanced_accuracy: 0.2149 (0.2149)  cohen_kappa: 0.0186 (0.0186)  f1_weighted: 0.1583 (0.1583)  time: 0.6380  data: 0.5079  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6095 (1.6154)  accuracy: 0.2069 (0.2173)  balanced_accuracy: 0.2044 (0.2194)  cohen_kappa: 0.0045 (0.0234)  f1_weighted: 0.1520 (0.1695)  time: 0.2550  data: 0.1274  max mem: 0
Test: Total time: 0:00:01 (0.2839 s / it)
* loss 1.615
Accuracy of the network on the 750 test EEG: 0.22%, balanced_accuracy:0.22%
Accuracy of the network on the 4500 train EEG: 0.20%, balanced_accuracy:0.22%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.20% balanced_accuracy test: 0.21%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [9]  [ 0/35]  eta: 0:00:37  lr: 0.000442  min_lr: 0.000002  loss: 1.5988 (1.5988)  class_acc: 0.1797 (0.1797)  balanced_accuracy: 0.1717 (0.1717)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0378 (2.0378)  time: 1.0607  data: 0.8121  max mem: 0
Epoch: [9]  [10/35]  eta: 0:00:08  lr: 0.000436  min_lr: 0.000002  loss: 1.6089 (1.6081)  class_acc: 0.1953 (0.1974)  balanced_accuracy: 0.2089 (0.2094)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6379 (2.3926)  time: 0.3261  data: 0.0751  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [9]  [20/35]  eta: 0:00:04  lr: 0.000431  min_lr: 0.000002  loss: 1.6098 (1.6097)  class_acc: 0.1953 (0.1987)  balanced_accuracy: 0.2089 (0.2109)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2842 (1.7811)  time: 0.2530  data: 0.0009  max mem: 0
Epoch: [9]  [30/35]  eta: 0:00:01  lr: 0.000425  min_lr: 0.000002  loss: 1.6085 (1.6091)  class_acc: 0.1953 (0.2039)  balanced_accuracy: 0.2071 (0.2119)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0935 (1.5383)  time: 0.2525  data: 0.0008  max mem: 0
Epoch: [9]  [34/35]  eta: 0:00:00  lr: 0.000422  min_lr: 0.000002  loss: 1.6079 (1.6088)  class_acc: 0.2109 (0.2056)  balanced_accuracy: 0.2120 (0.2120)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0526 (1.4719)  time: 0.2521  data: 0.0009  max mem: 0
Epoch: [9] Total time: 0:00:09 (0.2793 s / it)
Averaged stats: lr: 0.000422  min_lr: 0.000002  loss: 1.6079 (1.6088)  class_acc: 0.2109 (0.2056)  balanced_accuracy: 0.2120 (0.2120)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.0526 (1.4719)
Val:  [0/4]  eta: 0:00:02  loss: 1.6141 (1.6141)  accuracy: 0.1823 (0.1823)  balanced_accuracy: 0.1821 (0.1821)  cohen_kappa: -0.0225 (-0.0225)  f1_weighted: 0.1317 (0.1317)  time: 0.6560  data: 0.5282  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6087 (1.6108)  accuracy: 0.1823 (0.2040)  balanced_accuracy: 0.1821 (0.2031)  cohen_kappa: -0.0225 (0.0043)  f1_weighted: 0.1343 (0.1575)  time: 0.2579  data: 0.1321  max mem: 0
Val: Total time: 0:00:01 (0.2868 s / it)
* loss 1.611
Accuracy of the network on the 750 val EEG: 0.20%, balanced_accuracy:0.20%
Test:  [0/4]  eta: 0:00:02  loss: 1.6126 (1.6126)  accuracy: 0.2083 (0.2083)  balanced_accuracy: 0.2105 (0.2105)  cohen_kappa: 0.0131 (0.0131)  f1_weighted: 0.1581 (0.1581)  time: 0.6221  data: 0.4922  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6086 (1.6089)  accuracy: 0.2069 (0.2027)  balanced_accuracy: 0.2057 (0.2031)  cohen_kappa: 0.0043 (0.0025)  f1_weighted: 0.1581 (0.1606)  time: 0.2491  data: 0.1237  max mem: 0
Test: Total time: 0:00:01 (0.2781 s / it)
* loss 1.609
Accuracy of the network on the 750 test EEG: 0.20%, balanced_accuracy:0.20%
Accuracy of the network on the 4500 train EEG: 0.21%, balanced_accuracy:0.21%
Max balanced_accuracy val:0.20%,  balanced_accuracy train: 0.21% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [10]  [ 0/35]  eta: 0:00:32  lr: 0.000422  min_lr: 0.000002  loss: 1.6040 (1.6040)  class_acc: 0.2578 (0.2578)  balanced_accuracy: 0.2543 (0.2543)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9815 (0.9815)  time: 0.9369  data: 0.6859  max mem: 0
Epoch: [10]  [10/35]  eta: 0:00:07  lr: 0.000416  min_lr: 0.000002  loss: 1.6052 (1.6066)  class_acc: 0.2266 (0.2102)  balanced_accuracy: 0.2304 (0.2192)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8268 (1.8365)  time: 0.3162  data: 0.0636  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [10]  [20/35]  eta: 0:00:04  lr: 0.000409  min_lr: 0.000002  loss: 1.6067 (1.6075)  class_acc: 0.2109 (0.2121)  balanced_accuracy: 0.2116 (0.2194)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0592 (2.0266)  time: 0.2534  data: 0.0010  max mem: 0
Epoch: [10]  [30/35]  eta: 0:00:01  lr: 0.000403  min_lr: 0.000001  loss: 1.6064 (1.6069)  class_acc: 0.1953 (0.2069)  balanced_accuracy: 0.2086 (0.2162)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0592 (2.0759)  time: 0.2521  data: 0.0008  max mem: 0
Epoch: [10]  [34/35]  eta: 0:00:00  lr: 0.000400  min_lr: 0.000001  loss: 1.6064 (1.6066)  class_acc: 0.1953 (0.2074)  balanced_accuracy: 0.2148 (0.2158)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0857 (2.2439)  time: 0.2522  data: 0.0007  max mem: 0
Epoch: [10] Total time: 0:00:09 (0.2765 s / it)
Averaged stats: lr: 0.000400  min_lr: 0.000001  loss: 1.6064 (1.6066)  class_acc: 0.1953 (0.2074)  balanced_accuracy: 0.2148 (0.2158)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0857 (2.2439)
Val:  [0/4]  eta: 0:00:02  loss: 1.6238 (1.6238)  accuracy: 0.1875 (0.1875)  balanced_accuracy: 0.1858 (0.1858)  cohen_kappa: -0.0183 (-0.0183)  f1_weighted: 0.1576 (0.1576)  time: 0.6847  data: 0.5554  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6104 (1.6136)  accuracy: 0.1875 (0.2053)  balanced_accuracy: 0.1858 (0.2055)  cohen_kappa: -0.0183 (0.0070)  f1_weighted: 0.1576 (0.1800)  time: 0.2641  data: 0.1389  max mem: 0
Val: Total time: 0:00:01 (0.2933 s / it)
* loss 1.614
Accuracy of the network on the 750 val EEG: 0.21%, balanced_accuracy:0.21%
Test:  [0/4]  eta: 0:00:02  loss: 1.6184 (1.6184)  accuracy: 0.1771 (0.1771)  balanced_accuracy: 0.1752 (0.1752)  cohen_kappa: -0.0311 (-0.0311)  f1_weighted: 0.1327 (0.1327)  time: 0.6706  data: 0.5422  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6083 (1.6109)  accuracy: 0.1823 (0.1973)  balanced_accuracy: 0.1952 (0.1987)  cohen_kappa: -0.0076 (-0.0020)  f1_weighted: 0.1451 (0.1613)  time: 0.2609  data: 0.1358  max mem: 0
Test: Total time: 0:00:01 (0.2897 s / it)
* loss 1.611
Accuracy of the network on the 750 test EEG: 0.20%, balanced_accuracy:0.20%
Accuracy of the network on the 4500 train EEG: 0.21%, balanced_accuracy:0.22%
Max balanced_accuracy val:0.21%,  balanced_accuracy train: 0.22% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [11]  [ 0/35]  eta: 0:00:36  lr: 0.000399  min_lr: 0.000001  loss: 1.6084 (1.6084)  class_acc: 0.2266 (0.2266)  balanced_accuracy: 0.2258 (0.2258)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2396 (2.2396)  time: 1.0308  data: 0.7811  max mem: 0
Epoch: [11]  [10/35]  eta: 0:00:08  lr: 0.000393  min_lr: 0.000001  loss: 1.6063 (1.6063)  class_acc: 0.2344 (0.2330)  balanced_accuracy: 0.2258 (0.2201)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7161 (2.8686)  time: 0.3232  data: 0.0716  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [11]  [20/35]  eta: 0:00:04  lr: 0.000386  min_lr: 0.000001  loss: 1.6071 (1.6083)  class_acc: 0.2266 (0.2254)  balanced_accuracy: 0.2273 (0.2244)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.4409 (3.6404)  time: 0.2520  data: 0.0006  max mem: 0
Epoch: [11]  [30/35]  eta: 0:00:01  lr: 0.000379  min_lr: 0.000001  loss: 1.6032 (1.6060)  class_acc: 0.2188 (0.2253)  balanced_accuracy: 0.2273 (0.2244)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7868 (3.3645)  time: 0.2513  data: 0.0009  max mem: 0
Epoch: [11]  [34/35]  eta: 0:00:00  lr: 0.000376  min_lr: 0.000001  loss: 1.6030 (1.6056)  class_acc: 0.2188 (0.2263)  balanced_accuracy: 0.2295 (0.2243)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7868 (3.3500)  time: 0.2510  data: 0.0009  max mem: 0
Epoch: [11] Total time: 0:00:09 (0.2777 s / it)
Averaged stats: lr: 0.000376  min_lr: 0.000001  loss: 1.6030 (1.6056)  class_acc: 0.2188 (0.2263)  balanced_accuracy: 0.2295 (0.2243)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7868 (3.3500)
Val:  [0/4]  eta: 0:00:02  loss: 1.6220 (1.6220)  accuracy: 0.1615 (0.1615)  balanced_accuracy: 0.1614 (0.1614)  cohen_kappa: -0.0484 (-0.0484)  f1_weighted: 0.1541 (0.1541)  time: 0.6640  data: 0.5364  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6076 (1.6143)  accuracy: 0.1615 (0.1787)  balanced_accuracy: 0.1614 (0.1780)  cohen_kappa: -0.0484 (-0.0269)  f1_weighted: 0.1541 (0.1593)  time: 0.2588  data: 0.1342  max mem: 0
Val: Total time: 0:00:01 (0.2874 s / it)
* loss 1.614
Accuracy of the network on the 750 val EEG: 0.18%, balanced_accuracy:0.18%
Test:  [0/4]  eta: 0:00:02  loss: 1.6197 (1.6197)  accuracy: 0.2083 (0.2083)  balanced_accuracy: 0.2074 (0.2074)  cohen_kappa: 0.0108 (0.0108)  f1_weighted: 0.1979 (0.1979)  time: 0.6693  data: 0.5400  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6076 (1.6109)  accuracy: 0.2083 (0.2040)  balanced_accuracy: 0.2074 (0.2036)  cohen_kappa: 0.0108 (0.0050)  f1_weighted: 0.1979 (0.1865)  time: 0.2610  data: 0.1351  max mem: 0
Test: Total time: 0:00:01 (0.2901 s / it)
* loss 1.611
Accuracy of the network on the 750 test EEG: 0.20%, balanced_accuracy:0.20%
Accuracy of the network on the 4500 train EEG: 0.23%, balanced_accuracy:0.22%
Max balanced_accuracy val:0.21%,  balanced_accuracy train: 0.22% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [12]  [ 0/35]  eta: 0:00:34  lr: 0.000375  min_lr: 0.000001  loss: 1.6056 (1.6056)  class_acc: 0.2031 (0.2031)  balanced_accuracy: 0.2034 (0.2034)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 5.1790 (5.1790)  time: 0.9983  data: 0.7482  max mem: 0
Epoch: [12]  [10/35]  eta: 0:00:08  lr: 0.000368  min_lr: 0.000001  loss: 1.6069 (1.6070)  class_acc: 0.2500 (0.2443)  balanced_accuracy: 0.2328 (0.2388)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7053 (2.8420)  time: 0.3212  data: 0.0694  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [12]  [20/35]  eta: 0:00:04  lr: 0.000361  min_lr: 0.000001  loss: 1.6085 (1.6084)  class_acc: 0.2266 (0.2254)  balanced_accuracy: 0.2235 (0.2291)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4827 (2.6728)  time: 0.2524  data: 0.0011  max mem: 0
Epoch: [12]  [30/35]  eta: 0:00:01  lr: 0.000353  min_lr: 0.000001  loss: 1.6044 (1.6051)  class_acc: 0.2422 (0.2351)  balanced_accuracy: 0.2286 (0.2368)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.5904 (3.3306)  time: 0.2524  data: 0.0009  max mem: 0
Epoch: [12]  [34/35]  eta: 0:00:00  lr: 0.000350  min_lr: 0.000001  loss: 1.6026 (1.6038)  class_acc: 0.2500 (0.2377)  balanced_accuracy: 0.2432 (0.2387)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 4.1545 (3.6749)  time: 0.2526  data: 0.0010  max mem: 0
Epoch: [12] Total time: 0:00:09 (0.2779 s / it)
Averaged stats: lr: 0.000350  min_lr: 0.000001  loss: 1.6026 (1.6038)  class_acc: 0.2500 (0.2377)  balanced_accuracy: 0.2432 (0.2387)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 4.1545 (3.6749)
Val:  [0/4]  eta: 0:00:02  loss: 1.6185 (1.6185)  accuracy: 0.1719 (0.1719)  balanced_accuracy: 0.1733 (0.1733)  cohen_kappa: -0.0335 (-0.0335)  f1_weighted: 0.1177 (0.1177)  time: 0.6775  data: 0.5473  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6165 (1.6192)  accuracy: 0.1897 (0.1987)  balanced_accuracy: 0.1920 (0.1979)  cohen_kappa: -0.0075 (-0.0018)  f1_weighted: 0.1332 (0.1341)  time: 0.2643  data: 0.1369  max mem: 0
Val: Total time: 0:00:01 (0.2937 s / it)
* loss 1.619
Accuracy of the network on the 750 val EEG: 0.20%, balanced_accuracy:0.20%
Test:  [0/4]  eta: 0:00:02  loss: 1.6173 (1.6173)  accuracy: 0.1875 (0.1875)  balanced_accuracy: 0.1870 (0.1870)  cohen_kappa: -0.0162 (-0.0162)  f1_weighted: 0.1331 (0.1331)  time: 0.6560  data: 0.5254  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6099 (1.6112)  accuracy: 0.1875 (0.2027)  balanced_accuracy: 0.1870 (0.2021)  cohen_kappa: -0.0162 (0.0031)  f1_weighted: 0.1331 (0.1363)  time: 0.2582  data: 0.1318  max mem: 0
Test: Total time: 0:00:01 (0.2875 s / it)
* loss 1.611
Accuracy of the network on the 750 test EEG: 0.20%, balanced_accuracy:0.20%
Accuracy of the network on the 4500 train EEG: 0.24%, balanced_accuracy:0.24%
Max balanced_accuracy val:0.21%,  balanced_accuracy train: 0.22% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [13]  [ 0/35]  eta: 0:00:37  lr: 0.000349  min_lr: 0.000001  loss: 1.6007 (1.6007)  class_acc: 0.2422 (0.2422)  balanced_accuracy: 0.2533 (0.2533)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 7.6103 (7.6103)  time: 1.0815  data: 0.8313  max mem: 0
Epoch: [13]  [10/35]  eta: 0:00:08  lr: 0.000342  min_lr: 0.000001  loss: 1.5981 (1.6011)  class_acc: 0.2344 (0.2301)  balanced_accuracy: 0.2509 (0.2352)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 5.1115 (6.2178)  time: 0.3284  data: 0.0762  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [13]  [20/35]  eta: 0:00:04  lr: 0.000334  min_lr: 0.000001  loss: 1.6057 (1.6049)  class_acc: 0.2188 (0.2184)  balanced_accuracy: 0.2248 (0.2265)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0470 (4.7835)  time: 0.2525  data: 0.0005  max mem: 0
Epoch: [13]  [30/35]  eta: 0:00:01  lr: 0.000326  min_lr: 0.000001  loss: 1.6024 (1.6034)  class_acc: 0.2266 (0.2263)  balanced_accuracy: 0.2250 (0.2325)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.2945 (4.7218)  time: 0.2520  data: 0.0007  max mem: 0
Epoch: [13]  [34/35]  eta: 0:00:00  lr: 0.000323  min_lr: 0.000001  loss: 1.5992 (1.6021)  class_acc: 0.2344 (0.2308)  balanced_accuracy: 0.2287 (0.2345)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 4.3873 (4.6631)  time: 0.2519  data: 0.0008  max mem: 0
Epoch: [13] Total time: 0:00:09 (0.2799 s / it)
Averaged stats: lr: 0.000323  min_lr: 0.000001  loss: 1.5992 (1.6021)  class_acc: 0.2344 (0.2308)  balanced_accuracy: 0.2287 (0.2345)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 4.3873 (4.6631)
Val:  [0/4]  eta: 0:00:02  loss: 1.6165 (1.6165)  accuracy: 0.1771 (0.1771)  balanced_accuracy: 0.1781 (0.1781)  cohen_kappa: -0.0272 (-0.0272)  f1_weighted: 0.1465 (0.1465)  time: 0.6325  data: 0.5025  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6165 (1.6203)  accuracy: 0.1927 (0.1920)  balanced_accuracy: 0.1904 (0.1917)  cohen_kappa: -0.0125 (-0.0101)  f1_weighted: 0.1450 (0.1465)  time: 0.2531  data: 0.1257  max mem: 0
Val: Total time: 0:00:01 (0.2820 s / it)
* loss 1.620
Accuracy of the network on the 750 val EEG: 0.19%, balanced_accuracy:0.19%
Test:  [0/4]  eta: 0:00:02  loss: 1.6111 (1.6111)  accuracy: 0.2083 (0.2083)  balanced_accuracy: 0.2100 (0.2100)  cohen_kappa: 0.0126 (0.0126)  f1_weighted: 0.1687 (0.1687)  time: 0.6728  data: 0.5427  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6046 (1.6090)  accuracy: 0.2083 (0.2160)  balanced_accuracy: 0.2100 (0.2163)  cohen_kappa: 0.0126 (0.0203)  f1_weighted: 0.1687 (0.1669)  time: 0.2621  data: 0.1361  max mem: 0
Test: Total time: 0:00:01 (0.2913 s / it)
* loss 1.609
Accuracy of the network on the 750 test EEG: 0.22%, balanced_accuracy:0.22%
Accuracy of the network on the 4500 train EEG: 0.23%, balanced_accuracy:0.23%
Max balanced_accuracy val:0.21%,  balanced_accuracy train: 0.22% balanced_accuracy test: 0.20%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [14]  [ 0/35]  eta: 0:00:35  lr: 0.000322  min_lr: 0.000001  loss: 1.6027 (1.6027)  class_acc: 0.2422 (0.2422)  balanced_accuracy: 0.2448 (0.2448)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 5.5280 (5.5280)  time: 1.0073  data: 0.7575  max mem: 0
Epoch: [14]  [10/35]  eta: 0:00:08  lr: 0.000314  min_lr: 0.000001  loss: 1.5949 (1.5936)  class_acc: 0.2500 (0.2514)  balanced_accuracy: 0.2515 (0.2532)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 5.3362 (5.8246)  time: 0.3228  data: 0.0701  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [14]  [20/35]  eta: 0:00:04  lr: 0.000306  min_lr: 0.000001  loss: 1.5962 (1.5993)  class_acc: 0.2344 (0.2347)  balanced_accuracy: 0.2393 (0.2417)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 5.1836 (5.5229)  time: 0.2544  data: 0.0010  max mem: 0
Epoch: [14]  [30/35]  eta: 0:00:01  lr: 0.000298  min_lr: 0.000001  loss: 1.5962 (1.5960)  class_acc: 0.2344 (0.2382)  balanced_accuracy: 0.2304 (0.2455)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 6.0798 (6.2126)  time: 0.2535  data: 0.0008  max mem: 0
Epoch: [14]  [34/35]  eta: 0:00:00  lr: 0.000295  min_lr: 0.000001  loss: 1.5897 (1.5937)  class_acc: 0.2422 (0.2455)  balanced_accuracy: 0.2507 (0.2519)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 6.5847 (6.6911)  time: 0.2532  data: 0.0010  max mem: 0
Epoch: [14] Total time: 0:00:09 (0.2791 s / it)
Averaged stats: lr: 0.000295  min_lr: 0.000001  loss: 1.5897 (1.5937)  class_acc: 0.2422 (0.2455)  balanced_accuracy: 0.2507 (0.2519)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 6.5847 (6.6911)
Val:  [0/4]  eta: 0:00:02  loss: 1.6131 (1.6131)  accuracy: 0.2031 (0.2031)  balanced_accuracy: 0.2038 (0.2038)  cohen_kappa: 0.0046 (0.0046)  f1_weighted: 0.1945 (0.1945)  time: 0.6363  data: 0.5053  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6130 (1.6188)  accuracy: 0.1927 (0.2107)  balanced_accuracy: 0.1911 (0.2110)  cohen_kappa: -0.0124 (0.0134)  f1_weighted: 0.1740 (0.1957)  time: 0.2529  data: 0.1267  max mem: 0
Val: Total time: 0:00:01 (0.2817 s / it)
* loss 1.619
Accuracy of the network on the 750 val EEG: 0.21%, balanced_accuracy:0.21%
Test:  [0/4]  eta: 0:00:02  loss: 1.6120 (1.6120)  accuracy: 0.1719 (0.1719)  balanced_accuracy: 0.1734 (0.1734)  cohen_kappa: -0.0323 (-0.0323)  f1_weighted: 0.1643 (0.1643)  time: 0.6831  data: 0.5533  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6061 (1.6069)  accuracy: 0.2188 (0.2120)  balanced_accuracy: 0.2110 (0.2111)  cohen_kappa: 0.0173 (0.0153)  f1_weighted: 0.1924 (0.1929)  time: 0.2667  data: 0.1389  max mem: 0
Test: Total time: 0:00:01 (0.2962 s / it)
* loss 1.607
Accuracy of the network on the 750 test EEG: 0.21%, balanced_accuracy:0.21%
Accuracy of the network on the 4500 train EEG: 0.25%, balanced_accuracy:0.25%
Max balanced_accuracy val:0.21%,  balanced_accuracy train: 0.25% balanced_accuracy test: 0.21%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [15]  [ 0/35]  eta: 0:00:34  lr: 0.000294  min_lr: 0.000001  loss: 1.5917 (1.5917)  class_acc: 0.2734 (0.2734)  balanced_accuracy: 0.2811 (0.2811)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 15.8484 (15.8484)  time: 0.9757  data: 0.7254  max mem: 0
Epoch: [15]  [10/35]  eta: 0:00:08  lr: 0.000286  min_lr: 0.000001  loss: 1.5828 (1.5825)  class_acc: 0.2656 (0.2642)  balanced_accuracy: 0.2654 (0.2656)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 12.2485 (13.0541)  time: 0.3210  data: 0.0674  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [15]  [20/35]  eta: 0:00:04  lr: 0.000277  min_lr: 0.000001  loss: 1.5866 (1.5883)  class_acc: 0.2500 (0.2537)  balanced_accuracy: 0.2645 (0.2581)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 9.9487 (11.3430)  time: 0.2536  data: 0.0010  max mem: 0
Epoch: [15]  [30/35]  eta: 0:00:01  lr: 0.000269  min_lr: 0.000001  loss: 1.5866 (1.5854)  class_acc: 0.2500 (0.2588)  balanced_accuracy: 0.2658 (0.2636)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 8.6488 (10.8120)  time: 0.2519  data: 0.0008  max mem: 0
Epoch: [15]  [34/35]  eta: 0:00:00  lr: 0.000266  min_lr: 0.000001  loss: 1.5724 (1.5817)  class_acc: 0.2734 (0.2623)  balanced_accuracy: 0.2823 (0.2664)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 9.9415 (11.2721)  time: 0.2523  data: 0.0008  max mem: 0
Epoch: [15] Total time: 0:00:09 (0.2778 s / it)
Averaged stats: lr: 0.000266  min_lr: 0.000001  loss: 1.5724 (1.5817)  class_acc: 0.2734 (0.2623)  balanced_accuracy: 0.2823 (0.2664)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 9.9415 (11.2721)
Val:  [0/4]  eta: 0:00:02  loss: 1.6140 (1.6140)  accuracy: 0.2344 (0.2344)  balanced_accuracy: 0.2348 (0.2348)  cohen_kappa: 0.0438 (0.0438)  f1_weighted: 0.2310 (0.2310)  time: 0.6298  data: 0.4995  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6140 (1.6201)  accuracy: 0.2344 (0.2227)  balanced_accuracy: 0.2330 (0.2228)  cohen_kappa: 0.0405 (0.0285)  f1_weighted: 0.2208 (0.2135)  time: 0.2511  data: 0.1254  max mem: 0
Val: Total time: 0:00:01 (0.2801 s / it)
* loss 1.620
Accuracy of the network on the 750 val EEG: 0.22%, balanced_accuracy:0.22%
Test:  [0/4]  eta: 0:00:02  loss: 1.6204 (1.6204)  accuracy: 0.2083 (0.2083)  balanced_accuracy: 0.2097 (0.2097)  cohen_kappa: 0.0126 (0.0126)  f1_weighted: 0.2026 (0.2026)  time: 0.6576  data: 0.5273  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6080 (1.6063)  accuracy: 0.2083 (0.2493)  balanced_accuracy: 0.2097 (0.2488)  cohen_kappa: 0.0126 (0.0621)  f1_weighted: 0.2026 (0.2311)  time: 0.2598  data: 0.1321  max mem: 0
Test: Total time: 0:00:01 (0.2892 s / it)
* loss 1.606
Accuracy of the network on the 750 test EEG: 0.25%, balanced_accuracy:0.25%
Accuracy of the network on the 4500 train EEG: 0.26%, balanced_accuracy:0.27%
Max balanced_accuracy val:0.22%,  balanced_accuracy train: 0.27% balanced_accuracy test: 0.25%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [16]  [ 0/35]  eta: 0:00:34  lr: 0.000265  min_lr: 0.000001  loss: 1.5690 (1.5690)  class_acc: 0.2891 (0.2891)  balanced_accuracy: 0.2728 (0.2728)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 11.3983 (11.3983)  time: 0.9838  data: 0.7250  max mem: 0
Epoch: [16]  [10/35]  eta: 0:00:08  lr: 0.000257  min_lr: 0.000001  loss: 1.5513 (1.5521)  class_acc: 0.2969 (0.3004)  balanced_accuracy: 0.2749 (0.2972)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 16.8140 (16.9782)  time: 0.3210  data: 0.0673  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [16]  [20/35]  eta: 0:00:04  lr: 0.000248  min_lr: 0.000001  loss: 1.5584 (1.5655)  class_acc: 0.2734 (0.2827)  balanced_accuracy: 0.2749 (0.2840)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 17.1585 (18.6252)  time: 0.2547  data: 0.0009  max mem: 0
Epoch: [16]  [30/35]  eta: 0:00:01  lr: 0.000240  min_lr: 0.000001  loss: 1.5574 (1.5626)  class_acc: 0.2734 (0.2828)  balanced_accuracy: 0.2756 (0.2834)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 14.5853 (18.0009)  time: 0.2540  data: 0.0006  max mem: 0
Epoch: [16]  [34/35]  eta: 0:00:00  lr: 0.000237  min_lr: 0.000001  loss: 1.5503 (1.5589)  class_acc: 0.2891 (0.2862)  balanced_accuracy: 0.2820 (0.2861)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 15.4822 (18.8193)  time: 0.2531  data: 0.0008  max mem: 0
Epoch: [16] Total time: 0:00:09 (0.2788 s / it)
Averaged stats: lr: 0.000237  min_lr: 0.000001  loss: 1.5503 (1.5589)  class_acc: 0.2891 (0.2862)  balanced_accuracy: 0.2820 (0.2861)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 15.4822 (18.8193)
Val:  [0/4]  eta: 0:00:02  loss: 1.6294 (1.6294)  accuracy: 0.2135 (0.2135)  balanced_accuracy: 0.2132 (0.2132)  cohen_kappa: 0.0170 (0.0170)  f1_weighted: 0.1810 (0.1810)  time: 0.6666  data: 0.5376  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6348 (1.6518)  accuracy: 0.2344 (0.2333)  balanced_accuracy: 0.2315 (0.2325)  cohen_kappa: 0.0393 (0.0412)  f1_weighted: 0.2098 (0.2082)  time: 0.2607  data: 0.1348  max mem: 0
Val: Total time: 0:00:01 (0.2896 s / it)
* loss 1.652
Accuracy of the network on the 750 val EEG: 0.23%, balanced_accuracy:0.23%
Test:  [0/4]  eta: 0:00:02  loss: 1.6521 (1.6521)  accuracy: 0.2292 (0.2292)  balanced_accuracy: 0.2326 (0.2326)  cohen_kappa: 0.0401 (0.0401)  f1_weighted: 0.1977 (0.1977)  time: 0.6690  data: 0.5378  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6269 (1.6330)  accuracy: 0.2292 (0.2453)  balanced_accuracy: 0.2326 (0.2448)  cohen_kappa: 0.0401 (0.0565)  f1_weighted: 0.1977 (0.2186)  time: 0.2626  data: 0.1345  max mem: 0
Test: Total time: 0:00:01 (0.2918 s / it)
* loss 1.633
Accuracy of the network on the 750 test EEG: 0.25%, balanced_accuracy:0.25%
Accuracy of the network on the 4500 train EEG: 0.29%, balanced_accuracy:0.29%
Max balanced_accuracy val:0.23%,  balanced_accuracy train: 0.29% balanced_accuracy test: 0.25%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [17]  [ 0/35]  eta: 0:00:37  lr: 0.000236  min_lr: 0.000001  loss: 1.5617 (1.5617)  class_acc: 0.2656 (0.2656)  balanced_accuracy: 0.2700 (0.2700)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 34.8299 (34.8299)  time: 1.0815  data: 0.8013  max mem: 0
Epoch: [17]  [10/35]  eta: 0:00:08  lr: 0.000228  min_lr: 0.000001  loss: 1.5111 (1.5190)  class_acc: 0.3281 (0.3345)  balanced_accuracy: 0.3338 (0.3313)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 22.6504 (26.1994)  time: 0.3286  data: 0.0734  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [17]  [20/35]  eta: 0:00:04  lr: 0.000219  min_lr: 0.000001  loss: 1.5316 (1.5316)  class_acc: 0.3203 (0.3162)  balanced_accuracy: 0.3130 (0.3158)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 23.1874 (26.3378)  time: 0.2557  data: 0.0004  max mem: 0
Epoch: [17]  [30/35]  eta: 0:00:01  lr: 0.000211  min_lr: 0.000001  loss: 1.5443 (1.5341)  class_acc: 0.2969 (0.3110)  balanced_accuracy: 0.2990 (0.3104)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 22.1212 (24.7340)  time: 0.2559  data: 0.0007  max mem: 0
Epoch: [17]  [34/35]  eta: 0:00:00  lr: 0.000208  min_lr: 0.000001  loss: 1.5277 (1.5278)  class_acc: 0.3047 (0.3183)  balanced_accuracy: 0.3006 (0.3171)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 22.9183 (25.3205)  time: 0.2550  data: 0.0009  max mem: 0
Epoch: [17] Total time: 0:00:09 (0.2822 s / it)
Averaged stats: lr: 0.000208  min_lr: 0.000001  loss: 1.5277 (1.5278)  class_acc: 0.3047 (0.3183)  balanced_accuracy: 0.3006 (0.3171)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 22.9183 (25.3205)
Val:  [0/4]  eta: 0:00:02  loss: 1.6563 (1.6563)  accuracy: 0.2188 (0.2188)  balanced_accuracy: 0.2178 (0.2178)  cohen_kappa: 0.0227 (0.0227)  f1_weighted: 0.2059 (0.2059)  time: 0.6101  data: 0.4804  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6666 (1.6667)  accuracy: 0.2188 (0.2280)  balanced_accuracy: 0.2178 (0.2278)  cohen_kappa: 0.0227 (0.0345)  f1_weighted: 0.2094 (0.2161)  time: 0.2480  data: 0.1204  max mem: 0
Val: Total time: 0:00:01 (0.2772 s / it)
* loss 1.667
Accuracy of the network on the 750 val EEG: 0.23%, balanced_accuracy:0.23%
Test:  [0/4]  eta: 0:00:02  loss: 1.6360 (1.6360)  accuracy: 0.2344 (0.2344)  balanced_accuracy: 0.2327 (0.2327)  cohen_kappa: 0.0414 (0.0414)  f1_weighted: 0.2249 (0.2249)  time: 0.6266  data: 0.4960  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6336 (1.6363)  accuracy: 0.2471 (0.2667)  balanced_accuracy: 0.2474 (0.2658)  cohen_kappa: 0.0596 (0.0830)  f1_weighted: 0.2387 (0.2532)  time: 0.2509  data: 0.1245  max mem: 0
Test: Total time: 0:00:01 (0.2802 s / it)
* loss 1.636
Accuracy of the network on the 750 test EEG: 0.27%, balanced_accuracy:0.27%
Accuracy of the network on the 4500 train EEG: 0.32%, balanced_accuracy:0.32%
Max balanced_accuracy val:0.23%,  balanced_accuracy train: 0.29% balanced_accuracy test: 0.25%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [18]  [ 0/35]  eta: 0:00:33  lr: 0.000207  min_lr: 0.000001  loss: 1.5218 (1.5218)  class_acc: 0.3594 (0.3594)  balanced_accuracy: 0.3667 (0.3667)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 41.8253 (41.8253)  time: 0.9672  data: 0.7170  max mem: 0
Epoch: [18]  [10/35]  eta: 0:00:08  lr: 0.000199  min_lr: 0.000001  loss: 1.4692 (1.4656)  class_acc: 0.3672 (0.3729)  balanced_accuracy: 0.3667 (0.3739)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 32.6103 (34.8910)  time: 0.3203  data: 0.0658  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [18]  [20/35]  eta: 0:00:04  lr: 0.000191  min_lr: 0.000001  loss: 1.4793 (1.4839)  class_acc: 0.3594 (0.3571)  balanced_accuracy: 0.3611 (0.3588)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 33.7819 (37.0661)  time: 0.2546  data: 0.0006  max mem: 0
Epoch: [18]  [30/35]  eta: 0:00:01  lr: 0.000183  min_lr: 0.000001  loss: 1.4954 (1.4877)  class_acc: 0.3281 (0.3556)  balanced_accuracy: 0.3408 (0.3583)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 31.4615 (33.7172)  time: 0.2541  data: 0.0009  max mem: 0
Epoch: [18]  [34/35]  eta: 0:00:00  lr: 0.000180  min_lr: 0.000001  loss: 1.4712 (1.4803)  class_acc: 0.3594 (0.3629)  balanced_accuracy: 0.3612 (0.3648)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 31.1291 (33.4749)  time: 0.2540  data: 0.0009  max mem: 0
Epoch: [18] Total time: 0:00:09 (0.2788 s / it)
Averaged stats: lr: 0.000180  min_lr: 0.000001  loss: 1.4712 (1.4803)  class_acc: 0.3594 (0.3629)  balanced_accuracy: 0.3612 (0.3648)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 31.1291 (33.4749)
Val:  [0/4]  eta: 0:00:02  loss: 1.6738 (1.6738)  accuracy: 0.2135 (0.2135)  balanced_accuracy: 0.2132 (0.2132)  cohen_kappa: 0.0169 (0.0169)  f1_weighted: 0.2105 (0.2105)  time: 0.6612  data: 0.5314  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.6936 (1.6929)  accuracy: 0.2135 (0.2227)  balanced_accuracy: 0.2132 (0.2233)  cohen_kappa: 0.0169 (0.0290)  f1_weighted: 0.2105 (0.2132)  time: 0.2609  data: 0.1331  max mem: 0
Val: Total time: 0:00:01 (0.2898 s / it)
* loss 1.693
Accuracy of the network on the 750 val EEG: 0.22%, balanced_accuracy:0.22%
Test:  [0/4]  eta: 0:00:02  loss: 1.7181 (1.7181)  accuracy: 0.2344 (0.2344)  balanced_accuracy: 0.2332 (0.2332)  cohen_kappa: 0.0425 (0.0425)  f1_weighted: 0.2298 (0.2298)  time: 0.6280  data: 0.4984  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6710 (1.6923)  accuracy: 0.2344 (0.2520)  balanced_accuracy: 0.2332 (0.2514)  cohen_kappa: 0.0425 (0.0650)  f1_weighted: 0.2298 (0.2440)  time: 0.2522  data: 0.1251  max mem: 0
Test: Total time: 0:00:01 (0.2814 s / it)
* loss 1.692
Accuracy of the network on the 750 test EEG: 0.25%, balanced_accuracy:0.25%
Accuracy of the network on the 4500 train EEG: 0.36%, balanced_accuracy:0.36%
Max balanced_accuracy val:0.23%,  balanced_accuracy train: 0.29% balanced_accuracy test: 0.25%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [19]  [ 0/35]  eta: 0:00:35  lr: 0.000179  min_lr: 0.000001  loss: 1.4640 (1.4640)  class_acc: 0.3750 (0.3750)  balanced_accuracy: 0.3767 (0.3767)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 61.0304 (61.0304)  time: 1.0067  data: 0.7562  max mem: 0
Epoch: [19]  [10/35]  eta: 0:00:08  lr: 0.000171  min_lr: 0.000001  loss: 1.4018 (1.4157)  class_acc: 0.4219 (0.4169)  balanced_accuracy: 0.4183 (0.4141)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 44.2020 (45.3122)  time: 0.3235  data: 0.0696  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [19]  [20/35]  eta: 0:00:04  lr: 0.000163  min_lr: 0.000001  loss: 1.4232 (1.4334)  class_acc: 0.4141 (0.4007)  balanced_accuracy: 0.4077 (0.4027)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 40.2443 (43.4384)  time: 0.2547  data: 0.0007  max mem: 0
Epoch: [19]  [30/35]  eta: 0:00:01  lr: 0.000155  min_lr: 0.000001  loss: 1.4487 (1.4404)  class_acc: 0.3672 (0.3879)  balanced_accuracy: 0.3726 (0.3889)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 35.6317 (40.5899)  time: 0.2532  data: 0.0007  max mem: 0
Epoch: [19]  [34/35]  eta: 0:00:00  lr: 0.000152  min_lr: 0.000001  loss: 1.4456 (1.4372)  class_acc: 0.3672 (0.3904)  balanced_accuracy: 0.3736 (0.3912)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 35.2648 (40.7613)  time: 0.2526  data: 0.0009  max mem: 0
Epoch: [19] Total time: 0:00:09 (0.2791 s / it)
Averaged stats: lr: 0.000152  min_lr: 0.000001  loss: 1.4456 (1.4372)  class_acc: 0.3672 (0.3904)  balanced_accuracy: 0.3736 (0.3912)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 35.2648 (40.7613)
Val:  [0/4]  eta: 0:00:02  loss: 1.7100 (1.7100)  accuracy: 0.2344 (0.2344)  balanced_accuracy: 0.2332 (0.2332)  cohen_kappa: 0.0423 (0.0423)  f1_weighted: 0.2226 (0.2226)  time: 0.7078  data: 0.5778  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.7100 (1.7184)  accuracy: 0.2396 (0.2413)  balanced_accuracy: 0.2407 (0.2412)  cohen_kappa: 0.0497 (0.0516)  f1_weighted: 0.2226 (0.2270)  time: 0.2711  data: 0.1445  max mem: 0
Val: Total time: 0:00:01 (0.3002 s / it)
* loss 1.718
Accuracy of the network on the 750 val EEG: 0.24%, balanced_accuracy:0.24%
Test:  [0/4]  eta: 0:00:02  loss: 1.7412 (1.7412)  accuracy: 0.2656 (0.2656)  balanced_accuracy: 0.2637 (0.2637)  cohen_kappa: 0.0803 (0.0803)  f1_weighted: 0.2526 (0.2526)  time: 0.6288  data: 0.4995  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.6917 (1.7219)  accuracy: 0.2656 (0.2627)  balanced_accuracy: 0.2637 (0.2630)  cohen_kappa: 0.0803 (0.0786)  f1_weighted: 0.2479 (0.2469)  time: 0.2504  data: 0.1249  max mem: 0
Test: Total time: 0:00:01 (0.2788 s / it)
* loss 1.722
Accuracy of the network on the 750 test EEG: 0.26%, balanced_accuracy:0.26%
Accuracy of the network on the 4500 train EEG: 0.39%, balanced_accuracy:0.39%
Max balanced_accuracy val:0.24%,  balanced_accuracy train: 0.39% balanced_accuracy test: 0.26%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [20]  [ 0/35]  eta: 0:00:35  lr: 0.000152  min_lr: 0.000001  loss: 1.4334 (1.4334)  class_acc: 0.3750 (0.3750)  balanced_accuracy: 0.3765 (0.3765)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 45.1126 (45.1126)  time: 1.0276  data: 0.7778  max mem: 0
Epoch: [20]  [10/35]  eta: 0:00:08  lr: 0.000144  min_lr: 0.000001  loss: 1.3631 (1.3659)  class_acc: 0.4375 (0.4503)  balanced_accuracy: 0.4357 (0.4520)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 44.5413 (45.3777)  time: 0.3248  data: 0.0712  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [20]  [20/35]  eta: 0:00:04  lr: 0.000137  min_lr: 0.000001  loss: 1.3718 (1.3881)  class_acc: 0.4297 (0.4323)  balanced_accuracy: 0.4354 (0.4366)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 48.1657 (52.9622)  time: 0.2540  data: 0.0005  max mem: 0
Epoch: [20]  [30/35]  eta: 0:00:01  lr: 0.000129  min_lr: 0.000000  loss: 1.4044 (1.3997)  class_acc: 0.4297 (0.4254)  balanced_accuracy: 0.4100 (0.4310)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 45.9752 (49.4108)  time: 0.2535  data: 0.0008  max mem: 0
Epoch: [20]  [34/35]  eta: 0:00:00  lr: 0.000126  min_lr: 0.000000  loss: 1.4006 (1.3959)  class_acc: 0.4297 (0.4275)  balanced_accuracy: 0.4393 (0.4325)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 45.8051 (49.1536)  time: 0.2532  data: 0.0008  max mem: 0
Epoch: [20] Total time: 0:00:09 (0.2799 s / it)
Averaged stats: lr: 0.000126  min_lr: 0.000000  loss: 1.4006 (1.3959)  class_acc: 0.4297 (0.4275)  balanced_accuracy: 0.4393 (0.4325)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 45.8051 (49.1536)
Val:  [0/4]  eta: 0:00:02  loss: 1.7401 (1.7401)  accuracy: 0.2396 (0.2396)  balanced_accuracy: 0.2381 (0.2381)  cohen_kappa: 0.0485 (0.0485)  f1_weighted: 0.2174 (0.2174)  time: 0.6763  data: 0.5470  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.7401 (1.7467)  accuracy: 0.2448 (0.2467)  balanced_accuracy: 0.2459 (0.2466)  cohen_kappa: 0.0567 (0.0583)  f1_weighted: 0.2252 (0.2306)  time: 0.2626  data: 0.1370  max mem: 0
Val: Total time: 0:00:01 (0.2916 s / it)
* loss 1.747
Accuracy of the network on the 750 val EEG: 0.25%, balanced_accuracy:0.25%
Test:  [0/4]  eta: 0:00:02  loss: 1.8174 (1.8174)  accuracy: 0.2656 (0.2656)  balanced_accuracy: 0.2633 (0.2633)  cohen_kappa: 0.0798 (0.0798)  f1_weighted: 0.2479 (0.2479)  time: 0.6438  data: 0.5146  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.7382 (1.7543)  accuracy: 0.2656 (0.2613)  balanced_accuracy: 0.2633 (0.2621)  cohen_kappa: 0.0798 (0.0766)  f1_weighted: 0.2479 (0.2502)  time: 0.2544  data: 0.1289  max mem: 0
Test: Total time: 0:00:01 (0.2835 s / it)
* loss 1.754
Accuracy of the network on the 750 test EEG: 0.26%, balanced_accuracy:0.26%
Accuracy of the network on the 4500 train EEG: 0.43%, balanced_accuracy:0.43%
Max balanced_accuracy val:0.25%,  balanced_accuracy train: 0.43% balanced_accuracy test: 0.26%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [21]  [ 0/35]  eta: 0:00:33  lr: 0.000126  min_lr: 0.000000  loss: 1.3815 (1.3815)  class_acc: 0.3828 (0.3828)  balanced_accuracy: 0.3850 (0.3850)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 59.6184 (59.6184)  time: 0.9524  data: 0.7018  max mem: 0
Epoch: [21]  [10/35]  eta: 0:00:07  lr: 0.000119  min_lr: 0.000000  loss: 1.3305 (1.3270)  class_acc: 0.4766 (0.4709)  balanced_accuracy: 0.4888 (0.4737)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 40.1054 (47.2502)  time: 0.3185  data: 0.0652  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [21]  [20/35]  eta: 0:00:04  lr: 0.000112  min_lr: 0.000000  loss: 1.3452 (1.3497)  class_acc: 0.4609 (0.4606)  balanced_accuracy: 0.4649 (0.4645)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 44.1732 (53.6126)  time: 0.2545  data: 0.0010  max mem: 0
Epoch: [21]  [30/35]  eta: 0:00:01  lr: 0.000105  min_lr: 0.000000  loss: 1.3565 (1.3592)  class_acc: 0.4375 (0.4556)  balanced_accuracy: 0.4499 (0.4587)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 53.8376 (57.1966)  time: 0.2540  data: 0.0008  max mem: 0
Epoch: [21]  [34/35]  eta: 0:00:00  lr: 0.000102  min_lr: 0.000000  loss: 1.3452 (1.3547)  class_acc: 0.4375 (0.4540)  balanced_accuracy: 0.4395 (0.4562)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 53.7772 (57.0622)  time: 0.2538  data: 0.0008  max mem: 0
Epoch: [21] Total time: 0:00:09 (0.2780 s / it)
Averaged stats: lr: 0.000102  min_lr: 0.000000  loss: 1.3452 (1.3547)  class_acc: 0.4375 (0.4540)  balanced_accuracy: 0.4395 (0.4562)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 53.7772 (57.0622)
Val:  [0/4]  eta: 0:00:02  loss: 1.7357 (1.7357)  accuracy: 0.2344 (0.2344)  balanced_accuracy: 0.2332 (0.2332)  cohen_kappa: 0.0421 (0.0421)  f1_weighted: 0.2264 (0.2264)  time: 0.6486  data: 0.5191  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.7471 (1.7551)  accuracy: 0.2396 (0.2600)  balanced_accuracy: 0.2407 (0.2599)  cohen_kappa: 0.0502 (0.0752)  f1_weighted: 0.2264 (0.2484)  time: 0.2561  data: 0.1304  max mem: 0
Val: Total time: 0:00:01 (0.2852 s / it)
* loss 1.755
Accuracy of the network on the 750 val EEG: 0.26%, balanced_accuracy:0.26%
Test:  [0/4]  eta: 0:00:02  loss: 1.8463 (1.8463)  accuracy: 0.2344 (0.2344)  balanced_accuracy: 0.2338 (0.2338)  cohen_kappa: 0.0432 (0.0432)  f1_weighted: 0.2248 (0.2248)  time: 0.6609  data: 0.5319  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.7389 (1.7712)  accuracy: 0.2471 (0.2693)  balanced_accuracy: 0.2472 (0.2702)  cohen_kappa: 0.0569 (0.0870)  f1_weighted: 0.2265 (0.2610)  time: 0.2589  data: 0.1330  max mem: 0
Test: Total time: 0:00:01 (0.2880 s / it)
* loss 1.771
Accuracy of the network on the 750 test EEG: 0.27%, balanced_accuracy:0.27%
Accuracy of the network on the 4500 train EEG: 0.45%, balanced_accuracy:0.46%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [22]  [ 0/35]  eta: 0:00:33  lr: 0.000102  min_lr: 0.000000  loss: 1.3361 (1.3361)  class_acc: 0.4688 (0.4688)  balanced_accuracy: 0.4548 (0.4548)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 69.4047 (69.4047)  time: 0.9618  data: 0.7114  max mem: 0
Epoch: [22]  [10/35]  eta: 0:00:07  lr: 0.000095  min_lr: 0.000000  loss: 1.2639 (1.2863)  class_acc: 0.5000 (0.5092)  balanced_accuracy: 0.5078 (0.5097)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 60.6610 (64.2869)  time: 0.3186  data: 0.0653  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [22]  [20/35]  eta: 0:00:04  lr: 0.000089  min_lr: 0.000000  loss: 1.3073 (1.3074)  class_acc: 0.4844 (0.4914)  balanced_accuracy: 0.4858 (0.4935)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 69.0236 (71.9179)  time: 0.2557  data: 0.0007  max mem: 0
Epoch: [22]  [30/35]  eta: 0:00:01  lr: 0.000082  min_lr: 0.000000  loss: 1.3348 (1.3194)  class_acc: 0.4609 (0.4806)  balanced_accuracy: 0.4659 (0.4827)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 74.7781 (69.6123)  time: 0.2556  data: 0.0009  max mem: 0
Epoch: [22]  [34/35]  eta: 0:00:00  lr: 0.000080  min_lr: 0.000000  loss: 1.3073 (1.3105)  class_acc: 0.4766 (0.4871)  balanced_accuracy: 0.4689 (0.4884)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 74.7781 (67.5435)  time: 0.2552  data: 0.0009  max mem: 0
Epoch: [22] Total time: 0:00:09 (0.2791 s / it)
Averaged stats: lr: 0.000080  min_lr: 0.000000  loss: 1.3073 (1.3105)  class_acc: 0.4766 (0.4871)  balanced_accuracy: 0.4689 (0.4884)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 74.7781 (67.5435)
Val:  [0/4]  eta: 0:00:02  loss: 1.7544 (1.7544)  accuracy: 0.2344 (0.2344)  balanced_accuracy: 0.2335 (0.2335)  cohen_kappa: 0.0424 (0.0424)  f1_weighted: 0.2267 (0.2267)  time: 0.6411  data: 0.5120  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.7613 (1.7778)  accuracy: 0.2356 (0.2480)  balanced_accuracy: 0.2364 (0.2481)  cohen_kappa: 0.0454 (0.0603)  f1_weighted: 0.2267 (0.2373)  time: 0.2541  data: 0.1285  max mem: 0
Val: Total time: 0:00:01 (0.2828 s / it)
* loss 1.778
Accuracy of the network on the 750 val EEG: 0.25%, balanced_accuracy:0.25%
Test:  [0/4]  eta: 0:00:02  loss: 1.8600 (1.8600)  accuracy: 0.2656 (0.2656)  balanced_accuracy: 0.2650 (0.2650)  cohen_kappa: 0.0821 (0.0821)  f1_weighted: 0.2548 (0.2548)  time: 0.6667  data: 0.5368  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.7918 (1.8164)  accuracy: 0.2656 (0.2733)  balanced_accuracy: 0.2650 (0.2740)  cohen_kappa: 0.0821 (0.0924)  f1_weighted: 0.2548 (0.2668)  time: 0.2602  data: 0.1343  max mem: 0
Test: Total time: 0:00:01 (0.2891 s / it)
* loss 1.816
Accuracy of the network on the 750 test EEG: 0.27%, balanced_accuracy:0.27%
Accuracy of the network on the 4500 train EEG: 0.49%, balanced_accuracy:0.49%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [23]  [ 0/35]  eta: 0:00:36  lr: 0.000079  min_lr: 0.000000  loss: 1.2674 (1.2674)  class_acc: 0.4922 (0.4922)  balanced_accuracy: 0.4836 (0.4836)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 39.9678 (39.9678)  time: 1.0354  data: 0.7848  max mem: 0
Epoch: [23]  [10/35]  eta: 0:00:08  lr: 0.000073  min_lr: 0.000000  loss: 1.2674 (1.2489)  class_acc: 0.5078 (0.5213)  balanced_accuracy: 0.5184 (0.5252)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 55.6669 (54.9017)  time: 0.3262  data: 0.0721  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [23]  [20/35]  eta: 0:00:04  lr: 0.000068  min_lr: 0.000000  loss: 1.2479 (1.2528)  class_acc: 0.5078 (0.5145)  balanced_accuracy: 0.5161 (0.5163)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 52.7269 (55.7254)  time: 0.2545  data: 0.0006  max mem: 0
Epoch: [23]  [30/35]  eta: 0:00:01  lr: 0.000062  min_lr: 0.000000  loss: 1.2626 (1.2708)  class_acc: 0.4922 (0.5013)  balanced_accuracy: 0.4946 (0.5034)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 56.3351 (59.8284)  time: 0.2532  data: 0.0006  max mem: 0
Epoch: [23]  [34/35]  eta: 0:00:00  lr: 0.000060  min_lr: 0.000000  loss: 1.2626 (1.2648)  class_acc: 0.4922 (0.5060)  balanced_accuracy: 0.4962 (0.5076)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 58.9378 (59.6376)  time: 0.2525  data: 0.0007  max mem: 0
Epoch: [23] Total time: 0:00:09 (0.2800 s / it)
Averaged stats: lr: 0.000060  min_lr: 0.000000  loss: 1.2626 (1.2648)  class_acc: 0.4922 (0.5060)  balanced_accuracy: 0.4962 (0.5076)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 58.9378 (59.6376)
Val:  [0/4]  eta: 0:00:02  loss: 1.8037 (1.8037)  accuracy: 0.2292 (0.2292)  balanced_accuracy: 0.2282 (0.2282)  cohen_kappa: 0.0361 (0.0361)  f1_weighted: 0.2237 (0.2237)  time: 0.5375  data: 0.4069  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.8313 (1.8422)  accuracy: 0.2292 (0.2373)  balanced_accuracy: 0.2282 (0.2377)  cohen_kappa: 0.0361 (0.0472)  f1_weighted: 0.2237 (0.2316)  time: 0.2291  data: 0.1025  max mem: 0
Val: Total time: 0:00:01 (0.2580 s / it)
* loss 1.842
Accuracy of the network on the 750 val EEG: 0.24%, balanced_accuracy:0.24%
Test:  [0/4]  eta: 0:00:02  loss: 1.9086 (1.9086)  accuracy: 0.2917 (0.2917)  balanced_accuracy: 0.2910 (0.2910)  cohen_kappa: 0.1140 (0.1140)  f1_weighted: 0.2833 (0.2833)  time: 0.6778  data: 0.5485  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.8224 (1.8701)  accuracy: 0.2448 (0.2693)  balanced_accuracy: 0.2453 (0.2698)  cohen_kappa: 0.0581 (0.0873)  f1_weighted: 0.2443 (0.2635)  time: 0.2630  data: 0.1374  max mem: 0
Test: Total time: 0:00:01 (0.2982 s / it)
* loss 1.870
Accuracy of the network on the 750 test EEG: 0.27%, balanced_accuracy:0.27%
Accuracy of the network on the 4500 train EEG: 0.51%, balanced_accuracy:0.51%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [24]  [ 0/35]  eta: 0:00:37  lr: 0.000059  min_lr: 0.000000  loss: 1.2562 (1.2562)  class_acc: 0.5312 (0.5312)  balanced_accuracy: 0.5235 (0.5235)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 65.1373 (65.1373)  time: 1.0605  data: 0.8105  max mem: 0
Epoch: [24]  [10/35]  eta: 0:00:08  lr: 0.000054  min_lr: 0.000000  loss: 1.2355 (1.2332)  class_acc: 0.5312 (0.5312)  balanced_accuracy: 0.5302 (0.5349)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 65.0692 (61.3083)  time: 0.3278  data: 0.0742  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [24]  [20/35]  eta: 0:00:04  lr: 0.000049  min_lr: 0.000000  loss: 1.2374 (1.2451)  class_acc: 0.5234 (0.5242)  balanced_accuracy: 0.5280 (0.5261)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 65.0692 (65.0582)  time: 0.2548  data: 0.0005  max mem: 0
Epoch: [24]  [30/35]  eta: 0:00:01  lr: 0.000044  min_lr: 0.000000  loss: 1.2567 (1.2562)  class_acc: 0.4922 (0.5159)  balanced_accuracy: 0.4954 (0.5177)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 68.5422 (66.7919)  time: 0.2538  data: 0.0007  max mem: 0
Epoch: [24]  [34/35]  eta: 0:00:00  lr: 0.000043  min_lr: 0.000000  loss: 1.2454 (1.2505)  class_acc: 0.5000 (0.5170)  balanced_accuracy: 0.5047 (0.5183)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 69.6174 (66.1110)  time: 0.2522  data: 0.0008  max mem: 0
Epoch: [24] Total time: 0:00:09 (0.2808 s / it)
Averaged stats: lr: 0.000043  min_lr: 0.000000  loss: 1.2454 (1.2505)  class_acc: 0.5000 (0.5170)  balanced_accuracy: 0.5047 (0.5183)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 69.6174 (66.1110)
Val:  [0/4]  eta: 0:00:02  loss: 1.7950 (1.7950)  accuracy: 0.2604 (0.2604)  balanced_accuracy: 0.2601 (0.2601)  cohen_kappa: 0.0754 (0.0754)  f1_weighted: 0.2547 (0.2547)  time: 0.6374  data: 0.5089  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.8477 (1.8491)  accuracy: 0.2240 (0.2307)  balanced_accuracy: 0.2252 (0.2312)  cohen_kappa: 0.0297 (0.0388)  f1_weighted: 0.2202 (0.2252)  time: 0.2537  data: 0.1278  max mem: 0
Val: Total time: 0:00:01 (0.2829 s / it)
* loss 1.849
Accuracy of the network on the 750 val EEG: 0.23%, balanced_accuracy:0.23%
Test:  [0/4]  eta: 0:00:02  loss: 1.9010 (1.9010)  accuracy: 0.2552 (0.2552)  balanced_accuracy: 0.2539 (0.2539)  cohen_kappa: 0.0678 (0.0678)  f1_weighted: 0.2509 (0.2509)  time: 0.6086  data: 0.4795  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.8218 (1.8601)  accuracy: 0.2500 (0.2627)  balanced_accuracy: 0.2500 (0.2628)  cohen_kappa: 0.0645 (0.0791)  f1_weighted: 0.2466 (0.2588)  time: 0.2460  data: 0.1203  max mem: 0
Test: Total time: 0:00:01 (0.2851 s / it)
* loss 1.860
Accuracy of the network on the 750 test EEG: 0.26%, balanced_accuracy:0.26%
Accuracy of the network on the 4500 train EEG: 0.52%, balanced_accuracy:0.52%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [25]  [ 0/35]  eta: 0:00:35  lr: 0.000042  min_lr: 0.000000  loss: 1.2566 (1.2566)  class_acc: 0.5078 (0.5078)  balanced_accuracy: 0.5067 (0.5067)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 73.6053 (73.6053)  time: 1.0195  data: 0.7510  max mem: 0
Epoch: [25]  [10/35]  eta: 0:00:08  lr: 0.000038  min_lr: 0.000000  loss: 1.1801 (1.1882)  class_acc: 0.5859 (0.5661)  balanced_accuracy: 0.5883 (0.5720)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 56.3791 (59.1393)  time: 0.3275  data: 0.0687  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [25]  [20/35]  eta: 0:00:04  lr: 0.000033  min_lr: 0.000000  loss: 1.2082 (1.2229)  class_acc: 0.5469 (0.5372)  balanced_accuracy: 0.5440 (0.5413)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 63.7408 (65.1220)  time: 0.2562  data: 0.0006  max mem: 0
Epoch: [25]  [30/35]  eta: 0:00:01  lr: 0.000029  min_lr: 0.000000  loss: 1.2296 (1.2232)  class_acc: 0.5234 (0.5297)  balanced_accuracy: 0.5328 (0.5329)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 67.8105 (67.4698)  time: 0.2535  data: 0.0008  max mem: 0
Epoch: [25]  [34/35]  eta: 0:00:00  lr: 0.000028  min_lr: 0.000000  loss: 1.2082 (1.2153)  class_acc: 0.5234 (0.5346)  balanced_accuracy: 0.5328 (0.5370)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 65.4738 (67.2765)  time: 0.2528  data: 0.0008  max mem: 0
Epoch: [25] Total time: 0:00:09 (0.2805 s / it)
Averaged stats: lr: 0.000028  min_lr: 0.000000  loss: 1.2082 (1.2153)  class_acc: 0.5234 (0.5346)  balanced_accuracy: 0.5328 (0.5370)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 65.4738 (67.2765)
Val:  [0/4]  eta: 0:00:02  loss: 1.7999 (1.7999)  accuracy: 0.2500 (0.2500)  balanced_accuracy: 0.2494 (0.2494)  cohen_kappa: 0.0618 (0.0618)  f1_weighted: 0.2456 (0.2456)  time: 0.6227  data: 0.4939  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.8825 (1.8721)  accuracy: 0.2500 (0.2453)  balanced_accuracy: 0.2494 (0.2456)  cohen_kappa: 0.0618 (0.0570)  f1_weighted: 0.2456 (0.2409)  time: 0.2509  data: 0.1240  max mem: 0
Val: Total time: 0:00:01 (0.2802 s / it)
* loss 1.872
Accuracy of the network on the 750 val EEG: 0.25%, balanced_accuracy:0.25%
Test:  [0/4]  eta: 0:00:02  loss: 1.9489 (1.9489)  accuracy: 0.2552 (0.2552)  balanced_accuracy: 0.2543 (0.2543)  cohen_kappa: 0.0689 (0.0689)  f1_weighted: 0.2532 (0.2532)  time: 0.5986  data: 0.4647  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.8314 (1.8953)  accuracy: 0.2448 (0.2613)  balanced_accuracy: 0.2448 (0.2614)  cohen_kappa: 0.0581 (0.0773)  f1_weighted: 0.2459 (0.2587)  time: 0.2454  data: 0.1169  max mem: 0
Test: Total time: 0:00:01 (0.2742 s / it)
* loss 1.895
Accuracy of the network on the 750 test EEG: 0.26%, balanced_accuracy:0.26%
Accuracy of the network on the 4500 train EEG: 0.53%, balanced_accuracy:0.54%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [26]  [ 0/35]  eta: 0:00:36  lr: 0.000028  min_lr: 0.000000  loss: 1.2119 (1.2119)  class_acc: 0.5312 (0.5312)  balanced_accuracy: 0.5231 (0.5231)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 109.9473 (109.9473)  time: 1.0383  data: 0.7887  max mem: 0
Epoch: [26]  [10/35]  eta: 0:00:08  lr: 0.000024  min_lr: 0.000000  loss: 1.1865 (1.1921)  class_acc: 0.5625 (0.5568)  balanced_accuracy: 0.5656 (0.5590)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 59.8800 (65.3159)  time: 0.3242  data: 0.0722  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [26]  [20/35]  eta: 0:00:04  lr: 0.000021  min_lr: 0.000000  loss: 1.1926 (1.2071)  class_acc: 0.5547 (0.5528)  balanced_accuracy: 0.5508 (0.5540)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 59.8800 (68.8373)  time: 0.2527  data: 0.0006  max mem: 0
Epoch: [26]  [30/35]  eta: 0:00:01  lr: 0.000017  min_lr: 0.000000  loss: 1.2126 (1.2097)  class_acc: 0.5391 (0.5507)  balanced_accuracy: 0.5455 (0.5521)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 55.4941 (64.8672)  time: 0.2525  data: 0.0008  max mem: 0
Epoch: [26]  [34/35]  eta: 0:00:00  lr: 0.000016  min_lr: 0.000000  loss: 1.2053 (1.2048)  class_acc: 0.5469 (0.5518)  balanced_accuracy: 0.5456 (0.5528)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 60.6026 (64.9569)  time: 0.2523  data: 0.0009  max mem: 0
Epoch: [26] Total time: 0:00:09 (0.2789 s / it)
Averaged stats: lr: 0.000016  min_lr: 0.000000  loss: 1.2053 (1.2048)  class_acc: 0.5469 (0.5518)  balanced_accuracy: 0.5456 (0.5528)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 60.6026 (64.9569)
Val:  [0/4]  eta: 0:00:02  loss: 1.7937 (1.7937)  accuracy: 0.2552 (0.2552)  balanced_accuracy: 0.2547 (0.2547)  cohen_kappa: 0.0686 (0.0686)  f1_weighted: 0.2518 (0.2518)  time: 0.6043  data: 0.4749  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.8845 (1.8737)  accuracy: 0.2396 (0.2413)  balanced_accuracy: 0.2401 (0.2418)  cohen_kappa: 0.0501 (0.0520)  f1_weighted: 0.2382 (0.2388)  time: 0.2451  data: 0.1193  max mem: 0
Val: Total time: 0:00:01 (0.2752 s / it)
* loss 1.874
Accuracy of the network on the 750 val EEG: 0.24%, balanced_accuracy:0.24%
Test:  [0/4]  eta: 0:00:02  loss: 1.9338 (1.9338)  accuracy: 0.2552 (0.2552)  balanced_accuracy: 0.2553 (0.2553)  cohen_kappa: 0.0692 (0.0692)  f1_weighted: 0.2523 (0.2523)  time: 0.6253  data: 0.4960  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.8501 (1.8964)  accuracy: 0.2356 (0.2560)  balanced_accuracy: 0.2363 (0.2564)  cohen_kappa: 0.0458 (0.0710)  f1_weighted: 0.2320 (0.2527)  time: 0.2501  data: 0.1244  max mem: 0
Test: Total time: 0:00:01 (0.2824 s / it)
* loss 1.896
Accuracy of the network on the 750 test EEG: 0.26%, balanced_accuracy:0.26%
Accuracy of the network on the 4500 train EEG: 0.55%, balanced_accuracy:0.55%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [27]  [ 0/35]  eta: 0:00:36  lr: 0.000016  min_lr: 0.000000  loss: 1.1701 (1.1701)  class_acc: 0.5703 (0.5703)  balanced_accuracy: 0.5619 (0.5619)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 64.0873 (64.0873)  time: 1.0331  data: 0.7835  max mem: 0
Epoch: [27]  [10/35]  eta: 0:00:08  lr: 0.000013  min_lr: 0.000000  loss: 1.1542 (1.1514)  class_acc: 0.5859 (0.5930)  balanced_accuracy: 0.5806 (0.5930)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 65.5047 (73.6196)  time: 0.3243  data: 0.0718  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [27]  [20/35]  eta: 0:00:04  lr: 0.000011  min_lr: 0.000000  loss: 1.1585 (1.1704)  class_acc: 0.5859 (0.5796)  balanced_accuracy: 0.5806 (0.5794)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 72.6279 (71.1214)  time: 0.2530  data: 0.0007  max mem: 0
Epoch: [27]  [30/35]  eta: 0:00:01  lr: 0.000009  min_lr: 0.000000  loss: 1.2030 (1.1870)  class_acc: 0.5469 (0.5655)  balanced_accuracy: 0.5474 (0.5667)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 61.7840 (67.2049)  time: 0.2532  data: 0.0010  max mem: 0
Epoch: [27]  [34/35]  eta: 0:00:00  lr: 0.000008  min_lr: 0.000000  loss: 1.1976 (1.1795)  class_acc: 0.5625 (0.5681)  balanced_accuracy: 0.5597 (0.5687)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 55.4609 (66.0538)  time: 0.2530  data: 0.0010  max mem: 0
Epoch: [27] Total time: 0:00:09 (0.2792 s / it)
Averaged stats: lr: 0.000008  min_lr: 0.000000  loss: 1.1976 (1.1795)  class_acc: 0.5625 (0.5681)  balanced_accuracy: 0.5597 (0.5687)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 55.4609 (66.0538)
Val:  [0/4]  eta: 0:00:02  loss: 1.8031 (1.8031)  accuracy: 0.2604 (0.2604)  balanced_accuracy: 0.2602 (0.2602)  cohen_kappa: 0.0753 (0.0753)  f1_weighted: 0.2583 (0.2583)  time: 0.6845  data: 0.5541  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.8993 (1.8867)  accuracy: 0.2292 (0.2360)  balanced_accuracy: 0.2292 (0.2363)  cohen_kappa: 0.0367 (0.0454)  f1_weighted: 0.2274 (0.2350)  time: 0.2648  data: 0.1388  max mem: 0
Val: Total time: 0:00:01 (0.2942 s / it)
* loss 1.887
Accuracy of the network on the 750 val EEG: 0.24%, balanced_accuracy:0.24%
Test:  [0/4]  eta: 0:00:02  loss: 1.9404 (1.9404)  accuracy: 0.2240 (0.2240)  balanced_accuracy: 0.2240 (0.2240)  cohen_kappa: 0.0302 (0.0302)  f1_weighted: 0.2218 (0.2218)  time: 0.6535  data: 0.5235  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.8610 (1.9030)  accuracy: 0.2188 (0.2400)  balanced_accuracy: 0.2205 (0.2404)  cohen_kappa: 0.0256 (0.0511)  f1_weighted: 0.2163 (0.2365)  time: 0.2584  data: 0.1312  max mem: 0
Test: Total time: 0:00:01 (0.2871 s / it)
* loss 1.903
Accuracy of the network on the 750 test EEG: 0.24%, balanced_accuracy:0.24%
Accuracy of the network on the 4500 train EEG: 0.57%, balanced_accuracy:0.57%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [28]  [ 0/35]  eta: 0:00:33  lr: 0.000008  min_lr: 0.000000  loss: 1.2000 (1.2000)  class_acc: 0.5312 (0.5312)  balanced_accuracy: 0.5252 (0.5252)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 104.6502 (104.6502)  time: 0.9702  data: 0.7178  max mem: 0
Epoch: [28]  [10/35]  eta: 0:00:08  lr: 0.000006  min_lr: 0.000000  loss: 1.1702 (1.1646)  class_acc: 0.5703 (0.5746)  balanced_accuracy: 0.5794 (0.5771)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 69.7671 (72.3576)  time: 0.3200  data: 0.0663  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [28]  [20/35]  eta: 0:00:04  lr: 0.000004  min_lr: 0.000000  loss: 1.1702 (1.1726)  class_acc: 0.5703 (0.5692)  balanced_accuracy: 0.5794 (0.5704)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 69.7671 (70.7114)  time: 0.2545  data: 0.0008  max mem: 0
Epoch: [28]  [30/35]  eta: 0:00:01  lr: 0.000003  min_lr: 0.000000  loss: 1.1823 (1.1856)  class_acc: 0.5703 (0.5610)  balanced_accuracy: 0.5704 (0.5632)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 52.9003 (64.7176)  time: 0.2547  data: 0.0008  max mem: 0
Epoch: [28]  [34/35]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000000  loss: 1.1678 (1.1807)  class_acc: 0.5703 (0.5625)  balanced_accuracy: 0.5717 (0.5642)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 52.8944 (63.3021)  time: 0.2543  data: 0.0009  max mem: 0
Epoch: [28] Total time: 0:00:09 (0.2788 s / it)
Averaged stats: lr: 0.000003  min_lr: 0.000000  loss: 1.1678 (1.1807)  class_acc: 0.5703 (0.5625)  balanced_accuracy: 0.5717 (0.5642)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 52.8944 (63.3021)
Val:  [0/4]  eta: 0:00:02  loss: 1.8100 (1.8100)  accuracy: 0.2604 (0.2604)  balanced_accuracy: 0.2602 (0.2602)  cohen_kappa: 0.0754 (0.0754)  f1_weighted: 0.2583 (0.2583)  time: 0.6353  data: 0.5023  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.9068 (1.8920)  accuracy: 0.2344 (0.2413)  balanced_accuracy: 0.2346 (0.2419)  cohen_kappa: 0.0438 (0.0522)  f1_weighted: 0.2326 (0.2393)  time: 0.2532  data: 0.1261  max mem: 0
Val: Total time: 0:00:01 (0.2825 s / it)
* loss 1.892
Accuracy of the network on the 750 val EEG: 0.24%, balanced_accuracy:0.24%
Test:  [0/4]  eta: 0:00:02  loss: 1.9545 (1.9545)  accuracy: 0.2344 (0.2344)  balanced_accuracy: 0.2339 (0.2339)  cohen_kappa: 0.0430 (0.0430)  f1_weighted: 0.2299 (0.2299)  time: 0.6468  data: 0.5172  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.8610 (1.9101)  accuracy: 0.2344 (0.2453)  balanced_accuracy: 0.2339 (0.2458)  cohen_kappa: 0.0430 (0.0577)  f1_weighted: 0.2299 (0.2416)  time: 0.2558  data: 0.1298  max mem: 0
Test: Total time: 0:00:01 (0.2835 s / it)
* loss 1.910
Accuracy of the network on the 750 test EEG: 0.25%, balanced_accuracy:0.25%
Accuracy of the network on the 4500 train EEG: 0.56%, balanced_accuracy:0.56%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
[SANITY] step=0 min=-45.01 max=32.77 mean=0.2403 std=2.049
Epoch: [29]  [ 0/35]  eta: 0:00:35  lr: 0.000003  min_lr: 0.000000  loss: 1.2083 (1.2083)  class_acc: 0.5156 (0.5156)  balanced_accuracy: 0.5097 (0.5097)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 79.0247 (79.0247)  time: 1.0195  data: 0.7690  max mem: 0
Epoch: [29]  [10/35]  eta: 0:00:08  lr: 0.000002  min_lr: 0.000000  loss: 1.1470 (1.1425)  class_acc: 0.5781 (0.5938)  balanced_accuracy: 0.5871 (0.5956)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 67.1522 (64.2613)  time: 0.3251  data: 0.0707  max mem: 0
[SANITY] step=20 min=-19.09 max=24.5 mean=0.2307 std=1.288
Epoch: [29]  [20/35]  eta: 0:00:04  lr: 0.000001  min_lr: 0.000000  loss: 1.1622 (1.1599)  class_acc: 0.5781 (0.5807)  balanced_accuracy: 0.5860 (0.5835)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 53.9090 (61.4892)  time: 0.2552  data: 0.0008  max mem: 0
Epoch: [29]  [30/35]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000000  loss: 1.1870 (1.1724)  class_acc: 0.5625 (0.5731)  balanced_accuracy: 0.5638 (0.5752)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 54.1137 (60.3976)  time: 0.2545  data: 0.0008  max mem: 0
Epoch: [29]  [34/35]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000000  loss: 1.1828 (1.1696)  class_acc: 0.5625 (0.5723)  balanced_accuracy: 0.5630 (0.5734)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 52.8699 (58.8338)  time: 0.2541  data: 0.0007  max mem: 0
Epoch: [29] Total time: 0:00:09 (0.2804 s / it)
Averaged stats: lr: 0.000001  min_lr: 0.000000  loss: 1.1828 (1.1696)  class_acc: 0.5625 (0.5723)  balanced_accuracy: 0.5630 (0.5734)  loss_scale: 256.0000 (256.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 52.8699 (58.8338)
Val:  [0/4]  eta: 0:00:02  loss: 1.8121 (1.8121)  accuracy: 0.2656 (0.2656)  balanced_accuracy: 0.2653 (0.2653)  cohen_kappa: 0.0818 (0.0818)  f1_weighted: 0.2628 (0.2628)  time: 0.6430  data: 0.5123  max mem: 0
Val:  [3/4]  eta: 0:00:00  loss: 1.9084 (1.8937)  accuracy: 0.2344 (0.2440)  balanced_accuracy: 0.2346 (0.2445)  cohen_kappa: 0.0438 (0.0555)  f1_weighted: 0.2324 (0.2416)  time: 0.2561  data: 0.1281  max mem: 0
Val: Total time: 0:00:01 (0.2848 s / it)
* loss 1.894
Accuracy of the network on the 750 val EEG: 0.24%, balanced_accuracy:0.24%
Test:  [0/4]  eta: 0:00:02  loss: 1.9587 (1.9587)  accuracy: 0.2396 (0.2396)  balanced_accuracy: 0.2390 (0.2390)  cohen_kappa: 0.0494 (0.0494)  f1_weighted: 0.2351 (0.2351)  time: 0.6497  data: 0.5194  max mem: 0
Test:  [3/4]  eta: 0:00:00  loss: 1.8601 (1.9122)  accuracy: 0.2344 (0.2453)  balanced_accuracy: 0.2359 (0.2457)  cohen_kappa: 0.0454 (0.0576)  f1_weighted: 0.2298 (0.2417)  time: 0.2585  data: 0.1306  max mem: 0
Test: Total time: 0:00:01 (0.2879 s / it)
* loss 1.912
Accuracy of the network on the 750 test EEG: 0.25%, balanced_accuracy:0.25%
Accuracy of the network on the 4500 train EEG: 0.57%, balanced_accuracy:0.57%
Max balanced_accuracy val:0.26%,  balanced_accuracy train: 0.46% balanced_accuracy test: 0.27%
Training time 0:06:30

Process finished with exit code 0
