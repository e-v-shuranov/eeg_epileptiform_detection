{
 "cells": [
  {
   "cell_type": "code",
   "id": "9b4cd8f0-ef98-4fbb-a1b2-d589c0163494",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-29T13:39:27.567795Z",
     "start_time": "2024-12-29T13:39:26.466575Z"
    }
   },
   "source": [
    "import os\n",
    "import pywt\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import resample"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "d4c9908f-1a70-463c-8ab6-ddd6dc1f432a",
   "metadata": {},
   "source": [
    "### Checking the path to the directories"
   ]
  },
  {
   "cell_type": "code",
   "id": "e542657c-d8de-41d3-83f3-c0aaa41db932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:39:33.274056Z",
     "start_time": "2024-12-29T13:39:33.229317Z"
    }
   },
   "source": [
    "train_out_dir = '/Volumes/PHILIPS/train_files_TUEV'\n",
    "eval_out_dir = '/Volumes/PHILIPS/test_files_TUEV'\n",
    "\n",
    "data_path = \"/media/public/Datasets/TUEV/tuev/edf/processed_banana_half\"\n",
    "\n",
    "train_files = os.listdir(data_path + '/processed_train_banana')\n",
    "val_files = os.listdir(data_path + '/processed_eval_banana')\n",
    "test_files = os.listdir(data_path + '/processed_test_banana')\n",
    "\n",
    "print(f'length of train files: {len(train_files)}')\n",
    "print(f'length of eval files: {len(val_files)}')\n",
    "print(f'length of test files: {len(test_files)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train files: 65290\n",
      "length of eval files: 18642\n",
      "length of test files: 28305\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "25c6fb5c-0747-4093-9dc9-afc6db08d185",
   "metadata": {},
   "source": [
    "### Wavelet tranformation for a single file"
   ]
  },
  {
   "cell_type": "code",
   "id": "c9a1ca1f-c78e-4987-82eb-c5dd5050451a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:39:41.559029Z",
     "start_time": "2024-12-29T13:39:41.533431Z"
    }
   },
   "source": [
    "test_file = data_path + '/processed_train_banana/aaaaablw_00000001-0.pkl' # path to a pickle file\n",
    "sample = pickle.load(open(os.path.join(test_file), \"rb\"))\n",
    "\n",
    "X = sample[\"signal\"]\n",
    "coeffs = pywt.dwt(X, 'haar')  # Perform discrete Haar wavelet transform\n",
    "X = coeffs[0]\n",
    "\n",
    "Y = int(sample[\"label\"][0] - 1)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "88564ef0-fc3e-4043-b8af-f53c76844da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:39:43.764440Z",
     "start_time": "2024-12-29T13:39:43.756692Z"
    }
   },
   "source": [
    "print(X.shape)\n",
    "print(type(X))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 500)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "802cd0b7-7fda-40d9-b92b-52e6f8d6e28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:41:06.683402Z",
     "start_time": "2024-12-29T13:41:06.675123Z"
    }
   },
   "source": [
    "class TUEVLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, files, sampling_rate=200):\n",
    "        self.root = root\n",
    "        self.files = files\n",
    "        self.default_rate = 200\n",
    "        self.sampling_rate = sampling_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = pickle.load(open(os.path.join(self.root, self.files[index]), \"rb\"))\n",
    "        X = sample[\"signal\"]\n",
    "        if self.sampling_rate != self.default_rate:\n",
    "            X = resample(X, 5 * self.sampling_rate, axis=-1)\n",
    "\n",
    "        coefficients = pywt.dwt(X, 'haar')  # Perform discrete Haar wavelet transform\n",
    "        X = coefficients[0]\n",
    "        Y = int(sample[\"label\"][0] - 1)\n",
    "        \n",
    "        return X, Y\n",
    "    \n",
    "\n",
    "def prepare_TUEV_dataset():\n",
    "    # set random seed\n",
    "    seed = 4523\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # path to train, val, test files. Might need to be changed depending on your file organisation\n",
    "    # train_files = os.listdir(\"/Volumes/PHILIPS/train_files_TUEV/train_files\")\n",
    "    # val_files = os.listdir(\"/Volumes/PHILIPS/train_files_TUEV/eval_files\")\n",
    "    # test_files = os.listdir(\"/Volumes/PHILIPS/test_files_TUEV/test_files\")\n",
    "    data_path = \"/media/public/Datasets/TUEV/tuev/edf/processed_banana_half\"\n",
    "    \n",
    "    train_files = os.listdir(data_path + '/processed_train_banana')\n",
    "    val_files = os.listdir(data_path + '/processed_eval_banana')\n",
    "    test_files = os.listdir(data_path + '/processed_test_banana')\n",
    "\n",
    "    # prepare training and test data loader\n",
    "    train_dataset = TUEVLoader(\n",
    "        os.path.join(data_path + '/processed_train_banana'), train_files\n",
    "    )\n",
    "    test_dataset = TUEVLoader(\n",
    "        os.path.join(data_path + '/processed_test_banana'), test_files\n",
    "    )\n",
    "    val_dataset = TUEVLoader(\n",
    "        os.path.join(data_path + '/processed_eval_banana'), val_files\n",
    "    )\n",
    "    print(len(train_files), len(val_files), len(test_files))\n",
    "    return train_dataset, test_dataset, val_dataset"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "62539c41-bee4-4124-be27-3cae951c56d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:41:07.380722Z",
     "start_time": "2024-12-29T13:41:07.374Z"
    }
   },
   "source": [
    "def get_TUEV_dataset():\n",
    "    train_dataset, test_dataset, val_dataset = prepare_TUEV_dataset()\n",
    "    ch_names = ['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', \\\n",
    "                'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', 'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF', 'EEG T1-REF', 'EEG T2-REF']\n",
    "    ch_names_after_convert = ['FP1-F7', 'F7-T3', 'T3-T5', 'T5-O1',\n",
    "                              'FP2-F8', 'F8-T4', 'T4-T6', 'T6-O2',\n",
    "                              'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1',\n",
    "                              'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2']\n",
    "\n",
    "    new_ch_names = [\"FP1-F7\", \"F7-T7\", \"T7-P7\", \"P7-O1\",\n",
    "                    \"FP2-F8\", \"F8-T8\", \"T8-P8\", \"P8-O2\",\n",
    "                    \"FP1-F3\", \"F3-C3\", \"C3-P3\", \"P3-O1\",\n",
    "                    \"FP2-F4\", \"F4-C4\", \"C4-P4\", \"P4-O2\"]\n",
    "\n",
    "    new_ch_names_to_128 = [\"FP1-F7\", \"F7-T7\", \"T7-P7\", \"P7-O1\",\n",
    "                    \"FP2-F8\", \"F8-T8\", \"T8-P8\", \"P8-O2\"]\n",
    "\n",
    "\n",
    "    ch_names = [name.split(' ')[-1].split('-')[0] for name in ch_names_after_convert]\n",
    "    # args.nb_classes = 6\n",
    "    metrics = [\"accuracy\", \"balanced_accuracy\", \"cohen_kappa\"]\n",
    "    return train_dataset, test_dataset, val_dataset, new_ch_names_to_128, metrics"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "96fba64b-7c15-4c93-9af6-348cd3331383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:41:08.497487Z",
     "start_time": "2024-12-29T13:41:08.453795Z"
    }
   },
   "source": [
    "dataset_train, dataset_test, dataset_val, ch_names, metrics = get_TUEV_dataset()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65290 18642 28305\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:42:37.266883Z",
     "start_time": "2024-12-29T13:41:09.248566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_list, y_list = [], []\n",
    "for X_batch, y_batch in dataset_train:\n",
    "    X_list.append(X_batch)\n",
    "    y_list.append(y_batch)"
   ],
   "id": "539a8a40cc23ebd9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:42:40.737602Z",
     "start_time": "2024-12-29T13:42:37.337942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_list_test, y_list_test = [], []\n",
    "for X_batch, y_batch in dataset_test:\n",
    "    X_list_test.append(X_batch)\n",
    "    y_list_test.append(y_batch)\n",
    "    \n",
    "X_list_eval, y_list_eval = [], []\n",
    "for X_batch, y_batch in dataset_val:\n",
    "    X_list_eval.append(X_batch)\n",
    "    y_list_eval.append(y_batch)"
   ],
   "id": "bfa202a063539349",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:42:40.830868Z",
     "start_time": "2024-12-29T13:42:40.826159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(X_list))\n",
    "print(len(X_list[0]))\n",
    "print(len(X_list_test))\n",
    "print(len(X_list_test[0]))\n",
    "print(len(X_list_eval))\n",
    "print(len(X_list_eval[0]))"
   ],
   "id": "2615eaa63cb5f418",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65290\n",
      "8\n",
      "28305\n",
      "8\n",
      "18642\n",
      "8\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:45:16.044739Z",
     "start_time": "2024-12-29T13:45:15.614466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tmp = np.array(X_list)\n",
    "print(tmp.shape)\n",
    "X = tmp.reshape(65290, 4000)\n",
    "print(X.shape)\n",
    "y_list = np.array(y_list)\n",
    "print(y_list.shape)"
   ],
   "id": "6c6805a7a3718610",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65290, 8, 500)\n",
      "(65290, 4000)\n",
      "(65290,)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:46:00.157786Z",
     "start_time": "2024-12-29T13:46:00.028955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tmp = np.array(X_list_test)\n",
    "print(tmp.shape)\n",
    "X_test = tmp.reshape(28305, 4000)\n",
    "print(X_test.shape)\n",
    "y_list_test = np.array(y_list_test)\n",
    "print(y_list_test.shape)"
   ],
   "id": "46350121a62834fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28305, 8, 500)\n",
      "(28305, 4000)\n",
      "(28305,)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:46:15.683961Z",
     "start_time": "2024-12-29T13:46:15.596349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tmp = np.array(X_list_eval)\n",
    "X_eval = tmp.reshape(18642, 4000)\n",
    "print(X_eval.shape)\n",
    "y_list_eval = np.array(y_list_eval)\n",
    "print(y_list_eval.shape)"
   ],
   "id": "d1eb75a2bdd775a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18642, 4000)\n",
      "(18642,)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:52:56.673768Z",
     "start_time": "2024-12-29T13:52:54.913177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"/media/public/Datasets/TUEV/tuev/edf/wavelet_preprocess_half_banana/\"\n",
    "np.save(data_path + \"X_train_values_DWT.npy\", X)\n",
    "np.save(data_path + \"y_train_values_DWT.npy\", y_list)\n",
    "\n",
    "np.save(data_path + \"/X_test_values_DWT.npy\", X_test)\n",
    "np.save(data_path + \"/y_test_values_DWT.npy\", y_list_test)\n",
    "\n",
    "np.save(data_path + \"/X_val_values_DWT.npy\", X_eval)\n",
    "np.save(data_path + \"/y_val_values_DWT.npy\", y_list_eval)"
   ],
   "id": "f7be328f875af9fd",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "94087643-bec0-45bb-9e18-2a032297b102",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee75d086-ba7d-4f09-9675-161d67fb109f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:49:55.158485Z",
     "start_time": "2024-12-29T13:49:54.902292Z"
    }
   },
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "820146e1-07c1-492a-81aa-bd0f42efc62c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:54:26.884424Z",
     "start_time": "2024-12-29T13:54:25.218203Z"
    }
   },
   "source": [
    "data_path = \"/media/public/Datasets/TUEV/tuev/edf/wavelet_preprocess_half_banana/\"\n",
    "\n",
    "X_train = np.load(data_path + \"X_train_values_DWT.npy\")\n",
    "y_train = np.load(data_path + \"y_train_values_DWT.npy\")\n",
    "\n",
    "X_test = np.load(data_path + \"X_test_values_DWT.npy\")\n",
    "y_test = np.load(data_path + \"y_test_values_DWT.npy\")\n",
    "\n",
    "X_eval = np.load(data_path + \"X_val_values_DWT.npy\")\n",
    "y_eval = np.load(data_path + \"y_val_values_DWT.npy\")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "c3038f92-ab43-451f-ace9-88572db3b928",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-29T13:54:36.747929Z"
    }
   },
   "source": [
    "xgb_clf = GradientBoostingClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "with open(\"xgb_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(xgb_clf, file)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4bb58af1-7f5d-4ce5-b752-92d704017b00",
   "metadata": {},
   "source": [
    "### Test metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "329db603-b38c-48df-9145-145d73785249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.2576929871047518\n",
      "Accuracy: 0.7423070128952481\n",
      "Precision: 0.4446869639219509, Recall: 0.4067162525821333, F1-Score: 0.4165019914809527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Hamming Loss\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification Report\n",
    "# report = classification_report(y_test, y_pred, target_names=[f\"Class {i}\" for i in range(y_test.shape[1])])\n",
    "# print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94ac7980-3540-4d98-a300-a0a1621abc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        spsw       0.05      0.03      0.04       567\n",
      "        gped       0.66      0.46      0.54      3561\n",
      "        pled       0.29      0.15      0.20      1998\n",
      "        eyem       0.38      0.48      0.42       329\n",
      "        artf       0.47      0.40      0.43      2204\n",
      "       backg       0.81      0.92      0.86     19646\n",
      "\n",
      "    accuracy                           0.74     28305\n",
      "   macro avg       0.44      0.41      0.42     28305\n",
      "weighted avg       0.71      0.74      0.72     28305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred, target_names=['spsw', 'gped', 'pled', 'eyem', 'artf', 'backg'])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ed598-d3a5-4272-9603-0063380b2207",
   "metadata": {},
   "source": [
    "### Train metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65d05b4a-f57a-4c8e-9bce-99602782b538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        spsw       0.97      0.98      0.97       475\n",
      "        gped       0.97      0.87      0.92     10654\n",
      "        pled       0.97      0.73      0.83      4683\n",
      "        eyem       0.92      0.87      0.89       977\n",
      "        artf       0.98      0.80      0.88      9870\n",
      "       backg       0.91      1.00      0.95     43187\n",
      "\n",
      "    accuracy                           0.93     69846\n",
      "   macro avg       0.95      0.87      0.91     69846\n",
      "weighted avg       0.93      0.93      0.93     69846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predict = xgb_clf.predict(X_train)\n",
    "train_report = classification_report(y_train, train_predict, target_names=['spsw', 'gped', 'pled', 'eyem', 'artf', 'backg'])\n",
    "print(\"Classification Report:\\n\", train_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6958b-8093-4d82-b18c-8ed6f98b4db7",
   "metadata": {},
   "source": [
    "### Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf017de-af7e-40e1-ada8-5345c0d37b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        spsw       0.04      0.04      0.04       170\n",
      "        gped       0.38      0.45      0.41       600\n",
      "        pled       0.89      0.37      0.52      1501\n",
      "        eyem       0.22      0.42      0.29        93\n",
      "        artf       0.55      0.33      0.42      1183\n",
      "       backg       0.86      0.95      0.90     10539\n",
      "\n",
      "    accuracy                           0.80     14086\n",
      "   macro avg       0.49      0.43      0.43     14086\n",
      "weighted avg       0.80      0.80      0.79     14086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_predict = xgb_clf.predict(X_eval)\n",
    "eval_report = classification_report(y_eval, eval_predict, target_names=['spsw', 'gped', 'pled', 'eyem', 'artf', 'backg'])\n",
    "print(\"Classification Report:\\n\", eval_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e6373-7e04-4f26-81ac-0a81364c16b5",
   "metadata": {},
   "source": [
    "### Binary classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5941031e-e648-4c43-ac1d-948a3259ac9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.7182684758243453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "group_1 = {1, 2, 3}  # Group 1 (mapped to 0)\n",
    "group_2 = {4, 5, 6}  # Group 2 (mapped to 1)\n",
    "\n",
    "true_labels = [0 if cls in group_1 else 1 for cls in y_test]\n",
    "predicted_labels = [0 if cls in group_1 else 1 for cls in y_pred]\n",
    "\n",
    "balanced_acc = balanced_accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5452dcc-21fa-4063-a019-477edf011f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
